{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/07_sentence/07_sentence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchtext==0.15.1\n",
        "# !pip install portalocker\n",
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "id": "qq0keADLNuTR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to RNNs"
      ],
      "metadata": {
        "id": "oYECu1QOLk9a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MFdQXsFqJOzD"
      },
      "outputs": [],
      "source": [
        "# State machine (transition model) with 3 states:\n",
        "# 1. State h = -1:\n",
        "#   - Maintains itself when x = 1\n",
        "#   - Proceeds to the h = 0 state if x = -1\n",
        "# 2. State h = 0:\n",
        "#   - Moves to h = -1 state when x = 1\n",
        "#   - Advances to the h = 1 when x = -1\n",
        "# 3. State h = 1:\n",
        "#   - Sustains its position when x = -1\n",
        "#   - Transitions to h = 0 state when x = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "W_xh=torch.tensor(-10.0)\n",
        "W_hh=torch.tensor(10.0)\n",
        "b_h=torch.tensor(0.0)\n",
        "x_t=1\n",
        "h_prev=torch.tensor(-1)\n",
        "\n",
        "X=[1,1,-1,-1,1,1]\n",
        "H=[-1,-1,0,1,0,-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ0jN1TiLG-2",
        "outputId": "1d5cc4f1-2c77-4079-97d1-06faf1b2fbc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-3-eaec925ceedc>\", line 3, in <cell line: 0>\n",
            "    W_xh=torch.tensor(-10.0)\n",
            "<ipython-input-3-eaec925ceedc>:3: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  W_xh=torch.tensor(-10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the predicted state values\n",
        "H_hat = []\n",
        "# Loop through each data point in the input sequence X\n",
        "t=1\n",
        "for x in X:\n",
        "    # Assign the current data point to x_t\n",
        "    print(\"t=\",t)\n",
        "    x_t = x\n",
        "    # Print the value of the previous state (h at time t-1)\n",
        "    print(\"h_t-1\", h_prev.item())\n",
        "\n",
        "    # Compute the current state (h at time t) using the RNN formula with tanh activation\n",
        "    h_t = torch.tanh(x_t * W_xh + h_prev * W_hh + b_h)\n",
        "\n",
        "    # Update h_prev to the current state value for the next iteration\n",
        "    h_prev = h_t\n",
        "\n",
        "    # Print the current input value (x at time t)\n",
        "    print(\"x_t\", x_t)\n",
        "\n",
        "    # Print the computed state value (h at time t)\n",
        "    print(\"h_t\", h_t.item())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Append the current state value to the H_hat list after converting it to integer\n",
        "    H_hat.append(int(h_t.item()))\n",
        "    t+=1"
      ],
      "metadata": {
        "id": "94AnYIL9LTtD",
        "outputId": "8b06f7fa-72a8-4457-9d87-0685a7df3878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t= 1\n",
            "h_t-1 -1\n",
            "x_t 1\n",
            "h_t -1.0\n",
            "\n",
            "\n",
            "t= 2\n",
            "h_t-1 -1.0\n",
            "x_t 1\n",
            "h_t -1.0\n",
            "\n",
            "\n",
            "t= 3\n",
            "h_t-1 -1.0\n",
            "x_t -1\n",
            "h_t 0.0\n",
            "\n",
            "\n",
            "t= 4\n",
            "h_t-1 0.0\n",
            "x_t -1\n",
            "h_t 1.0\n",
            "\n",
            "\n",
            "t= 5\n",
            "h_t-1 1.0\n",
            "x_t 1\n",
            "h_t 0.0\n",
            "\n",
            "\n",
            "t= 6\n",
            "h_t-1 0.0\n",
            "x_t 1\n",
            "h_t -1.0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_hat"
      ],
      "metadata": {
        "id": "X8o4OpiALbn_",
        "outputId": "3584169d-7890-483c-8e01-5e894e4d6663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1, -1, 0, 1, 0, -1]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H"
      ],
      "metadata": {
        "id": "x7uxuEXRLcBr",
        "outputId": "b7462328-3b5c-4f3e-f84a-43a49638f76d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1, -1, 0, 1, 0, -1]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequence-to-sequence architecture\n",
        "\n",
        "## Encoder implementation in PyTorch"
      ],
      "metadata": {
        "id": "Oduh3fbrLpyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "5inDlii6MCti"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hid_dim, n_layers, dropout_prob):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_len, emb_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout_prob)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, input_batch):\n",
        "        #input_batch = [src len, batch size]\n",
        "        embed = self.dropout(self.embedding(input_batch))\n",
        "        embed = embed.to(device)\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        outputs, (hidden, cell) = self.lstm(embed)\n",
        "\n",
        "        return hidden, cell\n"
      ],
      "metadata": {
        "id": "4nduj7-wLdgH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = 8\n",
        "emb_dim = 10\n",
        "hid_dim=8\n",
        "n_layers=1\n",
        "dropout_prob=0.5\n",
        "\n",
        "encoder_t = Encoder(vocab_len, emb_dim, hid_dim, n_layers, dropout_prob).to(device)"
      ],
      "metadata": {
        "id": "Tbah1KqpL9K0",
        "outputId": "d0295962-e999-4119-8e53-674c5bde2ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_batch = torch.tensor([[0,3,4,2,1]])\n",
        "# you need to transpose the input tensor as the encoder LSTM is in Sequence_first mode by default\n",
        "src_batch = src_batch.t().to(device)\n",
        "print(\"Shape of input(src) tensor:\", src_batch.shape)\n",
        "hidden_t , cell_t = encoder_t(src_batch)\n",
        "print(\"Hidden tensor from encoder:\",hidden_t ,\"\\nCell tensor from encoder:\", cell_t)"
      ],
      "metadata": {
        "id": "tUz2HAn5MJ2w",
        "outputId": "d6748301-21bd-4e73-b007-448d1a7edf41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input(src) tensor: torch.Size([5, 1])\n",
            "Hidden tensor from encoder: tensor([[[-0.0210,  0.1240, -0.0093, -0.1022,  0.1309, -0.2510,  0.0275,\n",
            "           0.0961]]], grad_fn=<StackBackward0>) \n",
            "Cell tensor from encoder: tensor([[[-0.0534,  0.2033, -0.0534, -0.1975,  0.4286, -0.3490,  0.2029,\n",
            "           0.2242]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder implementation in PyTorch"
      ],
      "metadata": {
        "id": "Q0dGXxhTMmSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "\n",
        "\n",
        "        #input = [batch size]\n",
        "\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "        #input = [1, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        #embedded = [1, batch size, emb dim]\n",
        "\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "\n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        prediction_logit = self.fc_out(output.squeeze(0))\n",
        "        prediction = self.softmax(prediction_logit)\n",
        "        #prediction = [batch size, output dim]\n",
        "\n",
        "\n",
        "        return prediction, hidden, cell"
      ],
      "metadata": {
        "id": "P_drcRsTMGxL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim = 6\n",
        "emb_dim=10\n",
        "hid_dim = 8\n",
        "n_layers=1\n",
        "dropout=0.5\n",
        "\n",
        "decoder_t = Decoder(output_dim, emb_dim, hid_dim, n_layers, dropout).to(device)"
      ],
      "metadata": {
        "id": "tEyj1IgMMuFI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_t = torch.tensor([0]).to(device) #<bos>\n",
        "input_t.shape\n",
        "prediction, hidden, cell = decoder_t(input_t, hidden_t , cell_t)\n",
        "print(\"Prediction:\", prediction, '\\nHidden:',hidden,'\\nCell:', cell)"
      ],
      "metadata": {
        "id": "s-L0MHZcMxQa",
        "outputId": "7c1765e4-7b7a-4a6a-d7da-12e9311a5412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: tensor([[-1.8238, -1.6286, -1.6941, -1.9694, -1.8385, -1.8325]],\n",
            "       grad_fn=<LogSoftmaxBackward0>) \n",
            "Hidden: tensor([[[-0.0141, -0.2105,  0.0351,  0.1100, -0.1326, -0.0284,  0.1185,\n",
            "           0.1628]]], grad_fn=<StackBackward0>) \n",
            "Cell: tensor([[[-0.0360, -0.3676,  0.2376,  0.2736, -0.3931, -0.0937,  0.2207,\n",
            "           0.2640]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder-decoder connection"
      ],
      "metadata": {
        "id": "VJJcf9sfNAYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "#trg = [trg len, batch size]\n",
        "#teacher_forcing_ratio is probability to use teacher forcing\n",
        "#e.g. if teacher_forcing_ratio is 0.75 you use ground-truth inputs 75% of the time\n",
        "teacher_forcing_ratio = 0.5\n",
        "trg = torch.tensor([[0],[2],[3],[5],[1]]).to(device)\n",
        "\n",
        "\n",
        "batch_size = trg.shape[1]\n",
        "trg_len = trg.shape[0]\n",
        "trg_vocab_size = decoder_t.output_dim\n",
        "\n",
        "#tensor to store decoder outputs\n",
        "outputs_t = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n",
        "\n",
        "#send to device\n",
        "\n",
        "hidden_t = hidden_t.to(device)\n",
        "cell_t = cell_t.to(device)\n",
        "\n",
        "\n",
        "#first input to the decoder is the <bos> tokens\n",
        "input = trg[0,:]\n",
        "\n",
        "\n",
        "for t in range(1, trg_len):\n",
        "\n",
        "    #you loop through the trg len and generate tokens\n",
        "    #decoder receives previous generated token, cell and hidden\n",
        "    # decoder outputs it prediction(probablity distribution for the next token) and updates hidden and cell\n",
        "    output_t, hidden_t, cell_t = decoder_t(input, hidden_t, cell_t)\n",
        "\n",
        "    #place predictions in a tensor holding predictions for each token\n",
        "    outputs_t[t] = output_t\n",
        "\n",
        "    #decide if you are going to use teacher forcing or not\n",
        "    teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "    #get the highest predicted token from your predictions\n",
        "    top1 = output_t.argmax(1)\n",
        "\n",
        "\n",
        "    #if teacher forcing, use actual next token as next input\n",
        "    #if not, use predicted token\n",
        "    #input = trg[t] if teacher_force else top1\n",
        "    input = trg[t] if teacher_force else top1\n",
        "\n",
        "print(outputs_t,outputs_t.shape )"
      ],
      "metadata": {
        "id": "L2BXmY6XMzsU",
        "outputId": "eb973aad-39cc-4820-9af2-f65966ba75e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
            "\n",
            "        [[-1.7461, -1.6458, -1.6944, -1.9193, -1.8742, -1.9051]],\n",
            "\n",
            "        [[-1.7816, -1.6708, -1.6661, -1.9234, -1.8370, -1.9027]],\n",
            "\n",
            "        [[-1.9440, -1.6254, -1.6213, -1.9682, -1.7898, -1.8599]],\n",
            "\n",
            "        [[-1.8835, -1.5203, -1.6921, -2.0207, -1.8744, -1.8379]]],\n",
            "       grad_fn=<CopySlices>) torch.Size([5, 1, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that you need to get the argmax from the second dimension as **outputs** is an array of **output** tensors\n",
        "pred_tokens = outputs_t.argmax(2)\n",
        "print(pred_tokens)\n"
      ],
      "metadata": {
        "id": "F9da6-HvM2oN",
        "outputId": "094e95b7-e382-4c24-a77f-37799f301eed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [2],\n",
            "        [1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequence-to-sequence model implementation in PyTorch"
      ],
      "metadata": {
        "id": "mRaD0DgoNPqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device,trg_vocab):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.trg_vocab = trg_vocab\n",
        "\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 you use ground-truth inputs 75% of the time\n",
        "\n",
        "\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        hidden = hidden.to(device)\n",
        "        cell = cell.to(device)\n",
        "\n",
        "\n",
        "        #first input to the decoder is the <bos> tokens\n",
        "        input = trg[0,:]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "\n",
        "            #decide if you are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            #get the highest predicted token from your predictions\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "\n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            #input = trg[t] if teacher_force else top1\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "Nw0e-zPwM3y8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training model in PyTorch"
      ],
      "metadata": {
        "id": "cJooxGKqNXd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Wrap iterator with tqdm for progress logging\n",
        "    train_iterator = tqdm(iterator, desc=\"Training\", leave=False)\n",
        "\n",
        "    for i, (src,trg) in enumerate(iterator):\n",
        "\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "\n",
        "        trg = trg[1:].contiguous().view(-1)\n",
        "\n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update tqdm progress bar with the current loss\n",
        "        train_iterator.set_postfix(loss=loss.item())\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "    return epoch_loss / len(list(iterator))\n"
      ],
      "metadata": {
        "id": "JRgSDrziM4EL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating model in PyTorch"
      ],
      "metadata": {
        "id": "izsKISeGNcor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # Wrap iterator with tqdm for progress logging\n",
        "    valid_iterator = tqdm(iterator, desc=\"Training\", leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (src,trg) in enumerate(iterator):\n",
        "\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "\n",
        "            trg = trg[1:].contiguous().view(-1)\n",
        "\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            # Update tqdm progress bar with the current loss\n",
        "            valid_iterator.set_postfix(loss=loss.item())\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(list(iterator))\n"
      ],
      "metadata": {
        "id": "y0ITnn-kM4cb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "mJmxGwQWNgtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py'"
      ],
      "metadata": {
        "id": "xZeIvpWNM4vE",
        "outputId": "d34a77a7-342f-4d1b-cd7d-3466c9ccdd56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-21 19:46:47--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4890 (4.8K) [application/x-python]\n",
            "Saving to: ‘Multi30K_de_en_dataloader.py.3’\n",
            "\n",
            "\r          Multi30K_   0%[                    ]       0  --.-KB/s               \rMulti30K_de_en_data 100%[===================>]   4.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-21 19:46:48 (1.64 GB/s) - ‘Multi30K_de_en_dataloader.py.3’ saved [4890/4890]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run Multi30K_de_en_dataloader.py"
      ],
      "metadata": {
        "id": "DdFKvSy4M5JI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, valid_dataloader = get_translation_dataloaders(batch_size = 4)#,flip=True)\n",
        "src, trg = next(iter(train_dataloader))\n",
        "src,trg"
      ],
      "metadata": {
        "id": "NK9ttbsSM5jU",
        "outputId": "7fdbf227-8ff1-4c4c-f2a1-6bb7fd1176d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Multi30K_de_en_dataloader.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  src_sequences = torch.tensor(src_sequences, dtype=torch.int64)\n",
            "/content/Multi30K_de_en_dataloader.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  tgt_sequences = torch.tensor(tgt_sequences, dtype=torch.int64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[    2,     2,     2,     2],\n",
              "         [    3,  5510,  5510, 12642],\n",
              "         [    1,     3,     3,     8],\n",
              "         [    1,     1,     1,  1701],\n",
              "         [    1,     1,     1,     3]]),\n",
              " tensor([[   2,    2,    2,    2],\n",
              "         [   3, 6650,  216,    6],\n",
              "         [   1, 4623,  110, 3398],\n",
              "         [   1,  259, 3913,  202],\n",
              "         [   1,  172, 1650,  109],\n",
              "         [   1, 9953, 3823,   37],\n",
              "         [   1,  115,   71,    3],\n",
              "         [   1,  692, 2808,    1],\n",
              "         [   1, 3428, 2187,    1],\n",
              "         [   1,    5,    5,    1],\n",
              "         [   1,    3,    3,    1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_itr = iter(train_dataloader)\n",
        "# moving forward in the dataset to reach sequences of longer length for illustration purpose. (Remember the dataset is sorted on sequence len for optimal padding)\n",
        "for n in range(1000):\n",
        "    german, english= next(data_itr)\n",
        "\n",
        "for n in range(3):\n",
        "    german, english=next(data_itr)\n",
        "    german=german.T\n",
        "    english=english.T\n",
        "    print(\"________________\")\n",
        "    print(\"german\")\n",
        "    for g in german:\n",
        "        print(index_to_german(g))\n",
        "    print(\"________________\")\n",
        "    print(\"english\")\n",
        "    for e in english:\n",
        "        print(index_to_eng(e))"
      ],
      "metadata": {
        "id": "tRbRvxXlM5zM",
        "outputId": "415195a8-51d0-404d-ae8c-1b90999a874c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________\n",
            "german\n",
            "<bos> Personen mit schwarzen Hüten in der Innenstadt . <eos>\n",
            "<bos> Eine Gruppe Menschen protestiert in einer Stadt . <eos>\n",
            "<bos> Eine Gruppe teilt ihre politischen Ansichten mit . <eos>\n",
            "<bos> Mehrere Personen sitzen an einem felsigen Strand . <eos>\n",
            "________________\n",
            "english\n",
            "<bos> People in black hats gathered together downtown . <eos> <pad> <pad> <pad>\n",
            "<bos> A group of people protesting in a city . <eos> <pad> <pad>\n",
            "<bos> A group is letting their political opinion be known . <eos> <pad>\n",
            "<bos> A group of people are sitting on a rocky beach . <eos>\n",
            "________________\n",
            "german\n",
            "<bos> Zwei sitzende Personen mit Hüten und Sonnenbrillen . <eos>\n",
            "<bos> Ein kleiner Junge mit Hut beim Angeln . <eos>\n",
            "<bos> Diese zwei Frauen haben Spaß im Giorgio's . <eos>\n",
            "<bos> Zwei kleine Kinder schlafen auf dem Sofa . <eos>\n",
            "________________\n",
            "english\n",
            "<bos> Two people sitting in hats and shades . <eos> <pad> <pad> <pad>\n",
            "<bos> A young boy in a hat is fishing by himself . <eos>\n",
            "<bos> These two women is at Giorgio 's having fun . <eos> <pad>\n",
            "<bos> Two young children are asleep on a couch . <eos> <pad> <pad>\n",
            "________________\n",
            "german\n",
            "<bos> Zwei junge Mädchen marschieren in einem Umzug . <eos>\n",
            "<bos> Eine Frau läuft vor einer gestreiften Wand . <eos>\n",
            "<bos> Ein Mann fährt Jet-Ski auf dem Ozean . <eos>\n",
            "<bos> Die städtischen Straßenbahnen an einem sonnigen Tag . <eos>\n",
            "________________\n",
            "english\n",
            "<bos> Two young girls walk in a parade . <eos> <pad> <pad> <pad> <pad>\n",
            "<bos> A woman is running in front of a striped wall . <eos> <pad>\n",
            "<bos> A man rides a jet ski across the ocean . <eos> <pad> <pad>\n",
            "<bos> The urban trolly 's of a city on a sunny day . <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "e_g23TxHQOY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "vMyQKnoMM5-T"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(vocab_transform['de'])\n",
        "OUTPUT_DIM = len(vocab_transform['en'])\n",
        "ENC_EMB_DIM = 128 #256\n",
        "DEC_EMB_DIM = 128 #256\n",
        "HID_DIM = 256 #512\n",
        "N_LAYERS = 1 #2\n",
        "ENC_DROPOUT = 0.3 #0.5\n",
        "DEC_DROPOUT = 0.3 #0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device,trg_vocab = vocab_transform['en']).to(device)"
      ],
      "metadata": {
        "id": "2xsvzv_VM6KA",
        "outputId": "cc7d2ed5-5886-4377-89a5-523693107605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "P58zS6MnM6VR",
        "outputId": "b96cba88-7836-4803-c85c-3609fc47480b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(19214, 128)\n",
              "    (lstm): LSTM(128, 256, dropout=0.3)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(10837, 128)\n",
              "    (lstm): LSTM(128, 256, dropout=0.3)\n",
              "    (fc_out): Linear(in_features=256, out_features=10837, bias=True)\n",
              "    (softmax): LogSoftmax(dim=1)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (trg_vocab): Vocab()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "kBsYv78lM6gt",
        "outputId": "601ab82e-78b1-4b9b-b329-803354dd6b3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 7,422,165 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "PAD_IDX = vocab_transform['en'].get_stoi()['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "9-jxnpZ3M6th"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "N_EPOCHS = 3 #run the training for at least 5 epochs\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "best_train_loss = float('inf')\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "train_PPLs = []\n",
        "valid_PPLs = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
        "    train_ppl = math.exp(train_loss)\n",
        "    valid_loss = evaluate(model, valid_dataloader, criterion)\n",
        "    valid_ppl = math.exp(valid_loss)\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'RNN-TR-model.pt')\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_PPLs.append(train_ppl)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_PPLs.append(valid_ppl)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {train_ppl:7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {valid_ppl:7.3f}')"
      ],
      "metadata": {
        "id": "6IWSSO0zM64d",
        "outputId": "363a55c9-5fae-4895-c615-a1fe39aaf483",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/7250 [01:22<?, ?it/s, loss=4.27]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z9aBFAaHM7ET"
      },
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}