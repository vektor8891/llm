{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install -qq \"ibm-watsonx-ai==0.2.6\"\n",
        "! pip install -qq \"langchain==0.1.16\"\n",
        "! pip install -qq \"langchain-ibm==0.1.4\""
      ],
      "metadata": {
        "id": "J8uafqA4q7vE"
      },
      "id": "J8uafqA4q7vE",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-Context Engineering and Prompt Templates"
      ],
      "metadata": {
        "id": "xzm0KzZ5qcZh"
      },
      "id": "xzm0KzZ5qcZh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup LLM"
      ],
      "metadata": {
        "id": "HtVLFqpcqycM"
      },
      "id": "HtVLFqpcqycM"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e7184dd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7184dd7",
        "outputId": "f5cf3606-c4fa-4012-aebe-bbb8a60ad984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ibm_watson_machine_learning/foundation_models/extensions/langchain/llm.py:60: WatsonxLLMDeprecationWarning: ibm_watson_machine_learning.foundation_models.extensions.langchain.WatsonxLLM is deprecated and will not be supported in the future. Please import from langchain-ibm instead.\n",
            "To install langchain-ibm run `pip install -U langchain-ibm`.\n",
            "  _raise_watsonxllm_deprecation_warning()\n"
          ]
        }
      ],
      "source": [
        "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "from ibm_watsonx_ai.foundation_models import Model\n",
        "\n",
        "def llm_model(prompt_txt, params=None):\n",
        "    model_id = 'mistralai/mixtral-8x7b-instruct-v01'\n",
        "\n",
        "    default_params = {\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"min_new_tokens\": 0,\n",
        "        \"temperature\": 0.5,\n",
        "        \"top_p\": 0.2,\n",
        "        \"top_k\": 1\n",
        "    }\n",
        "\n",
        "    if params:\n",
        "        default_params.update(params)\n",
        "\n",
        "    parameters = {\n",
        "        GenParams.MAX_NEW_TOKENS: default_params[\"max_new_tokens\"],  # this controls the maximum number of tokens in the generated output\n",
        "        GenParams.MIN_NEW_TOKENS: default_params[\"min_new_tokens\"], # this controls the minimum number of tokens in the generated output\n",
        "        GenParams.TEMPERATURE: default_params[\"temperature\"], # this randomness or creativity of the model's responses\n",
        "        GenParams.TOP_P: default_params[\"top_p\"],\n",
        "        GenParams.TOP_K: default_params[\"top_k\"]\n",
        "    }\n",
        "\n",
        "    credentials = {\n",
        "        \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
        "    }\n",
        "\n",
        "    project_id = \"skills-network\"\n",
        "\n",
        "    model = Model(\n",
        "        model_id=model_id,\n",
        "        params=parameters,\n",
        "        credentials=credentials,\n",
        "        project_id=project_id\n",
        "    )\n",
        "\n",
        "    mixtral_llm = WatsonxLLM(model=model)\n",
        "    response  = mixtral_llm.invoke(prompt_txt)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GenParams().get_example_values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxi-SrBCq1ri",
        "outputId": "e6015c4c-e590-4bda-9342-6a7a1311233a"
      },
      "id": "mxi-SrBCq1ri",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'decoding_method': 'sample',\n",
              " 'length_penalty': {'decay_factor': 2.5, 'start_index': 5},\n",
              " 'temperature': 0.5,\n",
              " 'top_p': 0.2,\n",
              " 'top_k': 1,\n",
              " 'random_seed': 33,\n",
              " 'repetition_penalty': 2,\n",
              " 'min_new_tokens': 50,\n",
              " 'max_new_tokens': 200,\n",
              " 'stop_sequences': ['fail'],\n",
              " ' time_limit': 600000,\n",
              " 'truncate_input_tokens': 200,\n",
              " 'return_options': {'input_text': True,\n",
              "  'generated_tokens': True,\n",
              "  'input_tokens': True,\n",
              "  'token_logprobs': True,\n",
              "  'token_ranks': False,\n",
              "  'top_n_tokens': False}}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt engineering"
      ],
      "metadata": {
        "id": "gywz1YvuroJ9"
      },
      "id": "gywz1YvuroJ9"
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"max_new_tokens\": 128,\n",
        "    \"min_new_tokens\": 10,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_p\": 0.2,\n",
        "    \"top_k\": 1\n",
        "}\n",
        "\n",
        "prompt = \"The wind is\"\n",
        "\n",
        "response = llm_model(prompt, params)\n",
        "print(f\"prompt: {prompt}\\n\")\n",
        "print(f\"response : {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "qwsrDANgrmEs",
        "outputId": "02dfd73f-5be2-4b5a-b267-c3e2c43476ab"
      },
      "id": "qwsrDANgrmEs",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ibm_watson_machine_learning.wml_client_error:'`apikey` for IAM token is not provided in credentials for the client'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WMLClientError",
          "evalue": "'`apikey` for IAM token is not provided in credentials for the client'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-672175813.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The wind is\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"prompt: {prompt}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"response : {response}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-1133626563.py\u001b[0m in \u001b[0;36mllm_model\u001b[0;34m(prompt_txt, params)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mproject_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"skills-network\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     model = Model(\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ibm_watsonx_ai/foundation_models/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_id, credentials, params, project_id, space_id, verify, validate)\u001b[0m\n\u001b[1;32m     80\u001b[0m                  \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                  validate: bool = True) -> None:\n\u001b[0;32m---> 82\u001b[0;31m         ModelInference.__init__(self,\n\u001b[0m\u001b[1;32m     83\u001b[0m                                 \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                                 \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ibm_watsonx_ai/foundation_models/inference/model_inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_id, deployment_id, params, credentials, project_id, space_id, verify, api_client, validate)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAPIClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ibm_watsonx_ai/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wml_credentials, project_id, verify)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwml_credentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwml_credentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_fm_ga_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_if_fm_ga_api_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Remove on CPD 5.0 release\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ibm_watson_machine_learning/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wml_credentials, project_id, verify)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_IAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apikey_not_provided\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             if 'icp' == self.wml_credentials[u'instance_id'].lower() or 'openshift' == self.wml_credentials[\n",
            "\u001b[0;31mWMLClientError\u001b[0m: '`apikey` for IAM token is not provided in credentials for the client'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PGEmJG5Orp8-"
      },
      "id": "PGEmJG5Orp8-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31b1176b",
        "outputId": "060959a5-c898-4a85-f43d-4f8aaa68d5e4"
      },
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('IBM_CLOUD_API_KEY')\n",
        "\n",
        "if api_key:\n",
        "  print(\"IBM_CLOUD_API_KEY is successfully loaded from Colab secrets.\")\n",
        "else:\n",
        "  print(\"IBM_CLOUD_API_KEY not found in Colab secrets. Please make sure you have set it up correctly.\")"
      ],
      "id": "31b1176b",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IBM_CLOUD_API_KEY is successfully loaded from Colab secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d60c2ba2",
        "outputId": "e5607958-a238-4fa8-be78-121923deb3c8"
      },
      "source": [
        "# Update libraries to the latest versions\n",
        "! pip install -U \"ibm-watsonx-ai\" \"langchain-ibm\""
      ],
      "id": "d60c2ba2",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ibm-watsonx-ai in /usr/local/lib/python3.11/dist-packages (0.2.6)\n",
            "Collecting ibm-watsonx-ai\n",
            "  Downloading ibm_watsonx_ai-1.3.26-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-ibm in /usr/local/lib/python3.11/dist-packages (0.1.4)\n",
            "Collecting langchain-ibm\n",
            "  Downloading langchain_ibm-0.3.12-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.32.2)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.28.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.4.0)\n",
            "Requirement already satisfied: pandas<2.3.0,>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.1.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2025.6.15)\n",
            "Requirement already satisfied: lomond in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.3.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (23.2)\n",
            "Requirement already satisfied: ibm-cos-sdk<2.15.0,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.13.6)\n",
            "Collecting langchain-core<0.4.0,>=0.3.39 (from langchain-ibm)\n",
            "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ibm-watsonx-ai) (0.16.0)\n",
            "Requirement already satisfied: ibm-cos-sdk-core==2.13.6 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.13.6)\n",
            "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.13.6 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.13.6)\n",
            "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.9.0.post0)\n",
            "Collecting langsmith>=0.3.45 (from langchain-core<0.4.0,>=0.3.39->langchain-ibm)\n",
            "  Downloading langsmith-0.4.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (4.14.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.39->langchain-ibm) (2.11.7)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ibm-watsonx-ai) (3.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from lomond->ibm-watsonx-ai) (1.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.39->langchain-ibm) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai) (1.3.1)\n",
            "Downloading ibm_watsonx_ai-1.3.26-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_ibm-0.3.12-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.4.1-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.6/364.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langsmith, langchain-core, ibm-watsonx-ai, langchain-ibm\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.147\n",
            "    Uninstalling langsmith-0.1.147:\n",
            "      Successfully uninstalled langsmith-0.1.147\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.1.53\n",
            "    Uninstalling langchain-core-0.1.53:\n",
            "      Successfully uninstalled langchain-core-0.1.53\n",
            "  Attempting uninstall: ibm-watsonx-ai\n",
            "    Found existing installation: ibm_watsonx_ai 0.2.6\n",
            "    Uninstalling ibm_watsonx_ai-0.2.6:\n",
            "      Successfully uninstalled ibm_watsonx_ai-0.2.6\n",
            "  Attempting uninstall: langchain-ibm\n",
            "    Found existing installation: langchain-ibm 0.1.4\n",
            "    Uninstalling langchain-ibm-0.1.4:\n",
            "      Successfully uninstalled langchain-ibm-0.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-text-splitters 0.0.2 requires langchain-core<0.3,>=0.1.28, but you have langchain-core 0.3.66 which is incompatible.\n",
            "langchain-community 0.0.38 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.3.66 which is incompatible.\n",
            "langchain-community 0.0.38 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.4.1 which is incompatible.\n",
            "langchain 0.1.16 requires langchain-core<0.2.0,>=0.1.42, but you have langchain-core 0.3.66 which is incompatible.\n",
            "langchain 0.1.16 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ibm-watsonx-ai-1.3.26 langchain-core-0.3.66 langchain-ibm-0.3.12 langsmith-0.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain_core",
                  "langsmith"
                ]
              },
              "id": "cf64e81144a2458c925ff9d65d16ff4f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "e1bd807d",
        "outputId": "4db392c9-6932-4993-8f1a-df3c2b9ea0d9"
      },
      "source": [
        "from langchain_ibm.chat_models import WatsonxLLM\n",
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "from ibm_watsonx_ai.foundation_models import Model\n",
        "from google.colab import userdata\n",
        "# Removed the import of Credentials as it seems to be causing an ImportError\n",
        "# from ibm_watsonx_ai import Credentials\n",
        "\n",
        "def llm_model(prompt_txt, params=None):\n",
        "    model_id = 'mistralai/mixtral-8x7b-instruct-v01'\n",
        "\n",
        "    default_params = {\n",
        "        \"max_new_tokens\": 256,\n",
        "        \"min_new_tokens\": 0,\n",
        "        \"temperature\": 0.5,\n",
        "        \"top_p\": 0.2,\n",
        "        \"top_k\": 1\n",
        "    }\n",
        "\n",
        "    if params:\n",
        "        default_params.update(params)\n",
        "\n",
        "    parameters = {\n",
        "        GenParams.MAX_NEW_TOKENS: default_params[\"max_new_tokens\"],\n",
        "        GenParams.MIN_NEW_TOKENS: default_params[\"min_new_tokens\"],\n",
        "        GenParams.TEMPERATURE: default_params[\"temperature\"],\n",
        "        GenParams.TOP_P: default_params[\"top_p\"],\n",
        "        GenParams.TOP_K: default_params[\"top_k\"]\n",
        "    }\n",
        "\n",
        "    api_key = userdata.get('IBM_CLOUD_API_KEY')\n",
        "\n",
        "    credentials = {\n",
        "        \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
        "        \"apikey\": api_key\n",
        "    }\n",
        "\n",
        "    project_id = \"skills-network\"\n",
        "\n",
        "    model = Model(\n",
        "        model_id=model_id,\n",
        "        params=parameters,\n",
        "        credentials=credentials,\n",
        "        project_id=project_id\n",
        "    )\n",
        "\n",
        "    mixtral_llm = WatsonxLLM(model=model)\n",
        "    response  = mixtral_llm.invoke(prompt_txt)\n",
        "    return response"
      ],
      "id": "e1bd807d",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'WatsonxLLM' from 'langchain_ibm.chat_models' (/usr/local/lib/python3.11/dist-packages/langchain_ibm/chat_models.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2263509430.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_ibm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWatsonxLLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mibm_watsonx_ai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetanames\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenTextParamsMetaNames\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mGenParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mibm_watsonx_ai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoundation_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Removed the import of Credentials as it seems to be causing an ImportError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'WatsonxLLM' from 'langchain_ibm.chat_models' (/usr/local/lib/python3.11/dist-packages/langchain_ibm/chat_models.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}