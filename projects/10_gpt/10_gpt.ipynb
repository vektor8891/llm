{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6af91c32",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/10_gpt/10_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "nUd6MmhF_-Ri",
      "metadata": {
        "id": "nUd6MmhF_-Ri"
      },
      "outputs": [],
      "source": [
        "# !pip install torchtext==0.17.2\n",
        "# !pip install portalocker==2.8.2\n",
        "# !pip install transformers==4.35.2\n",
        "# !pip install torch==2.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jp9g4GFg_zaF",
      "metadata": {
        "id": "jp9g4GFg_zaF"
      },
      "source": [
        "# Text pipeline\n",
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "a0947318",
      "metadata": {
        "id": "a0947318"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "\n",
        "# Load the dataset\n",
        "train_iter, val_iter = IMDB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ae24860f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae24860f",
        "outputId": "c06c3160-e702-4795-8c55-e7bf123fd6a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1,\n",
              " \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_itr=iter(train_iter)\n",
        "# retrieving the third first record\n",
        "next(data_itr)\n",
        "next(data_itr)\n",
        "next(data_itr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Hf7mxFi9A7KR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf7mxFi9A7KR",
        "outputId": "164e926b-280e-4fc9-e33c-a0e63e530656"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mkFJfJW4BsvB",
      "metadata": {
        "id": "mkFJfJW4BsvB"
      },
      "source": [
        "## Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bYQMKgJ7BsU3",
      "metadata": {
        "id": "bYQMKgJ7BsU3"
      },
      "outputs": [],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, EOS_IDX = 0, 1, 2\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<|endoftext|>' ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5trXDm52BkpC",
      "metadata": {
        "id": "5trXDm52BkpC"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "_B4vrLbwBz2Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B4vrLbwBz2Y",
        "outputId": "6faf9b16-c421-466f-b782-993789b1d5c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "\n",
        "    for _,data_sample in data_iter:\n",
        "        yield  tokenizer(data_sample)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=special_symbols, special_first=True)\n",
        "vocab.set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1e-_-qRC1Sh",
      "metadata": {
        "id": "e1e-_-qRC1Sh"
      },
      "source": [
        "###  Text to index and index to Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8rkuKSjwB5Rn",
      "metadata": {
        "id": "8rkuKSjwB5Rn"
      },
      "outputs": [],
      "source": [
        "text_to_index=lambda text: [vocab(token) for token in tokenizer(text)]\n",
        "index_to_en = lambda seq_en: \" \".join([vocab.get_itos()[index] for index in seq_en])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "VF-tFTKuC3uW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VF-tFTKuC3uW",
        "outputId": "6b765e48-22d4-4c70-c006-7554d442c349"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<unk> <pad> <|endoftext|>'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check\n",
        "index_to_en(torch.tensor([0,1,2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rKtMsk25DCZy",
      "metadata": {
        "id": "rKtMsk25DCZy"
      },
      "source": [
        "### Collate function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "gLOi7hJ6C7X0",
      "metadata": {
        "id": "gLOi7hJ6C7X0"
      },
      "outputs": [],
      "source": [
        "def get_sample(block_size, text):\n",
        "    # Determine the length of the input text\n",
        "    sample_leg = len(text)\n",
        "    # Calculate the stopping point for randomly selecting a sample\n",
        "    # This ensures the selected sample doesn't exceed the text length\n",
        "    random_sample_stop = sample_leg - block_size\n",
        "\n",
        "\n",
        "    # Check if a random sample can be taken (if the text is longer than block_size)\n",
        "    if random_sample_stop >= 1:\n",
        "        # Randomly select a starting point for the sample\n",
        "        random_start = torch.randint(low=0, high=random_sample_stop, size=(1,)).item()\n",
        "        # Define the endpoint of the sample\n",
        "        stop = random_start + block_size\n",
        "\n",
        "        # Create the input and target sequences\n",
        "        src_sequence = text[random_start:stop]\n",
        "        tgt_sequence= text[random_start + 1:stop + 1]\n",
        "\n",
        "    # Handle the case where the text length is exactly equal or less the block size\n",
        "    elif random_sample_stop <= 0:\n",
        "        # Start from the beginning and use the entire text\n",
        "        random_start = 0\n",
        "        stop = sample_leg\n",
        "        src_sequence= text[random_start:stop]\n",
        "        tgt_sequence = text[random_start + 1:stop]\n",
        "        # Append an empty string to maintain sequence alignment\n",
        "        tgt_sequence.append( '<|endoftext|>')\n",
        "\n",
        "    return src_sequence, tgt_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "buYKCfpRDETB",
      "metadata": {
        "id": "buYKCfpRDETB"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=1\n",
        "\n",
        "batch_of_tokens=[]\n",
        "\n",
        "for i in range(BATCH_SIZE):\n",
        "  _,text =next(iter(train_iter))\n",
        "  batch_of_tokens.append(tokenizer(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "saEpbN5oDF5z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saEpbN5oDF5z",
        "outputId": "06b5f334-9d33-406b-fb9a-217dbadc36b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['i',\n",
              "  'rented',\n",
              "  'i',\n",
              "  'am',\n",
              "  'curious-yellow',\n",
              "  'from',\n",
              "  'my',\n",
              "  'video',\n",
              "  'store',\n",
              "  'because',\n",
              "  'of',\n",
              "  'all',\n",
              "  'the',\n",
              "  'controversy',\n",
              "  'that',\n",
              "  'surrounded',\n",
              "  'it',\n",
              "  'when',\n",
              "  'it',\n",
              "  'was',\n",
              "  'first',\n",
              "  'released',\n",
              "  'in',\n",
              "  '1967',\n",
              "  '.',\n",
              "  'i',\n",
              "  'also',\n",
              "  'heard',\n",
              "  'that',\n",
              "  'at',\n",
              "  'first',\n",
              "  'it',\n",
              "  'was',\n",
              "  'seized',\n",
              "  'by',\n",
              "  'u',\n",
              "  '.',\n",
              "  's',\n",
              "  '.',\n",
              "  'customs',\n",
              "  'if',\n",
              "  'it',\n",
              "  'ever',\n",
              "  'tried',\n",
              "  'to',\n",
              "  'enter',\n",
              "  'this',\n",
              "  'country',\n",
              "  ',',\n",
              "  'therefore',\n",
              "  'being',\n",
              "  'a',\n",
              "  'fan',\n",
              "  'of',\n",
              "  'films',\n",
              "  'considered',\n",
              "  'controversial',\n",
              "  'i',\n",
              "  'really',\n",
              "  'had',\n",
              "  'to',\n",
              "  'see',\n",
              "  'this',\n",
              "  'for',\n",
              "  'myself',\n",
              "  '.',\n",
              "  'the',\n",
              "  'plot',\n",
              "  'is',\n",
              "  'centered',\n",
              "  'around',\n",
              "  'a',\n",
              "  'young',\n",
              "  'swedish',\n",
              "  'drama',\n",
              "  'student',\n",
              "  'named',\n",
              "  'lena',\n",
              "  'who',\n",
              "  'wants',\n",
              "  'to',\n",
              "  'learn',\n",
              "  'everything',\n",
              "  'she',\n",
              "  'can',\n",
              "  'about',\n",
              "  'life',\n",
              "  '.',\n",
              "  'in',\n",
              "  'particular',\n",
              "  'she',\n",
              "  'wants',\n",
              "  'to',\n",
              "  'focus',\n",
              "  'her',\n",
              "  'attentions',\n",
              "  'to',\n",
              "  'making',\n",
              "  'some',\n",
              "  'sort',\n",
              "  'of',\n",
              "  'documentary',\n",
              "  'on',\n",
              "  'what',\n",
              "  'the',\n",
              "  'average',\n",
              "  'swede',\n",
              "  'thought',\n",
              "  'about',\n",
              "  'certain',\n",
              "  'political',\n",
              "  'issues',\n",
              "  'such',\n",
              "  'as',\n",
              "  'the',\n",
              "  'vietnam',\n",
              "  'war',\n",
              "  'and',\n",
              "  'race',\n",
              "  'issues',\n",
              "  'in',\n",
              "  'the',\n",
              "  'united',\n",
              "  'states',\n",
              "  '.',\n",
              "  'in',\n",
              "  'between',\n",
              "  'asking',\n",
              "  'politicians',\n",
              "  'and',\n",
              "  'ordinary',\n",
              "  'denizens',\n",
              "  'of',\n",
              "  'stockholm',\n",
              "  'about',\n",
              "  'their',\n",
              "  'opinions',\n",
              "  'on',\n",
              "  'politics',\n",
              "  ',',\n",
              "  'she',\n",
              "  'has',\n",
              "  'sex',\n",
              "  'with',\n",
              "  'her',\n",
              "  'drama',\n",
              "  'teacher',\n",
              "  ',',\n",
              "  'classmates',\n",
              "  ',',\n",
              "  'and',\n",
              "  'married',\n",
              "  'men',\n",
              "  '.',\n",
              "  'what',\n",
              "  'kills',\n",
              "  'me',\n",
              "  'about',\n",
              "  'i',\n",
              "  'am',\n",
              "  'curious-yellow',\n",
              "  'is',\n",
              "  'that',\n",
              "  '40',\n",
              "  'years',\n",
              "  'ago',\n",
              "  ',',\n",
              "  'this',\n",
              "  'was',\n",
              "  'considered',\n",
              "  'pornographic',\n",
              "  '.',\n",
              "  'really',\n",
              "  ',',\n",
              "  'the',\n",
              "  'sex',\n",
              "  'and',\n",
              "  'nudity',\n",
              "  'scenes',\n",
              "  'are',\n",
              "  'few',\n",
              "  'and',\n",
              "  'far',\n",
              "  'between',\n",
              "  ',',\n",
              "  'even',\n",
              "  'then',\n",
              "  'it',\n",
              "  \"'\",\n",
              "  's',\n",
              "  'not',\n",
              "  'shot',\n",
              "  'like',\n",
              "  'some',\n",
              "  'cheaply',\n",
              "  'made',\n",
              "  'porno',\n",
              "  '.',\n",
              "  'while',\n",
              "  'my',\n",
              "  'countrymen',\n",
              "  'mind',\n",
              "  'find',\n",
              "  'it',\n",
              "  'shocking',\n",
              "  ',',\n",
              "  'in',\n",
              "  'reality',\n",
              "  'sex',\n",
              "  'and',\n",
              "  'nudity',\n",
              "  'are',\n",
              "  'a',\n",
              "  'major',\n",
              "  'staple',\n",
              "  'in',\n",
              "  'swedish',\n",
              "  'cinema',\n",
              "  '.',\n",
              "  'even',\n",
              "  'ingmar',\n",
              "  'bergman',\n",
              "  ',',\n",
              "  'arguably',\n",
              "  'their',\n",
              "  'answer',\n",
              "  'to',\n",
              "  'good',\n",
              "  'old',\n",
              "  'boy',\n",
              "  'john',\n",
              "  'ford',\n",
              "  ',',\n",
              "  'had',\n",
              "  'sex',\n",
              "  'scenes',\n",
              "  'in',\n",
              "  'his',\n",
              "  'films',\n",
              "  '.',\n",
              "  'i',\n",
              "  'do',\n",
              "  'commend',\n",
              "  'the',\n",
              "  'filmmakers',\n",
              "  'for',\n",
              "  'the',\n",
              "  'fact',\n",
              "  'that',\n",
              "  'any',\n",
              "  'sex',\n",
              "  'shown',\n",
              "  'in',\n",
              "  'the',\n",
              "  'film',\n",
              "  'is',\n",
              "  'shown',\n",
              "  'for',\n",
              "  'artistic',\n",
              "  'purposes',\n",
              "  'rather',\n",
              "  'than',\n",
              "  'just',\n",
              "  'to',\n",
              "  'shock',\n",
              "  'people',\n",
              "  'and',\n",
              "  'make',\n",
              "  'money',\n",
              "  'to',\n",
              "  'be',\n",
              "  'shown',\n",
              "  'in',\n",
              "  'pornographic',\n",
              "  'theaters',\n",
              "  'in',\n",
              "  'america',\n",
              "  '.',\n",
              "  'i',\n",
              "  'am',\n",
              "  'curious-yellow',\n",
              "  'is',\n",
              "  'a',\n",
              "  'good',\n",
              "  'film',\n",
              "  'for',\n",
              "  'anyone',\n",
              "  'wanting',\n",
              "  'to',\n",
              "  'study',\n",
              "  'the',\n",
              "  'meat',\n",
              "  'and',\n",
              "  'potatoes',\n",
              "  '(',\n",
              "  'no',\n",
              "  'pun',\n",
              "  'intended',\n",
              "  ')',\n",
              "  'of',\n",
              "  'swedish',\n",
              "  'cinema',\n",
              "  '.',\n",
              "  'but',\n",
              "  'really',\n",
              "  ',',\n",
              "  'this',\n",
              "  'film',\n",
              "  'doesn',\n",
              "  \"'\",\n",
              "  't',\n",
              "  'have',\n",
              "  'much',\n",
              "  'of',\n",
              "  'a',\n",
              "  'plot',\n",
              "  '.']]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text=batch_of_tokens[0][0:100]\n",
        "text[0:100]\n",
        "batch_of_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "nRYzNzCQDKax",
      "metadata": {
        "id": "nRYzNzCQDKax"
      },
      "outputs": [],
      "source": [
        "block_size=10\n",
        "src_sequences, tgt_sequence=get_sample( block_size, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7DyyiDM4DZJa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DyyiDM4DZJa",
        "outputId": "80b1c5a6-e11f-496c-bd84-e8c46dfa1bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src:  ['in', 'particular', 'she', 'wants', 'to', 'focus', 'her', 'attentions', 'to', 'making']\n",
            "tgt:  ['particular', 'she', 'wants', 'to', 'focus', 'her', 'attentions', 'to', 'making', 'some']\n"
          ]
        }
      ],
      "source": [
        "print(\"src: \",src_sequences)\n",
        "print(\"tgt: \",tgt_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0oINQOoZDamD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oINQOoZDamD",
        "outputId": "bd320f1b-61f2-4dea-9641-3780df27c06a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample 0:\n",
            "Source Sequence (Text): ['purposes', 'rather', 'than', 'just', 'to', 'shock', 'people', 'and', 'make', 'money']\n",
            "Source Sequence (Indices): [4919, 253, 82, 45, 10, 1352, 89, 7, 94, 215]\n",
            "Source Sequence (Shape): torch.Size([10])\n",
            "Target Sequence (Text): ['rather', 'than', 'just', 'to', 'shock', 'people', 'and', 'make', 'money', 'to']\n",
            "Target Sequence (Indices): [253, 82, 45, 10, 1352, 89, 7, 94, 215, 10]\n",
            "Target Sequence (Shape): torch.Size([10])\n",
            "Sample 1:\n",
            "Source Sequence (Text): ['meat', 'and', 'potatoes', '(', 'no', 'pun', 'intended', ')', 'of', 'swedish']\n",
            "Source Sequence (Indices): [2876, 7, 14661, 29, 56, 4419, 1218, 27, 9, 3994]\n",
            "Source Sequence (Shape): torch.Size([10])\n",
            "Target Sequence (Text): ['and', 'potatoes', '(', 'no', 'pun', 'intended', ')', 'of', 'swedish', 'cinema']\n",
            "Target Sequence (Indices): [7, 14661, 29, 56, 4419, 1218, 27, 9, 3994, 534]\n",
            "Target Sequence (Shape): torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "# Initialize empty lists to store source and target sequences\n",
        "src_batch, tgt_batch = [], []\n",
        "\n",
        "# Define the batch size\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "# Loop to create batches of source and target sequences\n",
        "for i in range(BATCH_SIZE):\n",
        "    # Retrieve the next data point from the training iterator\n",
        "    _,text = next(iter(train_iter))\n",
        "\n",
        "    # Generate source and target sequences using the get_sample function\n",
        "    src_sequence_text, tgt_sequence_text = get_sample(block_size, tokenizer(text))\n",
        "\n",
        "    # Convert source and target sequences to tokenized vocabulary indices\n",
        "    src_sequence_indices = vocab(src_sequence_text)\n",
        "    tgt_sequence_indices = vocab(tgt_sequence_text)\n",
        "\n",
        "    # Convert the sequences to PyTorch tensors with dtype int64\n",
        "    src_sequence = torch.tensor(src_sequence_indices, dtype=torch.int64)\n",
        "    tgt_sequence = torch.tensor(tgt_sequence_indices, dtype=torch.int64)\n",
        "\n",
        "    # Append the source and target sequences to their respective batches\n",
        "    src_batch.append(src_sequence)\n",
        "    tgt_batch.append(tgt_sequence)\n",
        "\n",
        "    # Print the output for every 2nd sample (adjust as needed)\n",
        "    print(f\"Sample {i}:\")\n",
        "    print(\"Source Sequence (Text):\", src_sequence_text)\n",
        "    print(\"Source Sequence (Indices):\", src_sequence_indices)\n",
        "    print(\"Source Sequence (Shape):\", src_sequence.shape)\n",
        "    print(\"Target Sequence (Text):\", tgt_sequence_text)\n",
        "    print(\"Target Sequence (Indices):\", tgt_sequence_indices)\n",
        "    print(\"Target Sequence (Shape):\", tgt_sequence.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7VtAjlpxDj3m",
      "metadata": {
        "id": "7VtAjlpxDj3m"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "BLOCK_SIZE=30\n",
        "def collate_batch(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for _,_textt in batch:\n",
        "      src_sequence,tgt_sequence=get_sample(BLOCK_SIZE,tokenizer(_textt))\n",
        "      src_sequence=vocab(src_sequence)\n",
        "      tgt_sequence=vocab(tgt_sequence)\n",
        "      src_sequence= torch.tensor(src_sequence, dtype=torch.int64)\n",
        "      tgt_sequence = torch.tensor(tgt_sequence, dtype=torch.int64)\n",
        "      src_batch.append(src_sequence)\n",
        "      tgt_batch.append(tgt_sequence)\n",
        "\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=False)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=False)\n",
        "\n",
        "    return src_batch.to(DEVICE), tgt_batch.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "t1I4yiq5EBOD",
      "metadata": {
        "id": "t1I4yiq5EBOD"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE=1\n",
        "dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "val_dataloader= DataLoader(val_iter , batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DDSUa9WrEPpW",
      "metadata": {
        "id": "DDSUa9WrEPpW"
      },
      "source": [
        "### Iterating through data samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "qViP1Y62EHrS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qViP1Y62EHrS",
        "outputId": "3b870035-bca2-492f-fc6f-de73c16f1758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample 0\n",
            "sorce: scenes i saw made it obvious that the first howling was a great movie . so great , that seven horrible sequels had to be made . they started off\n",
            "\n",
            "\n",
            "target: i saw made it obvious that the first howling was a great movie . so great , that seven horrible sequels had to be made . they started off with\n",
            "\n",
            "\n",
            "sample 1\n",
            "sorce: apparent that they are the only two people left on earth--as you learn in the really stupid and totally unconvincing conclusion . usually the twist at the end makes the\n",
            "\n",
            "\n",
            "target: that they are the only two people left on earth--as you learn in the really stupid and totally unconvincing conclusion . usually the twist at the end makes the episode\n",
            "\n",
            "\n",
            "sample 2\n",
            "sorce: craven chose to go in the style of his older films , having no good tie but the main villain ' s name . even the actor playing dracula was\n",
            "\n",
            "\n",
            "target: chose to go in the style of his older films , having no good tie but the main villain ' s name . even the actor playing dracula was different\n",
            "\n",
            "\n",
            "sample 3\n",
            "sorce: ? is it the overacting totally ridiculously unrealistic football coach ? is it the commentaries by arne scheie ? the movie is just not funny ! but thats not my\n",
            "\n",
            "\n",
            "target: is it the overacting totally ridiculously unrealistic football coach ? is it the commentaries by arne scheie ? the movie is just not funny ! but thats not my main\n",
            "\n",
            "\n",
            "sample 4\n",
            "sorce: love , and he sees her likeness in a wax museum . it ' s a completely predictable story that goes nowhere . then you have the bit with christopher\n",
            "\n",
            "\n",
            "target: , and he sees her likeness in a wax museum . it ' s a completely predictable story that goes nowhere . then you have the bit with christopher lee\n",
            "\n",
            "\n",
            "sample 5\n",
            "sorce: they more or less followed the pattern of episodes set by the first bsg series . when they departed from that after meeting up with admiral cain and the pegasus\n",
            "\n",
            "\n",
            "target: more or less followed the pattern of episodes set by the first bsg series . when they departed from that after meeting up with admiral cain and the pegasus ,\n",
            "\n",
            "\n",
            "sample 6\n",
            "sorce: impossible to separate it from religion in commenting upon it . in my opinion , this movie pretends to explore deep issues , but thrives on stereotypes and prejudices with\n",
            "\n",
            "\n",
            "target: to separate it from religion in commenting upon it . in my opinion , this movie pretends to explore deep issues , but thrives on stereotypes and prejudices with little\n",
            "\n",
            "\n",
            "sample 7\n",
            "sorce: his dead wife and two children soon terrorize them . there is something you don ' t see every slasher . director don jones gets an a for effort although\n",
            "\n",
            "\n",
            "target: dead wife and two children soon terrorize them . there is something you don ' t see every slasher . director don jones gets an a for effort although the\n",
            "\n",
            "\n",
            "sample 8\n",
            "sorce: wars , die hard , you get the point . there isn ' t too many good horror , thriller , sets out there . many thanks to the whole\n",
            "\n",
            "\n",
            "target: , die hard , you get the point . there isn ' t too many good horror , thriller , sets out there . many thanks to the whole crew\n",
            "\n",
            "\n",
            "sample 9\n",
            "sorce: very disappointed when i saw it . it was very poorly written and sort of just fell apart . there wasn ' t a lot of good anything in this\n",
            "\n",
            "\n",
            "target: disappointed when i saw it . it was very poorly written and sort of just fell apart . there wasn ' t a lot of good anything in this movie\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset=iter(dataloader)\n",
        "for sample in range(10):\n",
        "  src,trt=next(dataset)\n",
        "  print(\"sample\",sample)\n",
        "  print(\"sorce:\",index_to_en(src))\n",
        "  print(\"\\n\")\n",
        "  print(\"target:\",index_to_en(trt))\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "PeWG2FQG1oDt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeWG2FQG1oDt",
        "outputId": "0e794e0d-b6ca-4d84-df8a-0ff16f627868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 1])\n",
            "torch.Size([30, 1])\n",
            "trailer\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for  src,trt in dataset:\n",
        "    print(trt.shape)\n",
        "    print(src.shape)\n",
        "    print(index_to_en(src[0,:]))\n",
        "    print(index_to_en(trt[0,:]))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "U5u243qe1pp5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5u243qe1pp5",
        "outputId": "3950d8e1-6b13-481f-872d-4775a8136d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "source: trailer i saw was very dynamic , that is not true for the film . that is to say the discrepancy between the trailer and the actual film is something\n",
            "target: i saw was very dynamic , that is not true for the film . that is to say the discrepancy between the trailer and the actual film is something very\n"
          ]
        }
      ],
      "source": [
        "print(\"source:\",index_to_en(src))\n",
        "print(\"target:\",index_to_en(trt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CLfhsHCV1uTJ",
      "metadata": {
        "id": "CLfhsHCV1uTJ"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8bfvyvRL1utw",
      "metadata": {
        "id": "8bfvyvRL1utw"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz,device=DEVICE):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "uhuJyLtn1xiM",
      "metadata": {
        "id": "uhuJyLtn1xiM"
      },
      "outputs": [],
      "source": [
        "def create_mask(src,device=DEVICE):\n",
        "    src_seq_len = src.shape[0]\n",
        "    src_mask = generate_square_subsequent_mask(src_seq_len)\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask,src_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wRsbcfW5104B",
      "metadata": {
        "id": "wRsbcfW5104B"
      },
      "source": [
        "## Positional encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "Lr8NmNWD11R8",
      "metadata": {
        "id": "Lr8NmNWD11R8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "# add positional information to the input tokens\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LQwJl5KS15E8",
      "metadata": {
        "id": "LQwJl5KS15E8"
      },
      "source": [
        "## Token embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "JeHgK_Tw15ZW",
      "metadata": {
        "id": "JeHgK_Tw15ZW"
      },
      "outputs": [],
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "okX2mTD517Vi",
      "metadata": {
        "id": "okX2mTD517Vi"
      },
      "source": [
        "## Custom GPT model architecture\n",
        "\n",
        "`CustomGPTModel`: transformer-based model architecture for generative pre-trained models. Purpose: to generate text and perform various NLP tasks. Main components:\n",
        "\n",
        "- **Initialization (`__init__`)**: initializes the embedding layer, positional encoding, transformer encoder layers, and a linear layer (`lm_head`) for generating logits over the vocabulary.\n",
        "\n",
        "- **Weight initialization (`init_weights`)**: initializes model weights using Xavier uniform initialization.\n",
        "\n",
        "- **Decoder (`decoder`)**: currently functions as the forward pass through the transformer encoder layers, followed by the generation of logits for the language modeling task. Adds positional encodings to the embeddings and applies a mask if necessary.\n",
        "\n",
        "- **Forward pass (`forward`)**: similar to `decoder`. Defines the forward computation of the model. Processes the input through embedding layers, positional encoding, transformer encoder layers, and produces the final output using the `lm_head`.\n",
        "\n",
        "- **Mask generation**: included in both `decoder` and `forward`. Purpose: to ensure prediction does not depend on future tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "OqC2dnrD19qo",
      "metadata": {
        "id": "OqC2dnrD19qo"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class CustomGPTModel(nn.Module):\n",
        "    def __init__(self, embed_size,vocab_size, num_heads, num_layers, max_seq_len=500,dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.init_weights()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.positional_encoding = PositionalEncoding(embed_size, dropout=dropout)\n",
        "\n",
        "        # Remaining layers are part of the TransformerDecoder\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.embed_size = embed_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def init_weights(self):\n",
        "      for p in self.parameters():\n",
        "          if p.dim() > 1:\n",
        "              nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def create_mask(src,device=DEVICE):\n",
        "        src_seq_len = src.shape[0]\n",
        "        src_mask = nn.Transformer.generate_square_subsequent_mask(src_seq_len)\n",
        "        src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "        return src_mask,src_padding_mask\n",
        "\n",
        "    def decoder(self, x,src_mask):\n",
        "        seq_length = x.size(0)\n",
        "\n",
        "        # Add positional embeddings to the input embeddings\n",
        "        x = self.embed(x)* math.sqrt(self.embed_size)\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "        if src_mask is None:\n",
        "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "            \"\"\"\n",
        "            src_mask, src_padding_mask = create_mask(x)\n",
        "\n",
        "        output = self.transformer_encoder(x, src_mask)\n",
        "        logits = self.lm_head(x)\n",
        "        return logits\n",
        "\n",
        "    def forward(self,x,src_mask=None,key_padding_mask=None):\n",
        "\n",
        "        seq_length = x.size(0)\n",
        "\n",
        "        # Add positional embeddings to the input embeddings\n",
        "        x = self.embed(x)* math.sqrt(self.embed_size) #src = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "\n",
        "        if src_mask is None:\n",
        "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "            \"\"\"\n",
        "            src_mask, src_padding_mask = create_mask(x)\n",
        "\n",
        "        output = self.transformer_encoder(x, src_mask,key_padding_mask)\n",
        "        x = self.lm_head(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Ypk4_Gw5ywt",
      "metadata": {
        "id": "5Ypk4_Gw5ywt"
      },
      "source": [
        "### Model configuration and initialization\n",
        "\n",
        "- `ntokens`: # unique tokens in the vocabulary\n",
        "- `emsize`: size of each embedding vector\n",
        "- `nlayers`: # transformer encoder layers\n",
        "- `nhead`: # attention heads\n",
        "- `dropout`: regularization technique to ignore randomly selected neurons during training to prevent overfitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "cSi1ssBZ5vnD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSi1ssBZ5vnD",
        "outputId": "f10289ab-7839-41ff-f1c2-8f68fdbf6455"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "ntokens = len(vocab)  # size of vocabulary\n",
        "emsize = 200  # embedding dimension\n",
        "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
        "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
        "dropout = 0.2  # dropout probability\n",
        "\n",
        "model = CustomGPTModel(embed_size=emsize, num_heads=nhead, num_layers=nlayers, vocab_size=ntokens,dropout=dropout).to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5czGvAzn6ZYR",
      "metadata": {
        "id": "5czGvAzn6ZYR"
      },
      "source": [
        "### Prompting\n",
        "\n",
        "Prompt: starting point for the model to generate text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "_Fr3Dwag6HTU",
      "metadata": {
        "id": "_Fr3Dwag6HTU"
      },
      "outputs": [],
      "source": [
        "def encode_prompt(prompt, block_size=BLOCK_SIZE):\n",
        "    # Handle None prompt\n",
        "    while prompt is None:\n",
        "        prompt = input(\"Sorry, prompt cannot be empty. Please enter a valid prompt: \")\n",
        "\n",
        "    tokens = tokenizer(prompt)\n",
        "    number_of_tokens = len(tokens)\n",
        "\n",
        "    # Handle long prompts\n",
        "    if number_of_tokens > block_size:\n",
        "        tokens = tokens[-block_size:]  # Keep last block_size characters\n",
        "\n",
        "    prompt_indices = vocab(tokens)\n",
        "    prompt_encoded = torch.tensor(prompt_indices, dtype=torch.int64).reshape(-1, 1)\n",
        "    return prompt_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "IijibOHh6kdv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IijibOHh6kdv",
        "outputId": "4f7fd67b-06e7-465e-881f-5e90fb4f3d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sorry, prompt cannot be empty. Please enter a valid prompt: 0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# print(index_to_en(encode_prompt(None)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "OEbNOcw16l0-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEbNOcw16l0-",
        "outputId": "47efb320-8362-4bd5-a1a4-56e57251d750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this is a prompt to get model generate next words .\n"
          ]
        }
      ],
      "source": [
        "print(index_to_en(encode_prompt(\"This is a prompt to get model generate next words.\" ) ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "UNdQkjGM6oab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNdQkjGM6oab",
        "outputId": "824ae042-3d5e-49b7-eb66-59c45accda23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[   15],\n",
              "        [   11],\n",
              "        [    6],\n",
              "        [33700],\n",
              "        [   10],\n",
              "        [   86],\n",
              "        [ 2076],\n",
              "        [ 5673],\n",
              "        [  388],\n",
              "        [  665],\n",
              "        [    3]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_encoded=encode_prompt(\"This is a prompt to get model generate next words.\").to(DEVICE)\n",
        "prompt_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "y9vxOymP6rEY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9vxOymP6rEY",
        "outputId": "8d52b035-90d0-42d1-d089-af07916c280a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 11, 68813])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits = model.decoder(prompt_encoded,src_mask=None).to(DEVICE)\n",
        "logits = logits.transpose(0, 1)\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a7KuXKgT6u5Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7KuXKgT6u5Y",
        "outputId": "a791365e-f566-4996-83db-a5e4d4374fb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 68813])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logit_preiction =logits[:,-1]\n",
        "logit_preiction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "8siF8Co361ts",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8siF8Co361ts",
        "outputId": "69dfe08b-d492-4667-c100-e6dc2b344313"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([15159])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " _, next_word_index = torch.max(logit_preiction, dim=1)\n",
        " next_word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "KG_avLoZ66Ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KG_avLoZ66Ec",
        "outputId": "71463e45-7ba2-43b1-ecf8-9c3a9972a08e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'booed'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index_to_en(next_word_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2rUbCFDI7IW0",
      "metadata": {
        "id": "2rUbCFDI7IW0"
      },
      "source": [
        "## Autoregressive text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "r14ecnUk7IHL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r14ecnUk7IHL",
        "outputId": "a7025d5c-dcdd-45e8-fab1-c0d92a02cab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device for prompt_encoded: torch.Size([5, 1])\n"
          ]
        }
      ],
      "source": [
        "prompt=\"this is the beginning of\"\n",
        "prompt_encoded = encode_prompt(prompt).to(DEVICE)\n",
        "print(\"Device for prompt_encoded:\", prompt_encoded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ANjr8K4O67eK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANjr8K4O67eK",
        "outputId": "1986a838-2b7a-4722-8368-0c28848cd61d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "Shape of logits at step 0: torch.Size([1, 5, 68813])\n",
            "Shape of logit_prediction at step 0: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 0: torch.Size([1, 1])\n",
            "Sequence for step 0: ['this', 'is', 'the', 'beginning', 'of', 'really--who']\n",
            "Shape of prompt_encoded after concatenation at step 0: torch.Size([6, 1])\n",
            " \n",
            "Shape of logits at step 1: torch.Size([1, 6, 68813])\n",
            "Shape of logit_prediction at step 1: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 1: torch.Size([1, 1])\n",
            "Sequence for step 1: ['this', 'is', 'the', 'beginning', 'of', 'really--who', 'flinstones']\n",
            "Shape of prompt_encoded after concatenation at step 1: torch.Size([7, 1])\n",
            " \n",
            "Shape of logits at step 2: torch.Size([1, 7, 68813])\n",
            "Shape of logit_prediction at step 2: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 2: torch.Size([1, 1])\n",
            "Sequence for step 2: ['this', 'is', 'the', 'beginning', 'of', 'really--who', 'flinstones', 'injuring']\n",
            "Shape of prompt_encoded after concatenation at step 2: torch.Size([8, 1])\n",
            " \n",
            "Shape of logits at step 3: torch.Size([1, 8, 68813])\n",
            "Shape of logit_prediction at step 3: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 3: torch.Size([1, 1])\n",
            "Sequence for step 3: ['this', 'is', 'the', 'beginning', 'of', 'really--who', 'flinstones', 'injuring', 'masterful']\n",
            "Shape of prompt_encoded after concatenation at step 3: torch.Size([9, 1])\n",
            " \n",
            "Shape of logits at step 4: torch.Size([1, 9, 68813])\n",
            "Shape of logit_prediction at step 4: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 4: torch.Size([1, 1])\n",
            "Sequence for step 4: ['this', 'is', 'the', 'beginning', 'of', 'really--who', 'flinstones', 'injuring', 'masterful', 'donna-reed']\n",
            "Shape of prompt_encoded after concatenation at step 4: torch.Size([10, 1])\n",
            " \n",
            "Shape of logits at step 5: torch.Size([1, 10, 68813])\n",
            "Shape of logit_prediction at step 5: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 5: torch.Size([1, 1])\n",
            "Sequence for step 5: ['this', 'is', 'the', 'beginning', 'of', 'really--who', 'flinstones', 'injuring', 'masterful', 'donna-reed', 'mueller-stahl']\n",
            "Shape of prompt_encoded after concatenation at step 5: torch.Size([11, 1])\n",
            " \n",
            "Shape of logits at step 6: torch.Size([1, 11, 68813])\n",
            "Shape of logit_prediction at step 6: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 6: torch.Size([1, 1])\n",
            "Sequence for step 6: ['this', 'is', 'the', 'beginning', 'of', 'really--who', 'flinstones', 'injuring', 'masterful', 'donna-reed', 'mueller-stahl', 'outings']\n",
            "Shape of prompt_encoded after concatenation at step 6: torch.Size([12, 1])\n",
            " \n",
            "Shape of logits at step 7: torch.Size([1, 12, 68813])\n",
            "Shape of logit_prediction at step 7: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 7: torch.Size([1, 1])\n",
            "Sequence for step 7: ['this', 'is', 'the', 'beginning', 'of', 'really--who', 'flinstones', 'injuring', 'masterful', 'donna-reed', 'mueller-stahl', 'outings', '$136']\n",
            "Shape of prompt_encoded after concatenation at step 7: torch.Size([13, 1])\n",
            " \n",
            "Shape of logits at step 8: torch.Size([1, 13, 68813])\n",
            "Shape of logit_prediction at step 8: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 8: torch.Size([1, 1])\n",
            "Sequence for step 8: ['this', 'is', 'the', 'beginning', 'of', 'really--who', 'flinstones', 'injuring', 'masterful', 'donna-reed', 'mueller-stahl', 'outings', '$136', '22-or-so']\n",
            "Shape of prompt_encoded after concatenation at step 8: torch.Size([14, 1])\n",
            " \n",
            "Shape of logits at step 9: torch.Size([1, 14, 68813])\n",
            "Shape of logit_prediction at step 9: torch.Size([1, 68813])\n",
            "Shape of next_token_encoded at step 9: torch.Size([1, 1])\n",
            "Sequence for step 9: ['this', 'is', 'the', 'beginning', 'of', 'really--who', 'flinstones', 'injuring', 'masterful', 'donna-reed', 'mueller-stahl', 'outings', '$136', '22-or-so', 'handycam']\n",
            "Shape of prompt_encoded after concatenation at step 9: torch.Size([15, 1])\n"
          ]
        }
      ],
      "source": [
        "max_new_tokens=10\n",
        "\n",
        "for i in range(max_new_tokens):\n",
        "    logits = model.decoder(prompt_encoded,src_mask=None)\n",
        "    logits = logits.transpose(0, 1)\n",
        "    print(\" \")\n",
        "    print(f\"Shape of logits at step {i}: {logits.shape}\")\n",
        "\n",
        "    logit_preiction = logits[:, -1]\n",
        "    print(f\"Shape of logit_prediction at step {i}: {logit_preiction.shape}\")\n",
        "\n",
        "    next_token_encoded = torch.argmax(logit_preiction, dim=-1).reshape(-1, 1)\n",
        "    print(f\"Shape of next_token_encoded at step {i}: {next_token_encoded.shape}\")\n",
        "\n",
        "    prompt_encoded = torch.cat((prompt_encoded, next_token_encoded), dim=0).to(DEVICE)\n",
        "    print(f\"Sequence for step {i}: {[index_to_en(j) for j in prompt_encoded]}\")\n",
        "    print(f\"Shape of prompt_encoded after concatenation at step {i}: {prompt_encoded.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "cCtuaM4T6_u_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCtuaM4T6_u_",
        "outputId": "2b52fdc9-84b2-4706-c72e-e5fba0d030b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, EOS_IDX = 0, 1, 2\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<|endoftext|>' ]\n",
        "BLOCK_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "iP22l4_x7nf3",
      "metadata": {
        "id": "iP22l4_x7nf3"
      },
      "outputs": [],
      "source": [
        "#auto-regressive Language Model text generation\n",
        "def generate(model, prompt=None, max_new_tokens=500, block_size=BLOCK_SIZE, vocab=vocab, tokenizer=tokenizer):\n",
        "    # Move model to the specified device (e.g., GPU or CPU)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # Encode the input prompt using the provided encode_prompt function\n",
        "    prompt_encoded = encode_prompt(prompt).to(DEVICE)\n",
        "    tokens = []\n",
        "\n",
        "    # Generate new tokens up to max_new_tokens\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Decode the encoded prompt using the model's decoder\n",
        "        logits = model(prompt_encoded,src_mask=None,key_padding_mask=None)\n",
        "\n",
        "        # Transpose the logits to bring the sequence length to the first dimension\n",
        "        logits = logits.transpose(0, 1)\n",
        "\n",
        "        # Select the logits of the last token in the sequence\n",
        "        logit_prediction = logits[:, -1]\n",
        "\n",
        "        # Choose the most probable next token from the logits(greedy decoding)\n",
        "        next_token_encoded = torch.argmax(logit_prediction, dim=-1).reshape(-1, 1)\n",
        "\n",
        "        # If the next token is the end-of-sequence (EOS) token, stop generation\n",
        "        if next_token_encoded.item() == EOS_IDX:\n",
        "            break\n",
        "\n",
        "        # Append the next token to the prompt_encoded and keep only the last 'block_size' tokens\n",
        "        prompt_encoded = torch.cat((prompt_encoded, next_token_encoded), dim=0)[-block_size:]\n",
        "\n",
        "        # Convert the next token index to a token string using the vocabulary\n",
        "        # Move the tensor back to CPU for vocab lookup if needed\n",
        "        token_id = next_token_encoded.to('cpu').item()\n",
        "        tokens.append(vocab.get_itos()[token_id])\n",
        "\n",
        "    # Join the generated tokens into a single string and return\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "u52fuxyj7oZ2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "u52fuxyj7oZ2",
        "outputId": "59508b49-bdf0-4a18-96e3-b326df61ae3a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'moroni **spoilers sequined name-homages high-story hurt sleep haystack demofilo point-they allende ridiculously-timed vietnamese poverty low caridad seize flame-throwing marriages trickle legions paradox chainsmoking willims raubal propelling kato dictate sharply cloth'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate(model,prompt=\"this is the beginning of\",max_new_tokens=30,vocab=vocab,tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TOSZ98lW8P1W",
      "metadata": {
        "id": "TOSZ98lW8P1W"
      },
      "source": [
        "### Decoding the differences: Training vs. inference\n",
        "\n",
        "- Training: using ground truth (\"teacher forcing\")\n",
        "- Interence: use previous predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "f7tF-JEx7qdB",
      "metadata": {
        "id": "f7tF-JEx7qdB"
      },
      "outputs": [],
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "loss_fn = CrossEntropyLoss(ignore_index=PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "Bx5712Dq89zt",
      "metadata": {
        "id": "Bx5712Dq89zt"
      },
      "outputs": [],
      "source": [
        "src,tgt=next(iter(dataloader))\n",
        "\n",
        "mask,padding_mask = create_mask(src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "w_uTUXCW8_pN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_uTUXCW8_pN",
        "outputId": "aa0cfdf1-a3ad-488c-bc2d-7fdc15af0755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 1, 68813])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "logits = model(src,src_mask=mask,key_padding_mask=padding_mask)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "74-JfxnT9COW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74-JfxnT9COW",
        "outputId": "b06b9c5c-963c-4622-a9f5-859550261ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output shape torch.Size([30, 1, 68813])\n",
            "source shape  tensor([[  137],\n",
            "        [    5],\n",
            "        [   22],\n",
            "        [ 2420],\n",
            "        [ 1191],\n",
            "        [ 2033],\n",
            "        [    3],\n",
            "        [   14],\n",
            "        [  203],\n",
            "        [    9],\n",
            "        [  198],\n",
            "        [    5],\n",
            "        [    4],\n",
            "        [  206],\n",
            "        [   19],\n",
            "        [   11],\n",
            "        [   69],\n",
            "        [ 1191],\n",
            "        [    5],\n",
            "        [   74],\n",
            "        [   11],\n",
            "        [  117],\n",
            "        [   13],\n",
            "        [   59],\n",
            "        [    8],\n",
            "        [   24],\n",
            "        [  291],\n",
            "        [13237],\n",
            "        [   12],\n",
            "        [   88]])\n"
          ]
        }
      ],
      "source": [
        "print(\"output shape\",logits.shape)\n",
        "print(\"source shape \",src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "M1XrYveR9D3I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1XrYveR9D3I",
        "outputId": "398b4a66-6dfe-412b-c362-ad5333ceae04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 1])\n",
            "torch.Size([30, 68813])\n",
            "torch.Size([30])\n"
          ]
        }
      ],
      "source": [
        "# drop the the first sample of the target\n",
        "tgt\n",
        "print(tgt.shape)\n",
        "print(logits.reshape(-1, logits.shape[-1]).shape)\n",
        "print(tgt.reshape(-1).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "OSVIBgBf9Tk9",
      "metadata": {
        "id": "OSVIBgBf9Tk9"
      },
      "outputs": [],
      "source": [
        "def evaluate(model: nn.Module, eval_data) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    with torch.no_grad():\n",
        "        for src,tgt in eval_data:\n",
        "            tgt = tgt.to(DEVICE)\n",
        "            #seq_len = src.size(0)\n",
        "            logits = model(src,src_mask=None,key_padding_mask=None)\n",
        "            total_loss +=  loss_fn(logits.reshape(-1, logits.shape[-1]), tgt.reshape(-1)).item()\n",
        "    return total_loss / (len(list(eval_data)) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "VZmTTlQg9VFU",
      "metadata": {
        "id": "VZmTTlQg9VFU"
      },
      "outputs": [],
      "source": [
        "# evaluate(model,val_dataloader) # NOTE: this takes a long time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7yRF144V9bNt",
      "metadata": {
        "id": "7yRF144V9bNt"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "(Only if you have GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b9lDyoL5F7mZ",
      "metadata": {
        "id": "b9lDyoL5F7mZ"
      },
      "outputs": [],
      "source": [
        "# from torch.optim import Adam\n",
        "\n",
        "# optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.01, betas=(0.9, 0.999))\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10000, gamma=0.9)\n",
        "\n",
        "# def train(model: nn.Module,train_data) -> None:\n",
        "#     model.train()  # turn on train mode\n",
        "#     total_loss = 0.\n",
        "#     log_interval = 10000\n",
        "#     start_time = time.time()\n",
        "\n",
        "#     num_batches = len(list(train_data)) // block_size\n",
        "#     for batch,srctgt in enumerate(train_data):\n",
        "#         src= srctgt[0]\n",
        "#         tgt= srctgt[1]\n",
        "#         logits = model(src,src_mask=None)\n",
        "#         logits_flat = logits.reshape(-1, logits.shape[-1])\n",
        "#         loss = loss_fn(logits_flat, tgt.reshape(-1))\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item()\n",
        "\n",
        "#         if (batch % log_interval == 0 and batch > 0) or batch==42060:\n",
        "#             lr = scheduler.get_last_lr()[0]\n",
        "#             ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "#             #cur_loss = total_loss / log_interval\n",
        "#             cur_loss = total_loss / batch\n",
        "#             ppl = math.exp(cur_loss)\n",
        "#             print(f'| epoch {epoch:3d} | {batch//block_size:5d}/{num_batches:5d} batches | '\n",
        "#                   f'lr {lr:02.4f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "#                   f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "#             start_time = time.time()\n",
        "\n",
        "#     return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "qMNUHcno9V91",
      "metadata": {
        "id": "qMNUHcno9V91"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "\n",
        "# best_val_loss = float('inf')\n",
        "# epochs = 30\n",
        "# Train_losses= []\n",
        "# Val_losses = []\n",
        "# for epoch in range(1, epochs + 1):\n",
        "#     epoch_start_time = time.time()\n",
        "#     train_loss = train(model,dataloader)\n",
        "#     val_loss = evaluate(model, val_dataloader)\n",
        "#     val_ppl = math.exp(val_loss)\n",
        "#     Train_losses.append(train_loss)\n",
        "#     Val_losses.append(val_loss)\n",
        "\n",
        "#     elapsed = time.time() - epoch_start_time\n",
        "#     print('-' * 89)\n",
        "#     print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "#         f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "#     print('-' * 89)\n",
        "\n",
        "#     if val_loss < best_val_loss:\n",
        "#         best_val_loss = val_loss\n",
        "#         torch.save(model.state_dict(), 'model_best_val_loss.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "RwqEA0d69eo2",
      "metadata": {
        "id": "RwqEA0d69eo2"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Calculate the number of epochs (assuming the lengths of train_losses and val_losses are equal)\n",
        "# num_epochs = len(Train_losses)\n",
        "\n",
        "# # Create a figure and a set of subplots\n",
        "# fig, ax = plt.subplots()\n",
        "\n",
        "# # Plot the training losses\n",
        "# ax.plot(range(num_epochs), Train_losses, label='Training Loss', color='blue')\n",
        "\n",
        "# # Plot the validation losses\n",
        "# ax.plot(range(num_epochs), Val_losses, label='Validation Loss', color='orange')\n",
        "\n",
        "# # Set the x-axis label\n",
        "# ax.set_xlabel('Epoch')\n",
        "\n",
        "# # Set the y-axis label\n",
        "# ax.set_ylabel('Loss')\n",
        "\n",
        "# # Set the title of the plot\n",
        "# ax.set_title('Training and Validation Losses')\n",
        "\n",
        "# # Add a legend to the plot\n",
        "# ax.legend()\n",
        "\n",
        "# # Show the plot\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pVX5BUuQIxeI",
      "metadata": {
        "id": "pVX5BUuQIxeI"
      },
      "source": [
        "## Loading the saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "ze4Lc8e8IxGF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze4Lc8e8IxGF",
        "outputId": "5c72594c-e9e1-48f3-e8ab-dc5825ce32f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-04-10 19:59:00--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/kyn1_OsXrzjef0xihlsXmg.pt\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122251138 (117M) [binary/octet-stream]\n",
            "Saving to: ‘kyn1_OsXrzjef0xihlsXmg.pt.1’\n",
            "\n",
            "kyn1_OsXrzjef0xihls 100%[===================>] 116.59M  26.3MB/s    in 5.0s    \n",
            "\n",
            "2025-04-10 19:59:06 (23.5 MB/s) - ‘kyn1_OsXrzjef0xihlsXmg.pt.1’ saved [122251138/122251138]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/kyn1_OsXrzjef0xihlsXmg.pt'\n",
        "model.load_state_dict(torch.load('kyn1_OsXrzjef0xihlsXmg.pt',map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "6eyDwRI4GBiK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eyDwRI4GBiK",
        "outputId": "42fd4b3f-dc39-48d7-85d4-2c6494e74d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "paid what makes for making such a flashback for making\n"
          ]
        }
      ],
      "source": [
        "print(generate(model,prompt=\"the movie was\",max_new_tokens=10,vocab=vocab,tokenizer=tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_6lgIqClI8uz",
      "metadata": {
        "id": "_6lgIqClI8uz"
      },
      "source": [
        "## Loading GPT2 model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "p8J6N0GdPkhh",
      "metadata": {
        "id": "p8J6N0GdPkhh"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "H-95sVyKI4dj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-95sVyKI4dj",
        "outputId": "7036f83f-bfed-4ae5-c066-21092694b74e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: the movie was\n",
            "Generated Text: the movie was a bit of a disappointment, but it was a great movie\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer1 = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Define the input prompt\n",
        "#input_text = \"Once upon a time in a faraway land,\"\n",
        "input_text = \"the movie was\"\n",
        "\n",
        "# Tokenize the input text and prepare the input for the model\n",
        "input_ids = tokenizer1.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text using the model\n",
        "# Set the desired length of the generated text (max_length),\n",
        "# and other generation parameters like temperature, top_k, and top_p\n",
        "max_length = 15\n",
        "temperature = 0.7\n",
        "top_k = 50\n",
        "top_p = 0.95\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    input_ids,\n",
        "    max_length=max_length,\n",
        "    temperature=temperature,\n",
        "    top_k=top_k,\n",
        "    top_p=top_p,\n",
        "    pad_token_id=tokenizer1.eos_token_id,\n",
        ")\n",
        "\n",
        "# Decode the generated text\n",
        "generated_text = tokenizer1.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the input prompt and the generated text\n",
        "print(f\"Input: {input_text}\")\n",
        "print(f\"Generated Text: {generated_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9azAKHtgSa_-",
      "metadata": {
        "id": "9azAKHtgSa_-"
      },
      "source": [
        "## Exercise: Creating a decoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "o0jOFFQ7I-Ty",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0jOFFQ7I-Ty",
        "outputId": "2dff5db3-538d-4511-cdff-d0bc86be65e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vampire-signature dont britcoms manuel norge meandered demy hibernation arnold-film entropy double-whammy replies methane darwinism rest-stop\n"
          ]
        }
      ],
      "source": [
        "ntokens = len(vocab)\n",
        "emsize = 200\n",
        "nlayers = 2\n",
        "nhead = 2\n",
        "dropout = 0.2\n",
        "\n",
        "model = CustomGPTModel(embed_size=emsize, num_heads=nhead, num_layers=nlayers, vocab_size=ntokens,dropout=dropout).to(DEVICE)\n",
        "\n",
        "print(generate(model,prompt=\"spring is\",max_new_tokens=15,vocab=vocab,tokenizer=tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "TW8Uegy1Sy-A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW8Uegy1Sy-A",
        "outputId": "de81deed-92c6-48ab-a8f8-3020b0284c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip freeze > requirements.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
