{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/03_dataloader/03_dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Custom data set and data loader in PyTorch"
            ],
            "metadata": {
                "id": "k3cHboWITq3X"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# !pip install torchtext==0.15.1\n",
                "# !pip install 'portalocker>=2.0.0'\n",
                "# !python -m spacy download fr_core_news_sm\n",
                "# !python -m spacy download de_core_news_sm"
            ],
            "metadata": {
                "id": "Sla2mb0rowNv"
            },
            "execution_count": 26,
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "A12eBrY0TEgz",
                "outputId": "11421170-8a64-449a-f69b-8d33c087e802"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[\"Fame's a fickle friend, Harry.\", \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\"]\n",
                        "['Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.', 'It is our choices, Harry, that show what we truly are, far more than our abilities.']\n",
                        "['Soon we must all face the choice between what is right and what is easy.', 'You are awesome!']\n"
                    ]
                }
            ],
            "source": [
                "from torch.utils.data import Dataset, DataLoader\n",
                "\n",
                "sentences = [\n",
                "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
                "    \"Fame's a fickle friend, Harry.\",\n",
                "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
                "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
                "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
                "    \"You are awesome!\"\n",
                "]\n",
                "\n",
                "# Define a custom dataset\n",
                "class CustomDataset(Dataset):\n",
                "    def __init__(self, sentences):\n",
                "        self.sentences = sentences\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.sentences)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        return self.sentences[idx]\n",
                "\n",
                "# Create an instance of your custom dataset\n",
                "custom_dataset = CustomDataset(sentences)\n",
                "\n",
                "# Define batch size\n",
                "batch_size = 2\n",
                "\n",
                "# Create a DataLoader\n",
                "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
                "\n",
                "# Iterate through the DataLoader\n",
                "for batch in dataloader:\n",
                "    print(batch)"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Creating tensors for custom data set"
            ],
            "metadata": {
                "id": "HXeWEoxBTzWX"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from torchtext.data.utils import get_tokenizer\n",
                "from torchtext.vocab import build_vocab_from_iterator\n",
                "import torch\n",
                "\n",
                "\n",
                "sentences = [\n",
                "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
                "    \"Fame's a fickle friend, Harry.\",\n",
                "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
                "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
                "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
                "    \"You are awesome!\"\n",
                "]\n",
                "\n",
                "# Define a custom data set\n",
                "class CustomDataset(Dataset):\n",
                "    def __init__(self, sentences, tokenizer, vocab):\n",
                "        self.sentences = sentences\n",
                "        self.tokenizer = tokenizer\n",
                "        self.vocab = vocab\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.sentences)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        tokens = self.tokenizer(self.sentences[idx])\n",
                "        # Convert tokens to tensor indices using vocab\n",
                "        tensor_indices = [self.vocab[token] for token in tokens]\n",
                "        return torch.tensor(tensor_indices)\n",
                "\n",
                "# Tokenizer\n",
                "tokenizer = get_tokenizer(\"basic_english\")\n",
                "\n",
                "# Build vocabulary\n",
                "vocab = build_vocab_from_iterator(map(tokenizer, sentences))\n",
                "\n",
                "# Create an instance of your custom data set\n",
                "custom_dataset = CustomDataset(sentences, tokenizer, vocab)\n",
                "\n",
                "print(\"Custom Dataset Length:\", len(custom_dataset))\n",
                "print(\"Sample Items:\")\n",
                "for i in range(6):\n",
                "    sample_item = custom_dataset[i]\n",
                "    print(f\"Item {i + 1}: {sample_item}\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "OcLg4LdCTLkp",
                "outputId": "0b52b400-b329-44e7-b451-c0e390367d80"
            },
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Custom Dataset Length: 6\n",
                        "Sample Items:\n",
                        "Item 1: tensor([11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
                        "        43, 61,  9, 44,  0, 14,  9, 33,  1])\n",
                        "Item 2: tensor([35,  6, 16,  3, 38, 40,  0,  8,  1])\n",
                        "Item 3: tensor([12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
                        "        21,  1])\n",
                        "Item 4: tensor([54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1])\n",
                        "Item 5: tensor([66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
                        "         2, 12, 64, 17, 26, 65,  1])\n",
                        "Item 6: tensor([19,  4, 25, 20])\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "def collate_fn(batch):\n",
                "    from torch.nn.utils.rnn import pad_sequence\n",
                "\n",
                "    # Pad sequences within the batch to have equal lengths\n",
                "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=0)\n",
                "    return padded_batch\n",
                "\n",
                "# Define batch size\n",
                "batch_size = 2\n",
                "\n",
                "# Create a data loader\n",
                "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
                "\n",
                "# Iterate through the data loader\n",
                "for batch in dataloader:\n",
                "    print(batch)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "6Erj9a8eVVbj",
                "outputId": "570cb02c-38c2-4ac5-91f2-a9e02f00c4a3"
            },
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
                        "         21,  1],\n",
                        "        [19,  4, 25, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
                        "          0,  0]])\n",
                        "tensor([[11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
                        "         43, 61,  9, 44,  0, 14,  9, 33,  1],\n",
                        "        [35,  6, 16,  3, 38, 40,  0,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
                        "          0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
                        "tensor([[66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
                        "          2, 12, 64, 17, 26, 65,  1],\n",
                        "        [54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1,  0,  0,\n",
                        "          0,  0,  0,  0,  0,  0,  0]])\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Iterate through the data loader\n",
                "for batch in dataloader:\n",
                "    for row in batch:\n",
                "        for idx in row:\n",
                "            words = [vocab.get_itos()[idx] for idx in row]\n",
                "        print(words)\n"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "3fqPBW-pXYUj",
                "outputId": "086632dd-7d65-4c03-97ba-9799ec9e6f7b"
            },
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "['if', 'you', 'want', 'to', 'know', 'what', 'a', 'man', \"'\", 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.']\n",
                        "['soon', 'we', 'must', 'all', 'face', 'the', 'choice', 'between', 'what', 'is', 'right', 'and', 'what', 'is', 'easy', '.', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
                        "['youth', 'can', 'not', 'know', 'how', 'age', 'thinks', 'and', 'feels', '.', 'but', 'old', 'men', 'are', 'guilty', 'if', 'they', 'forget', 'what', 'it', 'was', 'to', 'be', 'young', '.']\n",
                        "['fame', \"'\", 's', 'a', 'fickle', 'friend', ',', 'harry', '.', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
                        "['you', 'are', 'awesome', '!', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
                        "['it', 'is', 'our', 'choices', ',', 'harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '.']\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Create a custom collate function\n",
                "def collate_fn_bfFALSE(batch):\n",
                "    from torch.nn.utils.rnn import pad_sequence\n",
                "\n",
                "    # Pad sequences within the batch to have equal lengths\n",
                "    padded_batch = pad_sequence(batch, padding_value=0)\n",
                "    return padded_batch\n",
                "\n",
                "# Create a data loader with the custom collate function with batch_first=True,\n",
                "dataloader_bfFALSE = DataLoader(custom_dataset, batch_size=batch_size, collate_fn=collate_fn_bfFALSE)\n",
                "\n",
                "# Iterate through the data loader\n",
                "for seq in dataloader_bfFALSE:\n",
                "    for row in seq:\n",
                "        #print(row)\n",
                "        words = [vocab.get_itos()[idx] for idx in row]\n",
                "        print(words)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "vDiOLGvEZE6S",
                "outputId": "e16c5030-9fb3-43a6-9d9e-97a109a98585"
            },
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "['if', 'fame']\n",
                        "['you', \"'\"]\n",
                        "['want', 's']\n",
                        "['to', 'a']\n",
                        "['know', 'fickle']\n",
                        "['what', 'friend']\n",
                        "['a', ',']\n",
                        "['man', 'harry']\n",
                        "[\"'\", '.']\n",
                        "['s', ',']\n",
                        "['like', ',']\n",
                        "[',', ',']\n",
                        "['take', ',']\n",
                        "['a', ',']\n",
                        "['good', ',']\n",
                        "['look', ',']\n",
                        "['at', ',']\n",
                        "['how', ',']\n",
                        "['he', ',']\n",
                        "['treats', ',']\n",
                        "['his', ',']\n",
                        "['inferiors', ',']\n",
                        "[',', ',']\n",
                        "['not', ',']\n",
                        "['his', ',']\n",
                        "['equals', ',']\n",
                        "['.', ',']\n",
                        "['it', 'soon']\n",
                        "['is', 'we']\n",
                        "['our', 'must']\n",
                        "['choices', 'all']\n",
                        "[',', 'face']\n",
                        "['harry', 'the']\n",
                        "[',', 'choice']\n",
                        "['that', 'between']\n",
                        "['show', 'what']\n",
                        "['what', 'is']\n",
                        "['we', 'right']\n",
                        "['truly', 'and']\n",
                        "['are', 'what']\n",
                        "[',', 'is']\n",
                        "['far', 'easy']\n",
                        "['more', '.']\n",
                        "['than', ',']\n",
                        "['our', ',']\n",
                        "['abilities', ',']\n",
                        "['.', ',']\n",
                        "['youth', 'you']\n",
                        "['can', 'are']\n",
                        "['not', 'awesome']\n",
                        "['know', '!']\n",
                        "['how', ',']\n",
                        "['age', ',']\n",
                        "['thinks', ',']\n",
                        "['and', ',']\n",
                        "['feels', ',']\n",
                        "['.', ',']\n",
                        "['but', ',']\n",
                        "['old', ',']\n",
                        "['men', ',']\n",
                        "['are', ',']\n",
                        "['guilty', ',']\n",
                        "['if', ',']\n",
                        "['they', ',']\n",
                        "['forget', ',']\n",
                        "['what', ',']\n",
                        "['it', ',']\n",
                        "['was', ',']\n",
                        "['to', ',']\n",
                        "['be', ',']\n",
                        "['young', ',']\n",
                        "['.', ',']\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Iterate through the data loader with batch_first = TRUE\n",
                "for batch in dataloader:\n",
                "    print(batch)\n",
                "    print(\"Length of sequences in the batch:\",batch.shape[1])"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "hPtUxIz4eEBL",
                "outputId": "991aadd8-ca9b-4b0e-e331-2e6cd0a14666"
            },
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1,  0,  0,\n",
                        "          0,  0],\n",
                        "        [12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
                        "         21,  1]])\n",
                        "Length of sequences in the batch: 20\n",
                        "tensor([[35,  6, 16,  3, 38, 40,  0,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
                        "          0,  0,  0,  0,  0,  0,  0],\n",
                        "        [66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
                        "          2, 12, 64, 17, 26, 65,  1]])\n",
                        "Length of sequences in the batch: 25\n",
                        "tensor([[19,  4, 25, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
                        "          0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
                        "        [11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
                        "         43, 61,  9, 44,  0, 14,  9, 33,  1]])\n",
                        "Length of sequences in the batch: 27\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Define a custom data set\n",
                "class CustomDataset(Dataset):\n",
                "    def __init__(self, sentences):\n",
                "        self.sentences = sentences\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.sentences)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        return self.sentences[idx]\n",
                "\n",
                "custom_dataset=CustomDataset(sentences)\n",
                "\n",
                "custom_dataset[0]"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 35
                },
                "id": "8gs1XrSheezn",
                "outputId": "33a95469-6830-4812-f1a4-6ccf13db94f3"
            },
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\""
                        ],
                        "application/vnd.google.colaboratory.intrinsic+json": {
                            "type": "string"
                        }
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "def collate_fn(batch):\n",
                "    from torch.nn.utils.rnn import pad_sequence\n",
                "    # Tokenize each sample in the batch using the specified tokenizer\n",
                "    tensor_batch = []\n",
                "    for sample in batch:\n",
                "        tokens = tokenizer(sample)\n",
                "        # Convert tokens to vocabulary indices and create a tensor for each sample\n",
                "        tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n",
                "\n",
                "    # Pad sequences within the batch to have equal lengths using pad_sequence\n",
                "    # batch_first=True ensures that the tensors have shape (batch_size, max_sequence_length)\n",
                "    padded_batch = pad_sequence(tensor_batch, batch_first=True)\n",
                "\n",
                "    # Return the padded batch\n",
                "    return padded_batch\n",
                "\n",
                "# Create a data loader for the custom dataset\n",
                "dataloader = DataLoader(\n",
                "    dataset=custom_dataset,   # Custom PyTorch Dataset containing your data\n",
                "    batch_size=batch_size,     # Number of samples in each mini-batch\n",
                "    shuffle=True,              # Shuffle the data at the beginning of each epoch\n",
                "    collate_fn=collate_fn      # Custom collate function for processing batches\n",
                ")\n",
                "\n",
                "for batch in dataloader:\n",
                "    print(batch)\n",
                "    print(\"shape of sample\",len(batch))"
            ],
            "metadata": {
                "id": "x42jz4-KniJa",
                "outputId": "b00e2724-195f-493f-fa07-3e7f8f460de6",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1],\n",
                        "        [19,  4, 25, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
                        "shape of sample 2\n",
                        "tensor([[66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
                        "          2, 12, 64, 17, 26, 65,  1],\n",
                        "        [35,  6, 16,  3, 38, 40,  0,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
                        "          0,  0,  0,  0,  0,  0,  0]])\n",
                        "shape of sample 2\n",
                        "tensor([[12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
                        "         21,  1,  0,  0,  0,  0,  0,  0,  0],\n",
                        "        [11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
                        "         43, 61,  9, 44,  0, 14,  9, 33,  1]])\n",
                        "shape of sample 2\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Process French Text"
            ],
            "metadata": {
                "id": "anSlgdYroBn9"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "corpus = [\n",
                "    \"Ceci est une phrase.\",\n",
                "    \"C'est un autre exemple de phrase.\",\n",
                "    \"Voici une troisi\u00e8me phrase.\",\n",
                "    \"Il fait beau aujourd'hui.\",\n",
                "    \"J'aime beaucoup la cuisine fran\u00e7aise.\",\n",
                "    \"Quel est ton plat pr\u00e9f\u00e9r\u00e9 ?\",\n",
                "    \"Je t'adore.\",\n",
                "    \"Bon app\u00e9tit !\",\n",
                "    \"Je suis en train d'apprendre le fran\u00e7ais.\",\n",
                "    \"Nous devons partir t\u00f4t demain matin.\",\n",
                "    \"Je suis heureux.\",\n",
                "    \"Le film \u00e9tait vraiment captivant !\",\n",
                "    \"Je suis l\u00e0.\",\n",
                "    \"Je ne sais pas.\",\n",
                "    \"Je suis fatigu\u00e9 apr\u00e8s une longue journ\u00e9e de travail.\",\n",
                "    \"Est-ce que tu as des projets pour le week-end ?\",\n",
                "    \"Je vais chez le m\u00e9decin cet apr\u00e8s-midi.\",\n",
                "    \"La musique adoucit les m\u0153urs.\",\n",
                "    \"Je dois acheter du pain et du lait.\",\n",
                "    \"Il y a beaucoup de monde dans cette ville.\",\n",
                "    \"Merci beaucoup !\",\n",
                "    \"Au revoir !\",\n",
                "    \"Je suis ravi de vous rencontrer enfin !\",\n",
                "    \"Les vacances sont toujours trop courtes.\",\n",
                "    \"Je suis en retard.\",\n",
                "    \"F\u00e9licitations pour ton nouveau travail !\",\n",
                "    \"Je suis d\u00e9sol\u00e9, je ne peux pas venir \u00e0 la r\u00e9union.\",\n",
                "    \"\u00c0 quelle heure est le prochain train ?\",\n",
                "    \"Bonjour !\",\n",
                "    \"C'est g\u00e9nial !\"\n",
                "]\n",
                "\n",
                "def collate_fn_fr(batch):\n",
                "    from torch.nn.utils.rnn import pad_sequence\n",
                "\n",
                "    # Pad sequences within the batch to have equal lengths\n",
                "    tensor_batch=[]\n",
                "    for sample in batch:\n",
                "        tokens = tokenizer(sample)\n",
                "        tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n",
                "\n",
                "    padded_batch = pad_sequence(tensor_batch,batch_first=True)\n",
                "    return padded_batch\n",
                "\n",
                "# Build tokenizer\n",
                "tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\n",
                "\n",
                "# Build vocabulary\n",
                "vocab = build_vocab_from_iterator(map(tokenizer, corpus))\n",
                "\n",
                "# Sort sentences based on their length\n",
                "sorted_data = sorted(corpus, key=lambda x: len(tokenizer(x)))\n",
                "#print(sorted_data)\n",
                "dataloader = DataLoader(sorted_data, batch_size=4, shuffle=False, collate_fn=collate_fn_fr)\n",
                "\n",
                "for batch in dataloader:\n",
                "    print(batch)"
            ],
            "metadata": {
                "id": "1gpTXK-un1hs",
                "outputId": "a00abe66-f719-4775-c928-a6495ee3cc17",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([[ 27,   2,   0],\n",
                        "        [ 26,  45,   2],\n",
                        "        [ 35,   8,   2],\n",
                        "        [ 25, 101,   2]])\n",
                        "tensor([[  1, 105,  41,   0],\n",
                        "        [  1,   3,  76,   0],\n",
                        "        [  1,   3,  82,   0],\n",
                        "        [ 11,   4,  74,   2]])\n",
                        "tensor([[ 28,   4,  10,   9,   0],\n",
                        "        [ 38,  10, 107,   9,   0],\n",
                        "        [ 12,  69,  51,  49,   0],\n",
                        "        [  1,  16, 103,  17,   0]])\n",
                        "tensor([[  1,   3,  14, 100,   0,   0],\n",
                        "        [ 37,   4,  19,  92,  95,   7],\n",
                        "        [ 33,  71, 122, 117,  52,   2],\n",
                        "        [ 32,  85,  42,  80,  87,   0]])\n",
                        "tensor([[ 30,  18,  19,  88,  21,   2,   0],\n",
                        "        [ 31,  43,   8,  15,  57,  73,   0],\n",
                        "        [ 36,  62,  90, 110,  60,  83,   0],\n",
                        "        [ 34, 112, 104, 106, 108,  56,   0]])\n",
                        "tensor([[ 11,   4, 111,  50,  68,   5,   9,   0],\n",
                        "        [  1, 113,  55,   6,  86,  53,  47,   0],\n",
                        "        [  1,   3,  98,   5, 116,  99,  66,   2],\n",
                        "        [120,  97,  75,   4,   6,  93,  20,   7]])\n",
                        "tensor([[  1,   3,  14,  20,  58,  44,   6,  72,   0,   0],\n",
                        "        [  1,  63,  40,  13,  89,  67,  13,  79,   0,   0],\n",
                        "        [  1,   3,  70,  46,  10,  81,  78,   5,  21,   0],\n",
                        "        [ 12, 119,  39,   8,   5,  84,  59,  54, 115,   0]])\n",
                        "tensor([[ 29,  24,  96, 109,  48,  61,  94,  18,   6, 118,  23,  65,   7],\n",
                        "        [  1,   3,  64,  22,  77,  16,  91,  17, 114, 121,  15, 102,   0]])\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Data loader for German-English translation task"
            ],
            "metadata": {
                "id": "OqAgDKJApBkF"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from torchtext.datasets import multi30k, Multi30k\n",
                "import portalocker\n",
                "\n",
                "multi30k.URL[\"train\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/training.tar.gz\"\n",
                "multi30k.URL[\"valid\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/validation.tar.gz\"\n",
                "\n",
                "SRC_LANGUAGE = 'de'\n",
                "TGT_LANGUAGE = 'en'\n",
                "\n",
                "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
                "\n",
                "data_set = iter(train_iter)\n",
                "print(type(data_set))\n",
                "\n",
                "for n in range(5):\n",
                "    # Getting the next pair of source and target sentences from the training data set\n",
                "    src, tgt = next(data_set)\n",
                "\n",
                "    # Printing the source (German) and target (English) sentences\n",
                "    print(f\"sample {str(n+1)}\")\n",
                "    print(f\"Source ({SRC_LANGUAGE}): {src}\\nTarget ({TGT_LANGUAGE}): {tgt}\")"
            ],
            "metadata": {
                "id": "1tmFmiBJo_Od",
                "outputId": "fdd0e776-8014-4479-96e4-946c3d060fcf",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "<class 'generator'>\n",
                        "sample 1\n",
                        "Source (de): Zwei junge wei\u00dfe M\u00e4nner sind im Freien in der N\u00e4he vieler B\u00fcsche.\n",
                        "Target (en): Two young, White males are outside near many bushes.\n",
                        "sample 2\n",
                        "Source (de): Mehrere M\u00e4nner mit Schutzhelmen bedienen ein Antriebsradsystem.\n",
                        "Target (en): Several men in hard hats are operating a giant pulley system.\n",
                        "sample 3\n",
                        "Source (de): Ein kleines M\u00e4dchen klettert in ein Spielhaus aus Holz.\n",
                        "Target (en): A little girl climbing into a wooden playhouse.\n",
                        "sample 4\n",
                        "Source (de): Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.\n",
                        "Target (en): A man in a blue shirt is standing on a ladder cleaning a window.\n",
                        "sample 5\n",
                        "Source (de): Zwei M\u00e4nner stehen am Herd und bereiten Essen zu.\n",
                        "Target (en): Two men are at the stove preparing food.\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Tokenizer setup"
            ],
            "metadata": {
                "id": "rYIshO4x0R4h"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "german, english = next(data_set)\n",
                "print(f\"Source German ({SRC_LANGUAGE}): {german}\\nTarget English  ({TGT_LANGUAGE}): { english }\")\n",
                "\n",
                "# Making a placeholder dict to store both tokenizers\n",
                "token_transform = {}\n",
                "\n",
                "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
                "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"
            ],
            "metadata": {
                "id": "nfuePBRO0Rdg",
                "outputId": "6692a4ad-29b8-4024-f0f2-62dca0ef0422",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Source German (de): Ein Mann l\u00e4chelt einen ausgestopften L\u00f6wen an.\n",
                        "Target English  (en): A man is smiling at a stuffed lion\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "token_transform['de'](german)"
            ],
            "metadata": {
                "id": "IcRFRB3i0VWe",
                "outputId": "4b83bee3-1236-4ef7-b4c3-86d2b095a995",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['Ein', 'Mann', 'l\u00e4chelt', 'einen', 'ausgestopften', 'L\u00f6wen', 'an', '.']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 14
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "token_transform['en'](english)"
            ],
            "metadata": {
                "id": "8N_QpGxl5HEA",
                "outputId": "d91d552f-312f-432b-f223-d90d89029f1e",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['A', 'man', 'is', 'smiling', 'at', 'a', 'stuffed', 'lion']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 15
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Tokens to indices transformation (Vocab)"
            ],
            "metadata": {
                "id": "nqLConmu5RdV"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Define special symbols and indices\n",
                "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
                "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
                "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
            ],
            "metadata": {
                "id": "AG83CNNM5Kwv"
            },
            "execution_count": 16,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "from typing import Iterable, List\n",
                "\n",
                "#place holder dict for 'en' and 'de' vocab transforms\n",
                "vocab_transform = {}\n",
                "\n",
                "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
                "    # Define a mapping to associate the source and target languages\n",
                "    # with their respective positions in the data samples.\n",
                "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
                "\n",
                "    # Iterate over each data sample in the provided dataset iterator\n",
                "    for data_sample in data_iter:\n",
                "        # Tokenize the data sample corresponding to the specified language\n",
                "        # and yield the resulting tokens.\n",
                "        yield token_transform[language](data_sample[language_index[language]])\n",
                "\n",
                "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
                "    # Training data iterator\n",
                "    train_iterator = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
                "    #To decrease the number of padding tokens, you sort data on the source length to batch similar-length sequences together\n",
                "    sorted_dataset = sorted(train_iterator, key=lambda x: len(x[0].split()))\n",
                "    # Create torchtext's Vocab object\n",
                "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(sorted_dataset, ln),\n",
                "                                                    min_freq=1,\n",
                "                                                    specials=special_symbols,\n",
                "                                                    special_first=True)"
            ],
            "metadata": {
                "id": "If7LOSll5NnH"
            },
            "execution_count": 17,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
                "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
                "  vocab_transform[ln].set_default_index(UNK_IDX)"
            ],
            "metadata": {
                "id": "ADnwxKcQ5SyI"
            },
            "execution_count": 18,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "seq_en=vocab_transform['en'](token_transform['en'](english))\n",
                "print(f\"English text string: {english}\\n English sequence: {seq_en}\")\n",
                "\n",
                "seq_de=vocab_transform['de'](token_transform['de'](german))\n",
                "print(f\"German text string: {german}\\n German sequence: {seq_de}\")\n"
            ],
            "metadata": {
                "id": "Z6r9WkmQ5iSF",
                "outputId": "dfa66921-8868-4a70-f18a-1cbc52db6d95",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "English text string: A man is smiling at a stuffed lion\n",
                        " English sequence: [6, 12, 10, 136, 20, 4, 941, 2599]\n",
                        "German text string: Ein Mann l\u00e4chelt einen ausgestopften L\u00f6wen an.\n",
                        " German sequence: [5, 12, 172, 20, 5082, 4672, 23, 4]\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "# function to add BOS/EOS, flip source sentence and create tensor for input sequence indices\n",
                "def tensor_transform_s(token_ids: List[int]):\n",
                "    return torch.cat((torch.tensor([BOS_IDX]),\n",
                "                      torch.flip(torch.tensor(token_ids), dims=(0,)),\n",
                "                      torch.tensor([EOS_IDX])))\n",
                "\n",
                "# function to add BOS/EOS and create tensor for input sequence indices\n",
                "def tensor_transform_t(token_ids: List[int]):\n",
                "    return torch.cat((torch.tensor([BOS_IDX]),\n",
                "                      torch.tensor(token_ids),\n",
                "                      torch.tensor([EOS_IDX])))"
            ],
            "metadata": {
                "id": "AFyMbc1GrlI5"
            },
            "execution_count": 21,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "seq_en=tensor_transform_s(seq_en)\n",
                "seq_en"
            ],
            "metadata": {
                "id": "Dpllpwl7rwHs",
                "outputId": "b20ea229-6648-49e3-f493-d711935a2bca",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 22,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "tensor([   2, 2599,  941,    4,   20,  136,   10,   12,    6,    3])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 22
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "seq_de=tensor_transform_t(seq_de)\n",
                "seq_de"
            ],
            "metadata": {
                "id": "0hUBNp5Tr1HS",
                "outputId": "dd6e18c9-4a51-41fd-c55b-d3d46a9d148b",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 23,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "tensor([   2,    5,   12,  172,   20, 5082, 4672,   23,    4,    3])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 23
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# helper function to club together sequential operations\n",
                "def sequential_transforms(*transforms):\n",
                "    def func(txt_input):\n",
                "        for transform in transforms:\n",
                "            txt_input = transform(txt_input)\n",
                "        return txt_input\n",
                "    return func\n",
                "\n",
                "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
                "text_transform = {}\n",
                "\n",
                "text_transform[SRC_LANGUAGE] = sequential_transforms(token_transform[SRC_LANGUAGE], #Tokenization\n",
                "                                            vocab_transform[SRC_LANGUAGE], #Numericalization\n",
                "                                            tensor_transform_s) # Add BOS/EOS and create tensor\n",
                "\n",
                "text_transform[TGT_LANGUAGE] = sequential_transforms(token_transform[TGT_LANGUAGE], #Tokenization\n",
                "                                            vocab_transform[TGT_LANGUAGE], #Numericalization\n",
                "                                            tensor_transform_t) # Add BOS/EOS and create tensor\n"
            ],
            "metadata": {
                "id": "BHgXnJONr2lh"
            },
            "execution_count": 24,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Processing data in batches"
            ],
            "metadata": {
                "id": "VXtyezXHr_eu"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# function to collate data samples into batch tensors\n",
                "def collate_fn(batch):\n",
                "    from torch.nn.utils.rnn import pad_sequence\n",
                "    src_batch, tgt_batch = [], []\n",
                "    for src_sample, tgt_sample in batch:\n",
                "        src_sequences = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
                "        src_sequences = torch.tensor(src_sequences, dtype=torch.int64)\n",
                "        tgt_sequences = text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\"))\n",
                "        tgt_sequences = torch.tensor(tgt_sequences, dtype=torch.int64)\n",
                "        src_batch.append(src_sequences)\n",
                "        tgt_batch.append(tgt_sequences)\n",
                "\n",
                "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX,batch_first=True)\n",
                "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX,batch_first=True)\n",
                "\n",
                "    return src_batch.to(device), tgt_batch.to(device)\n",
                "\n",
                "BATCH_SIZE = 4\n",
                "\n",
                "train_iterator = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
                "sorted_train_iterator = sorted(train_iterator, key=lambda x: len(x[0].split()))\n",
                "train_dataloader = DataLoader(sorted_train_iterator, batch_size=BATCH_SIZE, collate_fn=collate_fn,drop_last=True)\n",
                "\n",
                "valid_iterator = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
                "sorted_valid_dataloader = sorted(valid_iterator, key=lambda x: len(x[0].split()))\n",
                "valid_dataloader = DataLoader(sorted_valid_dataloader, batch_size=BATCH_SIZE, collate_fn=collate_fn,drop_last=True)\n",
                "\n",
                "\n",
                "src, trg = next(iter(train_dataloader))\n",
                "src,trg"
            ],
            "metadata": {
                "id": "BgyjD7WTr-Sw",
                "outputId": "18b233e1-e285-4653-fc7f-f9db5c80809e",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "execution_count": 25,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "<ipython-input-25-f1e72d13c2b7>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  src_sequences = torch.tensor(src_sequences, dtype=torch.int64)\n",
                        "<ipython-input-25-f1e72d13c2b7>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  tgt_sequences = torch.tensor(tgt_sequences, dtype=torch.int64)\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(tensor([[    2,     3,     1,     1,     1],\n",
                            "         [    2,  5510,     3,     1,     1],\n",
                            "         [    2,  5510,     3,     1,     1],\n",
                            "         [    2,  1701,     8, 12642,     3]]),\n",
                            " tensor([[   2,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
                            "         [   2, 6650, 4623,  259,  172, 9953,  115,  692, 3428,    5,    3],\n",
                            "         [   2,  216,  110, 3913, 1650, 3823,   71, 2808, 2187,    5,    3],\n",
                            "         [   2,    6, 3398,  202,  109,   37,    3,    1,    1,    1,    1]]))"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 25
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!pip freeze > requirements.txt"
            ],
            "metadata": {
                "id": "ATYMUI_2sKA6"
            },
            "execution_count": 27,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [],
            "metadata": {
                "id": "qaYd-vv6sVvt"
            },
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        },
        "colab": {
            "provenance": [],
            "include_colab_link": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}