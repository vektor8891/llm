{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/03_dataloader/03_dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom data set and data loader in PyTorch"
      ],
      "metadata": {
        "id": "k3cHboWITq3X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A12eBrY0TEgz",
        "outputId": "69c743be-c149-4017-c671-b34450f1240d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\", 'You are awesome!']\n",
            "['Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.', 'Soon we must all face the choice between what is right and what is easy.']\n",
            "['It is our choices, Harry, that show what we truly are, far more than our abilities.', \"Fame's a fickle friend, Harry.\"]\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "sentences = [\n",
        "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
        "    \"Fame's a fickle friend, Harry.\",\n",
        "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
        "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
        "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
        "    \"You are awesome!\"\n",
        "]\n",
        "\n",
        "# Define a custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sentences[idx]\n",
        "\n",
        "# Create an instance of your custom dataset\n",
        "custom_dataset = CustomDataset(sentences)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 2\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "for batch in dataloader:\n",
        "    print(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating tensors for custom data set"
      ],
      "metadata": {
        "id": "HXeWEoxBTzWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torch\n",
        "\n",
        "\n",
        "sentences = [\n",
        "    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n",
        "    \"Fame's a fickle friend, Harry.\",\n",
        "    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n",
        "    \"Soon we must all face the choice between what is right and what is easy.\",\n",
        "    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n",
        "    \"You are awesome!\"\n",
        "]\n",
        "\n",
        "# Define a custom data set\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sentences, tokenizer, vocab):\n",
        "        self.sentences = sentences\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokenizer(self.sentences[idx])\n",
        "        # Convert tokens to tensor indices using vocab\n",
        "        tensor_indices = [self.vocab[token] for token in tokens]\n",
        "        return torch.tensor(tensor_indices)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, sentences))\n",
        "\n",
        "# Create an instance of your custom data set\n",
        "custom_dataset = CustomDataset(sentences, tokenizer, vocab)\n",
        "\n",
        "print(\"Custom Dataset Length:\", len(custom_dataset))\n",
        "print(\"Sample Items:\")\n",
        "for i in range(6):\n",
        "    sample_item = custom_dataset[i]\n",
        "    print(f\"Item {i + 1}: {sample_item}\")"
      ],
      "metadata": {
        "id": "OcLg4LdCTLkp",
        "outputId": "8f42a15c-8746-49c5-b65b-c35bb6e8693d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Dataset Length: 6\n",
            "Sample Items:\n",
            "Item 1: tensor([11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
            "        43, 61,  9, 44,  0, 14,  9, 33,  1])\n",
            "Item 2: tensor([35,  6, 16,  3, 38, 40,  0,  8,  1])\n",
            "Item 3: tensor([12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
            "        21,  1])\n",
            "Item 4: tensor([54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1])\n",
            "Item 5: tensor([66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
            "         2, 12, 64, 17, 26, 65,  1])\n",
            "Item 6: tensor([19,  4, 25, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "    # Pad sequences within the batch to have equal lengths\n",
        "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=0)\n",
        "    return padded_batch\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 2\n",
        "\n",
        "# Create a data loader\n",
        "dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Iterate through the data loader\n",
        "for batch in dataloader:\n",
        "    print(batch)"
      ],
      "metadata": {
        "id": "6Erj9a8eVVbj",
        "outputId": "f2b12888-1d7e-4243-f6ea-dec87bc80997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[35,  6, 16,  3, 38, 40,  0,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
            "         21,  1]])\n",
            "tensor([[11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
            "         43, 61,  9, 44,  0, 14,  9, 33,  1],\n",
            "        [54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
            "tensor([[19,  4, 25, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0],\n",
            "        [66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
            "          2, 12, 64, 17, 26, 65,  1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the data loader\n",
        "for batch in dataloader:\n",
        "    for row in batch:\n",
        "        for idx in row:\n",
        "            words = [vocab.get_itos()[idx] for idx in row]\n",
        "        print(words)\n",
        ""
      ],
      "metadata": {
        "id": "3fqPBW-pXYUj",
        "outputId": "7c3fb7ad-d731-43c3-9814-9cd9077ced63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['you', 'are', 'awesome', '!', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
            "['youth', 'can', 'not', 'know', 'how', 'age', 'thinks', 'and', 'feels', '.', 'but', 'old', 'men', 'are', 'guilty', 'if', 'they', 'forget', 'what', 'it', 'was', 'to', 'be', 'young', '.']\n",
            "['it', 'is', 'our', 'choices', ',', 'harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '.', ',', ',', ',', ',', ',', ',', ',']\n",
            "['if', 'you', 'want', 'to', 'know', 'what', 'a', 'man', \"'\", 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.']\n",
            "['fame', \"'\", 's', 'a', 'fickle', 'friend', ',', 'harry', '.', ',', ',', ',', ',', ',', ',', ',']\n",
            "['soon', 'we', 'must', 'all', 'face', 'the', 'choice', 'between', 'what', 'is', 'right', 'and', 'what', 'is', 'easy', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom collate function\n",
        "def collate_fn_bfFALSE(batch):\n",
        "    from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "    # Pad sequences within the batch to have equal lengths\n",
        "    padded_batch = pad_sequence(batch, padding_value=0)\n",
        "    return padded_batch\n",
        "\n",
        "# Create a data loader with the custom collate function with batch_first=True,\n",
        "dataloader_bfFALSE = DataLoader(custom_dataset, batch_size=batch_size, collate_fn=collate_fn_bfFALSE)\n",
        "\n",
        "# Iterate through the data loader\n",
        "for seq in dataloader_bfFALSE:\n",
        "    for row in seq:\n",
        "        #print(row)\n",
        "        words = [vocab.get_itos()[idx] for idx in row]\n",
        "        print(words)"
      ],
      "metadata": {
        "id": "vDiOLGvEZE6S",
        "outputId": "8f406118-0b16-47ae-f51a-22d6c7a86f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['if', 'fame']\n",
            "['you', \"'\"]\n",
            "['want', 's']\n",
            "['to', 'a']\n",
            "['know', 'fickle']\n",
            "['what', 'friend']\n",
            "['a', ',']\n",
            "['man', 'harry']\n",
            "[\"'\", '.']\n",
            "['s', ',']\n",
            "['like', ',']\n",
            "[',', ',']\n",
            "['take', ',']\n",
            "['a', ',']\n",
            "['good', ',']\n",
            "['look', ',']\n",
            "['at', ',']\n",
            "['how', ',']\n",
            "['he', ',']\n",
            "['treats', ',']\n",
            "['his', ',']\n",
            "['inferiors', ',']\n",
            "[',', ',']\n",
            "['not', ',']\n",
            "['his', ',']\n",
            "['equals', ',']\n",
            "['.', ',']\n",
            "['it', 'soon']\n",
            "['is', 'we']\n",
            "['our', 'must']\n",
            "['choices', 'all']\n",
            "[',', 'face']\n",
            "['harry', 'the']\n",
            "[',', 'choice']\n",
            "['that', 'between']\n",
            "['show', 'what']\n",
            "['what', 'is']\n",
            "['we', 'right']\n",
            "['truly', 'and']\n",
            "['are', 'what']\n",
            "[',', 'is']\n",
            "['far', 'easy']\n",
            "['more', '.']\n",
            "['than', ',']\n",
            "['our', ',']\n",
            "['abilities', ',']\n",
            "['.', ',']\n",
            "['youth', 'you']\n",
            "['can', 'are']\n",
            "['not', 'awesome']\n",
            "['know', '!']\n",
            "['how', ',']\n",
            "['age', ',']\n",
            "['thinks', ',']\n",
            "['and', ',']\n",
            "['feels', ',']\n",
            "['.', ',']\n",
            "['but', ',']\n",
            "['old', ',']\n",
            "['men', ',']\n",
            "['are', ',']\n",
            "['guilty', ',']\n",
            "['if', ',']\n",
            "['they', ',']\n",
            "['forget', ',']\n",
            "['what', ',']\n",
            "['it', ',']\n",
            "['was', ',']\n",
            "['to', ',']\n",
            "['be', ',']\n",
            "['young', ',']\n",
            "['.', ',']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the data loader with batch_first = TRUE\n",
        "for batch in dataloader:\n",
        "    print(batch)\n",
        "    print(\"Length of sequences in the batch:\",batch.shape[1])"
      ],
      "metadata": {
        "id": "hPtUxIz4eEBL",
        "outputId": "40316c86-2d35-47d5-aacf-26c5230f4cc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[19,  4, 25, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0],\n",
            "        [66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n",
            "          2, 12, 64, 17, 26, 65,  1]])\n",
            "Length of sequences in the batch: torch.Size([2, 25])\n",
            "tensor([[54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n",
            "         43, 61,  9, 44,  0, 14,  9, 33,  1]])\n",
            "Length of sequences in the batch: torch.Size([2, 27])\n",
            "tensor([[12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n",
            "         21,  1],\n",
            "        [35,  6, 16,  3, 38, 40,  0,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0]])\n",
            "Length of sequences in the batch: torch.Size([2, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8gs1XrSheezn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}