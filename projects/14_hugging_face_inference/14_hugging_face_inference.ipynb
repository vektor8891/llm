{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/14_hugging_face_inference/14_hugging_face_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "bb51e67b",
            "metadata": {
                "id": "bb51e67b"
            },
            "outputs": [],
            "source": [
                "# !pip install torch\n",
                "# !pip install transformers"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Text classification with DistilBERT"
            ],
            "metadata": {
                "id": "KzD4bOuVy6Be"
            },
            "id": "KzD4bOuVy6Be"
        },
        {
            "cell_type": "code",
            "source": [
                "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
                "\n",
                "# Load the tokenizer and model\n",
                "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
                "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 180,
                    "referenced_widgets": [
                        "a24c807eed544f2d8ca83f8f69b6ea0f",
                        "a70f79fab795487bb2f46a315c3361e9",
                        "6e454e30bcf845228179e57c1c03e7fb",
                        "3da2549b5d4e499d8855c3c2f7bba73a",
                        "ec61ae620056472a9775c62ef25b03d7",
                        "8f5f39ee602444f9890a601c42215c93",
                        "556ee8a9af844b558e9106707cef7941",
                        "18c8bf00410d439690564a3d201004e5",
                        "bf8b81f7ac36405996490319f1085a2e",
                        "2930a419078a47628f6f82584dc07f52",
                        "eacfb331101f4bd6aff104a9c790e115",
                        "9eab82d184dc42a5817f6abe81c914de",
                        "f1ecad3b09cb45439f5c70cf84a9b2f4",
                        "c13257a1434248a1a7e43bd3e2800dfe",
                        "a8ac4b590d2947bb9952a7a8a7d5b608",
                        "c87e3b08b25b4ca2bcd8faaaa838375c",
                        "e7a571faccd44e56a4c88fd9d0af41f3",
                        "1161ba41813a4c3e8945853eb372dc0e",
                        "09829eaa6c6e40e193831b9be988226c",
                        "6c704ed9394f46d8919da39200bda1e1",
                        "5d9491a750154c88b0d74089bd953942",
                        "6bc57fd7a37847dd989b65ef02447faf",
                        "d5b2c414c98948ac8e66655c0e6ed466",
                        "75b98008d102405fbfaa35a62ee1912f",
                        "d3d6b0c3be96471893b8667918ee59b5",
                        "812020a8e80c4dffbd0592ce74f92580",
                        "64f68406252248fdafd9ce6d83c2af07",
                        "02e4fb3f9b86442b8612571ea8ab0b6a",
                        "223f5c3a52db4d8a9bb671008b8d5543",
                        "f41ef29d19154d0faf5b56269e1440bb",
                        "ebd760a96cb84975948af0d5a7bb4172",
                        "67487f39bd974bf5b77e9ee94fcb3d1b",
                        "1e7a5f75375e41908b0d19c95bb08a3a",
                        "3138174801894a7dbde8c5ab0607c7dc",
                        "3b8272ffbcfb48eb8bb42e6ffb396491",
                        "581d78ed7cf44a8e9d187168964276a7",
                        "c1f57423cf63445d9466898f8ce813f1",
                        "a4bcb2c1a939409f9615f844a40fb453",
                        "8c2d3d3b64794b84bf274f89ded1766f",
                        "fb2ecf21f35a4550b940b4d057bbc075",
                        "f2d0cbaa849b45148bdde25a28d74142",
                        "3d1dd06a9b2042aeaa416a5b8cf5903b",
                        "e811d569e0e04c278af3c7ae99af2af1",
                        "00402eb226bb4de7a619147e3d5b5398"
                    ]
                },
                "id": "qNLa7cOEyxzu",
                "outputId": "dc6dc536-c086-49f5-8eee-65916658954b"
            },
            "id": "qNLa7cOEyxzu",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "a24c807eed544f2d8ca83f8f69b6ea0f"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "9eab82d184dc42a5817f6abe81c914de"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "d5b2c414c98948ac8e66655c0e6ed466"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
                        "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "3138174801894a7dbde8c5ab0607c7dc"
                        }
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Preprocess the input text"
            ],
            "metadata": {
                "id": "P0PwspODy83p"
            },
            "id": "P0PwspODy83p"
        },
        {
            "cell_type": "code",
            "source": [
                "# Sample text\n",
                "text = \"Congratulations! You've won a free ticket to the Bahamas. Reply WIN to claim.\"\n",
                "\n",
                "# Tokenize the input text\n",
                "inputs = tokenizer(text, return_tensors=\"pt\")\n",
                "\n",
                "print(inputs)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "5dxxf4WOy9IA",
                "outputId": "ce3392b0-76e1-4e24-beab-d239da7b6f1d"
            },
            "id": "5dxxf4WOy9IA",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{'input_ids': tensor([[  101, 23156,   999,  2017,  1005,  2310,  2180,  1037,  2489,  7281,\n",
                        "          2000,  1996, 17094,  1012,  7514,  2663,  2000,  4366,  1012,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "###  Perform inference"
            ],
            "metadata": {
                "id": "FZiprtXZzPxS"
            },
            "id": "FZiprtXZzPxS"
        },
        {
            "cell_type": "code",
            "source": [
                "import torch\n",
                "\n",
                "# Perform inference\n",
                "with torch.no_grad():\n",
                "    outputs = model(**inputs)\n",
                "\n",
                "# Get the logits\n",
                "logits = outputs.logits\n",
                "logits.shape"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "CExyHpzfzQJU",
                "outputId": "2b9e9862-df0f-4151-bc47-7ca1ebf3564f"
            },
            "id": "CExyHpzfzQJU",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "torch.Size([1, 2])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 6
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Post-process the output"
            ],
            "metadata": {
                "id": "QCK6W0zmzbir"
            },
            "id": "QCK6W0zmzbir"
        },
        {
            "cell_type": "code",
            "source": [
                "# Convert logits to probabilities\n",
                "probs = torch.softmax(logits, dim=-1)\n",
                "\n",
                "# Get the predicted class\n",
                "predicted_class = torch.argmax(probs, dim=-1)\n",
                "\n",
                "# Map the predicted class to the label\n",
                "labels = [\"NEGATIVE\", \"POSITIVE\"]\n",
                "predicted_label = labels[predicted_class]\n",
                "\n",
                "print(f\"Predicted label: {predicted_label}\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "Ie2pPu76zb0a",
                "outputId": "a54df131-ec76-4553-a13c-93ea869bc071"
            },
            "id": "Ie2pPu76zb0a",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Predicted label: POSITIVE\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Text generation with GPT-2"
            ],
            "metadata": {
                "id": "ovINYcHIz1bP"
            },
            "id": "ovINYcHIz1bP"
        },
        {
            "cell_type": "code",
            "source": [
                "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
                "\n",
                "# Load the tokenizer and model\n",
                "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
                "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 276,
                    "referenced_widgets": [
                        "9257e4d6340043278722d5b9f50571ec",
                        "4bf50a85daa54696900a560bcf9961f2",
                        "c355334ac3a34d05a63de9966a35583f",
                        "4e8d849051ad4a83b4cd8308ee229f4f",
                        "d371323226e848d8884c30af83332a42",
                        "fb78acf8b8f5419fb063651548b28754",
                        "de2b4222589b40d2ba591ee1612a791c",
                        "d1df39ac454f4edf95eb07f03e8f8c46",
                        "d605892570394810aa3006e421f40dcf",
                        "f19acfc4f0be4ecda6fef0b78921b140",
                        "04914119c7b1416f85a81ca8f6b78d90",
                        "69457d1e96594b8eab2caf868f5cc3af",
                        "404d7db049ad4cc1bdc3d41f2181cece",
                        "a549da4e1e1648d1a40f69e33125f95b",
                        "ce030b018e844285a897b5b09c7e77f9",
                        "5fff399e185e4b16a521740be09f2e9e",
                        "002be73f8a4d411c93780df670001a45",
                        "61b4c9ce74c1421ba30116042440ee6a",
                        "6631651d70da460f966517249f76ca9d",
                        "0c90a73a034945f992d6c57f7bf48e3b",
                        "13ac7021128d4266a32eaaa92b660c20",
                        "e4038b0dcd9549a49cddfb28c6027210",
                        "3bd6b82b57f64fd0b5a338ecd862c466",
                        "ed65192d54f04dd0b44135deff8c04ac",
                        "25456ce7a2fb4282b31588dfb34409c2",
                        "a5ddf168e4974161af044cece56b0569",
                        "6cbb755236ab4f7385b96061e1bb8928",
                        "592f7f491c4c464ea560c03c21a74891",
                        "39ae9f61134e443a8a4036a765d94444",
                        "d2369647afb444e6a1a2aac55a95531c",
                        "fec030f47d9b496c8e2d203cb63f0d46",
                        "3445063f256348cdae5f4a51a16d6f13",
                        "75b71ae0925e45599bc5e681d4535859",
                        "39a5cd3ea63046e48f89c9f06be8e210",
                        "7501776dd39d461faa3d3d41f56e14ee",
                        "54ac4aab4f99473191d0dd1592d61b53",
                        "c33a9349e59a47d19829e0d595ffb6a0",
                        "c97a7702089844a69f38d90caaafbf80",
                        "edac6f2db7a34ab7b852655bbf68a001",
                        "54fe97994f084466aa55d0bb39c19902",
                        "bad883102f4747fc94b9bfa69060b2a1",
                        "351536fb54ca4321808bb43a64239647",
                        "c62bc54a82d6448ea9da9ec976d3b770",
                        "579cf97361a64d6887d698480eab8ad7",
                        "01ffddbde2644e47b8d2ac8b470f6782",
                        "9c92be2fc8324337bf49ae23c851eaf7",
                        "d141c387a4584202afe57a1c0c70b8f4",
                        "8dcace86dd84485c8c04f748491f39d7",
                        "2e2c5b15291345d9937f55213698265c",
                        "6f63456591624eb688b2da25161911d6",
                        "c541456306d54f5d844c6d506e871e25",
                        "a485f96d399d49a0a6c85811de314c8a",
                        "de2ae72da02c4c1593da7091eea24b78",
                        "b51ea272226345a691751837cf95fc56",
                        "392a19d4e2bd42df88e5e949780e9b50",
                        "7d320d5159ed4a5a961dc141d3011997",
                        "8830a8156bf24355a761d6ba77f907b6",
                        "0586e04d4046414cba55ce3a0db0b5c3",
                        "a89eb8cb287446dea84c024943a528de",
                        "ca0a9ec2b6984f7bb96fb9fa77b4c8fe",
                        "d7cb80ec01194c42b07baca42a4ba8ab",
                        "6d47034107a647d9808433e844152151",
                        "b4d2869c39ab4148905ae711c384f551",
                        "08323526dc6448af8a3b04607f054f34",
                        "4cfe0febe81340288c7dce338d921158",
                        "e6a5ca95a9514ed5b07ceea132acc057",
                        "1b339fddd2fc43db9bc1a95a0396c259",
                        "3529807c1b624df592c73c669c7eed8c",
                        "32a8e72839294c7d8bbbbeddcc3d508a",
                        "824f16f0f9ac4c7f8c1fd2904bd682fb",
                        "d35447a84c9340f58e023b3e22d51807",
                        "5c7add2bccb344f9960f53ed17f92c3d",
                        "0d2662cfee7640e698c22dffd9b8d2ab",
                        "f69c4f7339264bd684711f9cda2e5ebe",
                        "788b43f6864a4730a85cd23a2307c9c4",
                        "98f6df9159cc4ca1bb956a8d37943297",
                        "56198d74ac194306acfd30158a0cd6b1"
                    ]
                },
                "id": "DruegHhyztlz",
                "outputId": "2d519975-0645-43a2-f7d3-68e4f533778a"
            },
            "id": "DruegHhyztlz",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "9257e4d6340043278722d5b9f50571ec"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "69457d1e96594b8eab2caf868f5cc3af"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "3bd6b82b57f64fd0b5a338ecd862c466"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "39a5cd3ea63046e48f89c9f06be8e210"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "01ffddbde2644e47b8d2ac8b470f6782"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
                        "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "7d320d5159ed4a5a961dc141d3011997"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "1b339fddd2fc43db9bc1a95a0396c259"
                        }
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Preprocess the input text  "
            ],
            "metadata": {
                "id": "xH0pR215z_gC"
            },
            "id": "xH0pR215z_gC"
        },
        {
            "cell_type": "code",
            "source": [
                "# Prompt\n",
                "prompt = \"Once upon a time\"\n",
                "\n",
                "# Tokenize the input text\n",
                "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
                "inputs"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "faKWeWzlz3RM",
                "outputId": "5591994e-9d4b-48a1-cd23-9db45a0f3ee6"
            },
            "id": "faKWeWzlz3RM",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'input_ids': tensor([[7454, 2402,  257,  640]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 10
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Perform inference  "
            ],
            "metadata": {
                "id": "3DtpyIwc0ESN"
            },
            "id": "3DtpyIwc0ESN"
        },
        {
            "cell_type": "code",
            "source": [
                "# Generate text\n",
                "output_ids = model.generate(\n",
                "    inputs.input_ids,\n",
                "    attention_mask=inputs.attention_mask,\n",
                "    pad_token_id=tokenizer.eos_token_id,\n",
                "    max_length=50,\n",
                "    num_return_sequences=1\n",
                ")\n",
                "\n",
                "output_ids"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "6by_q2TJ0BQq",
                "outputId": "89ed171d-473d-4551-f0ee-6ba309a14d57"
            },
            "id": "6by_q2TJ0BQq",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "tensor([[7454, 2402,  257,  640,   11,  262,  995,  373,  257, 1295,  286, 1049,\n",
                            "         8737,  290, 1049, 3514,   13,  383,  995,  373,  257, 1295,  286, 1049,\n",
                            "         3514,   11,  290,  262,  995,  373,  257, 1295,  286, 1049, 3514,   13,\n",
                            "          383,  995,  373,  257, 1295,  286, 1049, 3514,   11,  290,  262,  995,\n",
                            "          373,  257]])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 11
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Post-process the output  "
            ],
            "metadata": {
                "id": "Na0Zi0JZ0LrF"
            },
            "id": "Na0Zi0JZ0LrF"
        },
        {
            "cell_type": "code",
            "source": [
                "# Decode the generated text\n",
                "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
                "\n",
                "print(generated_text)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "dKY9dEJF0F-o",
                "outputId": "0647b6db-efc1-4326-8c71-a51695df983e"
            },
            "id": "dKY9dEJF0F-o",
            "execution_count": 12,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Hugging Face `pipeline()` function\n",
                "\n",
                "`pipeline()` function: high-level API to simplify the usage of pretrained models"
            ],
            "metadata": {
                "id": "RkiZskdH0STa"
            },
            "id": "RkiZskdH0STa"
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Example 1: Text classification using `pipeline()`"
            ],
            "metadata": {
                "id": "Qjm7wPgK0q-u"
            },
            "id": "Qjm7wPgK0q-u"
        },
        {
            "cell_type": "code",
            "source": [
                "from transformers import pipeline\n",
                "\n",
                "# Load a general text classification model\n",
                "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
                "\n",
                "# Classify a sample text\n",
                "result = classifier(\"Congratulations! You've won a free ticket to the Bahamas. Reply WIN to claim.\")\n",
                "print(result)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "LNn98TVG0OWV",
                "outputId": "a4fb4cd5-1ffb-4e9c-c252-99e62b799585"
            },
            "id": "LNn98TVG0OWV",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Device set to use cpu\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[{'label': 'POSITIVE', 'score': 0.9997586607933044}]\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Example 2: Language detection using `pipeline()`"
            ],
            "metadata": {
                "id": "ayriamdg01RD"
            },
            "id": "ayriamdg01RD"
        },
        {
            "cell_type": "code",
            "source": [
                "classifier = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")\n",
                "result = classifier(\"Bonjour, comment \u00e7a va?\")\n",
                "print(result)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 313,
                    "referenced_widgets": [
                        "91e931b444d440889e767bbee67a6320",
                        "1e0152dfee3e4c53bcf99d8a1c140aaa",
                        "8f6254ce34fa45599ba917c08b1e3631",
                        "1647fdb486ab4278b152878b6456159b",
                        "2698304cff6742e592ed40b458a15f15",
                        "24652b5d8a7f45b78ab49471c1131117",
                        "4e9587da85f4442c852ded0582cbd61c",
                        "53e0b4f2e05c4340a17b5fce4ad329f0",
                        "4ac0ec0f7b784cebadf5d75a02006f91",
                        "21596954e97348148988365f9a734506",
                        "88d22cc39b6d4d96bec70114dc1bc104",
                        "b39600a013764bc8b9acc433e1aa78f6",
                        "de3070658b81456a8744d00d0d11bcff",
                        "9bf605c98cd14d1dbf29ec9ed779482f",
                        "f1b5809e7378400ca22b25f20546edb3",
                        "8112087520b849cd886bf656719a835f",
                        "975e05a695754bd18a98c0b9068eda42",
                        "17ea79bce92d45ad97c00aac82ca5c96",
                        "863cdd9ef4914cb5ac3e2bcbdde4a229",
                        "a7ec23599bb84af7b4d83729b0d14e34",
                        "0c425ddfca6d4c8384940cbc65d7b688",
                        "90babee63c584561a3be0a4091188225",
                        "70277f2ce2de421fa2313b5eaf64dd32",
                        "42a6c58af9ae41c0b226fe363694eddb",
                        "ef565bb471c14bff8c95aa77256491bc",
                        "4d4cfe728d72483c93ebc3fb69748682",
                        "fbe26aff9c2b4b2f9e82b6761857a4b6",
                        "9e2f006f6c114922b9d72d73532437d3",
                        "864832e0b3134a949ad978526f40d687",
                        "7ca386637ce842f7b1ad3e4b4ee6bc0b",
                        "ebfbf0aacf244cf6bba07d0c31d3d3a7",
                        "2f3145aaa7b04a10bec1843ee7a4567f",
                        "43b70309d3584b96ac057a80eb961a10",
                        "d4f2510a799d4069bf8ea83fa7e3dd50",
                        "2375356b830f46c7aa5e82a0ab8c82d3",
                        "bd7ef46d7cbe49b1b20c26daef25dec5",
                        "d717595de15043aeb06659374663aa52",
                        "c789b36962364bf284fbdb9f5332b643",
                        "25b2d756fa554622a8ccc9acca063fbb",
                        "1edb4c8cde744a819c74ee78c84239c6",
                        "7c90f903ee234b0ab545768cc67526ce",
                        "cdeb1a64de3649449cb98ce55b68fe87",
                        "404a18f291634480ab5f4b1d46e7a3b5",
                        "01f222cc84a54d85a3c64668864ce831",
                        "4e42e223411a4b58bba2e5ee94749c90",
                        "f1b49f86fe10481b9f812078fecf1e1e",
                        "4d466666d87e4d07a207f3ef64f8662d",
                        "c630cdd9e6794a9fbbbe6f44262c6e4f",
                        "3f1302b0e15442a49217692d38cbf4cc",
                        "54a85c61c69546c28d8f8cf0618d5e0f",
                        "76419e829bbc46568df97649d29aeb04",
                        "588434f6e169416eb3ffdf99282bb6be",
                        "c42769625d4b4ea89d5d4e2fd54a60bc",
                        "b86450b7fdf54cf7882d2067c54a38e0",
                        "88b4c90e0afa48828cb9f378ba843fca",
                        "7b8de967137f488e986a3d424f4218ad",
                        "5b8e8cdaa417473b81f4fd4501e4d334",
                        "081fb29677da44859eb22c2b02b414e6",
                        "256c29e964004a289b8bb957cb08137e",
                        "d987942ad8584540a0c86e5d00b2636a",
                        "23ff83a39d054c14a99a761de17cfe0d",
                        "dc284dee1ac943c5890390fb4efe5afe",
                        "2385fd642664472a9e85f28f39fd872f",
                        "ab54fe1f6d23468a9ba2396269acd435",
                        "6b2586f3239c479892347bf36a2d2d71",
                        "76d5164e45ba40e3b4605c4dff1e454e"
                    ]
                },
                "id": "_ByQM9DM0uqF",
                "outputId": "762fc1e6-ab5d-4893-a244-f4a3d208a4a6"
            },
            "id": "_ByQM9DM0uqF",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "91e931b444d440889e767bbee67a6320"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
                        "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "b39600a013764bc8b9acc433e1aa78f6"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "70277f2ce2de421fa2313b5eaf64dd32"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
                        "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "d4f2510a799d4069bf8ea83fa7e3dd50"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "4e42e223411a4b58bba2e5ee94749c90"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "7b8de967137f488e986a3d424f4218ad"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Device set to use cpu\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[{'label': 'fr', 'score': 0.9934879541397095}]\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Example 3: Text generation using `pipeline()`"
            ],
            "metadata": {
                "id": "2o0aj2j21APg"
            },
            "id": "2o0aj2j21APg"
        },
        {
            "cell_type": "code",
            "source": [
                "# Initialize the text generation pipeline with GPT-2\n",
                "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
                "\n",
                "# Generate text based on a given prompt\n",
                "prompt = \"Once upon a time\"\n",
                "result = generator(prompt, max_length=50, num_return_sequences=1, truncation=True)\n",
                "\n",
                "# Print the generated text\n",
                "print(result[0]['generated_text'])"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "DE71K3dW03y_",
                "outputId": "d3536b95-6d56-48c8-cc21-9bf03654f5e9"
            },
            "id": "DE71K3dW03y_",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Device set to use cpu\n",
                        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Once upon a time, the word was \"the right kind of word\" and then it was \"not so good.\"\n",
                        "\n",
                        "Here is the passage for the other version of the idea: If we were to change the word from \"the right kind\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Example 4: Text generation using T5 with `pipeline()`"
            ],
            "metadata": {
                "id": "OQRDreIX1MDY"
            },
            "id": "OQRDreIX1MDY"
        },
        {
            "cell_type": "code",
            "source": [
                "# Initialize the text generation pipeline with T5\n",
                "generator = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
                "\n",
                "# Generate text based on a given prompt\n",
                "prompt = \"translate English to French: How are you?\"\n",
                "result = generator(prompt, max_length=50, num_return_sequences=1)\n",
                "\n",
                "# Print the generated text\n",
                "print(result[0]['generated_text'])"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 278,
                    "referenced_widgets": [
                        "cb1b9e7d626a4071a9ebd2fe76e465eb",
                        "e9f17f50a566404aa1bc150642a57406",
                        "dd8c0cdf7fbc4ddbb7b3be917175835a",
                        "1c2ba55751e54652a0e0e27e92652742",
                        "c471093392034c1c8efd2bd46755ffd8",
                        "72bf486d466d4f22b44ea6a29622d124",
                        "86a222620b324463b3b48421ba54868b",
                        "2ea17cc44e6e42cd8b1b9c6ded31a936",
                        "82634a6974d8487985c68da1ab12a75d",
                        "3d6329b6e30e412ba25ca6600f0d0526",
                        "f09aaf5bd4554f1da435d02dd2fee0f3",
                        "7cc293a59a274bb4b66c1bfbb12d592b",
                        "3e472c0d9ba44ecb87a5c1649dcbfeb7",
                        "2712630c6800421b8c0d4718ecf8dcd5",
                        "ba3542669d7d444497095d3853136387",
                        "1fc793564e2a4086aa191e3d3a804313",
                        "f6980e693f2c4e0fac7017cebc7a6dc6",
                        "a8c6b313928044ac8bcf6dbcbfde3585",
                        "4b7cdcb35961415f80eb49c34e62cdec",
                        "380ca198cc8f4c47b0448ecf6c408c4d",
                        "cf29f46fcb72437fbf825676ab6fc27c",
                        "8ba81c06a0b0482b9d77581182fa16f6",
                        "e0677d658e71429b8826516223a5fd57",
                        "a5f2278963e6451fbf5ebada82f2e186",
                        "06601b1e008249c091c094394b82e761",
                        "bb65ce436431424787d34a78c013d482",
                        "6e86fd138fef4aea8af6030b15d68f65",
                        "01460ae1714840309760e2c6285795cf",
                        "bf132b6ac8494142a907ba5f87a41d64",
                        "86bbc55c667e4fb9a932f75770c71f54",
                        "33655ef591464d53bbd2f47f8685c805",
                        "e1ebb30dbae64d1dbbec98a710454abe",
                        "667ad0fcc6f04e27aba242ecc2d947f3",
                        "bd9e394b8e9f42b9ac58235924e3df21",
                        "0be0c9f8fa594881a6c9b8e05f6a8260",
                        "56dd1af98e624dee8d8186297ad5d944",
                        "d1a804b864594809a6fbc4c914571e2e",
                        "fe3a3d0091754333b518e2688d00b817",
                        "b39e71e381124d17b2f7f0ae1800a0cf",
                        "4f7a3d555aa7494f97b6973ef578a2e8",
                        "5430cf7303504e53a5d996a9938911d0",
                        "531ac3900c62419b9529a32b04d7cb7b",
                        "cfe4bf12a24c490fa868614f678a5c20",
                        "49c0cbaa00544f5baff60fa9f0a9ce5e",
                        "22b7b68223fe4023acfdd1b89ce4c8c8",
                        "2e725bf6b2574a718292d64d1fc5d1be",
                        "52f8115e9c7545ccb5de266a518abbc2",
                        "8dde91fbb4f9476ab0e642f3bb3a2595",
                        "60d5be0c25e84b60b9075642753e5de3",
                        "819acff5dc3b448e8f8074c3f38b68c9",
                        "ea1cc9c38975456ab92895c535e29e4a",
                        "a63ee70fab434294ac2e0086bbde36f8",
                        "577b297d05804c2bb8386d83d9ddcd54",
                        "9a92d1fd2605473b962d50c57f34cfdd",
                        "3c4433f3ac8b4534bc592e54b992ffe2",
                        "8c7ede7a5f8f48328b83883cc7d75deb",
                        "88230238a23c48a0aa96225c973aac29",
                        "4d3f30fcda7c42baa9eeb2c00081d280",
                        "f1709350102844199e0ed41692629a48",
                        "49b47519ba1a42d4ac39ac94b7955bec",
                        "0b0111462cf24fd7a9a00474573359e5",
                        "62d4b4e6248f419d93fb7a6d55d798a1",
                        "92957b5428404a37a3d5f8ae96648b1e",
                        "967e35e7c2484b6f8b27eee92b5ddfc2",
                        "4705ff0ed0494beeaa01b18ca633adbc",
                        "d0006b4146a344bb877df7a34472fcc8"
                    ]
                },
                "id": "d5nNY10S1FIZ",
                "outputId": "34861304-875d-4b77-cb5b-8d9ef7d9fb25"
            },
            "id": "d5nNY10S1FIZ",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "cb1b9e7d626a4071a9ebd2fe76e465eb"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
                        "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "7cc293a59a274bb4b66c1bfbb12d592b"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "e0677d658e71429b8826516223a5fd57"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "bd9e394b8e9f42b9ac58235924e3df21"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "22b7b68223fe4023acfdd1b89ce4c8c8"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "8c7ede7a5f8f48328b83883cc7d75deb"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Device set to use cpu\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Comment \u00eates-vous?\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Exercise: Fill-mask task using BERT with `pipeline()`"
            ],
            "metadata": {
                "id": "wUzq_7go1g5D"
            },
            "id": "wUzq_7go1g5D"
        },
        {
            "cell_type": "code",
            "source": [
                "# Initialize the fill-mask pipeline with BERT\n",
                "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
                "\n",
                "# Generate text by filling in the masked token\n",
                "prompt = \"The capital of France is [MASK].\"\n",
                "result = fill_mask(prompt)\n",
                "\n",
                "# Print the generated text\n",
                "print(result)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 318,
                    "referenced_widgets": [
                        "68aa59c7325d4b6fbde0dc45d64dcc4e",
                        "59ce1601576444808123e71a9f6d8162",
                        "3f67d425e3ea4030a210f76705c88f36",
                        "2ca1e1bcf6774e63b148e54145132af9",
                        "a618c364e038493fa3402a4ac3d7a00d",
                        "018db048a6a54b7ca72121cea4edfe7e",
                        "00dbecf19773437eb2908dfaffbba1bc",
                        "648da64a56294ffeacf692be2e61e38e",
                        "6fa4f8c926544dd4a8a8f67678b0f7a9",
                        "efec74e33a2341be99a9081094f9dd70",
                        "4264278b6881471783c2145414201ce3",
                        "28f11c4e718347fea84314de1a6cb28d",
                        "b9e2f5ab15ed4b23b9fe934a8f289644",
                        "cf27187320364f728e443ad69e6697be",
                        "e2f538562f99429c915677bfd85099e0",
                        "275b747737744de48bb6300c09000b06",
                        "c67cb18e74f243d2b418e68b2d6c6dad",
                        "ebe98e0c14e34d5d9595b23be321ac9d",
                        "d589ec90105e4c20ab87ce7a7f6affe0",
                        "b24277c11f6d47469e5fb9ea72631c5c",
                        "2e4dd52262ab4207839e2780b975fcfc",
                        "2ff2d323bb77427fab458ed89f96ead2",
                        "4f5f6bc7603e48a394a0e92a267efe8c",
                        "72b6581aa7d849518dd2e05410828d36",
                        "b866f9206f3146a69e2048d01d522f00",
                        "a2171eed0af44bfc9eb562db13d7f53a",
                        "225d674ed7104b649a8fa05aa1c708e6",
                        "ebc1e4c5bc984c9f970ca0cd2345f257",
                        "419ef19e7fd94b27b5614c27d3c90299",
                        "f1b850e8e1d844a38e1e2c040a5feaaf",
                        "3aa190310a0c461c9c77c29b4849a628",
                        "b2c23307fca14bfd93ad866a5720467b",
                        "add54fa3731a40c5b6b7bdc9c824b011",
                        "4447837c007b4413b0d0a36fa0f3a843",
                        "d0fbd112149f443da4e9c7fb382ee7cb",
                        "1d0da33219034335866159ca7be9927b",
                        "367410d7d9d64887845c2d80175afdf4",
                        "b2b8bb9eb9774f56aa01c908468d608e",
                        "84e0f4372d144cb287820da9e6d8ea32",
                        "7068cbc2695a4093b195fac8176c9b70",
                        "f3631243ad2b4cdfbc6af05721057e72",
                        "1ace0030c72c42f4afe3d676469c2791",
                        "06694c2c0c574d739ecb028dd9f0ef8e",
                        "094d494092934266b2188002e2c645b4",
                        "cfd726b3914647b8937f9c9db1e76bd2",
                        "0d72d3849ab34dba81897cf6dd388bcf",
                        "a46fdd8b95bc4868b6ce3c135482d8af",
                        "d1474ea06c964b55940f7ed6938ceab2",
                        "29be2aebd72c40d1b2f54bd45e120bef",
                        "15d211caec364aada749eb628bec8638",
                        "3c7d331cf1fa4fc2813e481f71164b44",
                        "c4e1d62903be4279bec4b100a027a2a7",
                        "f50a0200b642491791679ecfe59caf8a",
                        "03a160b7b517478bb1765f32607c6dc9",
                        "d724edd77dae40a597cc754b6dc6ebed"
                    ]
                },
                "id": "eazH1eNF1Ov2",
                "outputId": "055b149b-f933-438e-9921-bc62074210e5"
            },
            "id": "eazH1eNF1Ov2",
            "execution_count": 17,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "68aa59c7325d4b6fbde0dc45d64dcc4e"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
                        "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "28f11c4e718347fea84314de1a6cb28d"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
                        "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "4f5f6bc7603e48a394a0e92a267efe8c"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "4447837c007b4413b0d0a36fa0f3a843"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "cfd726b3914647b8937f9c9db1e76bd2"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Device set to use cpu\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[{'score': 0.4167894423007965, 'token': 3000, 'token_str': 'paris', 'sequence': 'the capital of france is paris.'}, {'score': 0.07141634821891785, 'token': 22479, 'token_str': 'lille', 'sequence': 'the capital of france is lille.'}, {'score': 0.06339266151189804, 'token': 10241, 'token_str': 'lyon', 'sequence': 'the capital of france is lyon.'}, {'score': 0.04444744810461998, 'token': 16766, 'token_str': 'marseille', 'sequence': 'the capital of france is marseille.'}, {'score': 0.030297260731458664, 'token': 7562, 'token_str': 'tours', 'sequence': 'the capital of france is tours.'}]\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!pip freeze > requirements.txt"
            ],
            "metadata": {
                "id": "qNfuC0s_1knA"
            },
            "id": "qNfuC0s_1knA",
            "execution_count": 18,
            "outputs": []
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        },
        "colab": {
            "provenance": [],
            "include_colab_link": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}