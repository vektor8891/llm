{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/23_dpo_fine_tuning/23_dpo_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# ! pip install -qq datasets==3.2.0\n",
                "# ! pip install -qq trl==0.11.4"
            ],
            "metadata": {
                "id": "aLKjuDN3fsSm"
            },
            "id": "aLKjuDN3fsSm",
            "execution_count": 1,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Direct Preference Optimization (DPO)\n",
                "\n",
                "## Create and configure the model and tokenizer"
            ],
            "metadata": {
                "id": "3eBi5-rieOvj"
            },
            "id": "3eBi5-rieOvj"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "5edbcd19",
            "metadata": {
                "id": "5edbcd19"
            },
            "outputs": [],
            "source": [
                "from transformers import AutoModelForCausalLM, GPT2Tokenizer\n",
                "\n",
                "# Load the GPT-2 model\n",
                "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
                "\n",
                "# Load a reference model\n",
                "model_ref = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
                "\n",
                "# Load the GPT-2 tokenizer\n",
                "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
                "\n",
                "# Set the pad token to the end-of-sequence token\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "# Set the padding side to \"right\" to fix the overflow issue with FP16 training\n",
                "tokenizer.padding_side = \"right\"\n",
                "\n",
                "# Disable the use of the cache during the model's forward pass\n",
                "model.config.use_cache = False"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "model"
            ],
            "metadata": {
                "id": "PsGO0bOJerrX",
                "outputId": "0a07982e-9e5b-4cd1-b8b4-1d336a1e3717",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "PsGO0bOJerrX",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "GPT2LMHeadModel(\n",
                            "  (transformer): GPT2Model(\n",
                            "    (wte): Embedding(50257, 768)\n",
                            "    (wpe): Embedding(1024, 768)\n",
                            "    (drop): Dropout(p=0.1, inplace=False)\n",
                            "    (h): ModuleList(\n",
                            "      (0-11): 12 x GPT2Block(\n",
                            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
                            "        (attn): GPT2Attention(\n",
                            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
                            "          (c_proj): Conv1D(nf=768, nx=768)\n",
                            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
                            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
                            "        )\n",
                            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
                            "        (mlp): GPT2MLP(\n",
                            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
                            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
                            "          (act): NewGELUActivation()\n",
                            "          (dropout): Dropout(p=0.1, inplace=False)\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
                            "  )\n",
                            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
                            ")"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 3
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Quantized model configuration (Optional)\n",
                "\n",
                "memory-efficient training with GPU"
            ],
            "metadata": {
                "id": "p1mgWPW3e5qt"
            },
            "id": "p1mgWPW3e5qt"
        },
        {
            "cell_type": "code",
            "source": [
                "#!pip install -U bitsandbytes # this package is required for quantization"
            ],
            "metadata": {
                "id": "N0lahqSneyHZ"
            },
            "id": "N0lahqSneyHZ",
            "execution_count": 4,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "'''## Quantized model --only available on GPU\n",
                "from transformers import BitsAndBytesConfig\n",
                "\n",
                "# Configure the quantization parameters\n",
                "quantization_config = BitsAndBytesConfig(\n",
                "    # Load the model in 4-bit quantized format\n",
                "    load_in_4bit=True,\n",
                "    # Enable double quantization for better accuracy\n",
                "    bnb_4bit_use_double_quant=True,\n",
                "    # Use non-uniform 4-bit quantization (nf4)\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                "    # Use bfloat16 as the computation data type during quantization\n",
                "    bnb_4bit_compute_dtype=torch.bfloat16\n",
                ")\n",
                "\n",
                "# Load GPT-2 model with the specified quantization configuration\n",
                "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\n",
                "\n",
                "# Load a reference model with the same quantization configuration\n",
                "model_ref = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\n",
                "\n",
                "# Load GPT-2 tokenizer\n",
                "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
                "\n",
                "# Set the pad token to the end-of-sequence token\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "# Set the padding side to \"right\" to fix the overflow issue with FP16 training\n",
                "tokenizer.padding_side = \"right\"\n",
                "\n",
                "# Disable the use of the cache during the model's forward pass\n",
                "model.config.use_cache = False'''"
            ],
            "metadata": {
                "id": "ii1us2rifEmp",
                "outputId": "00e0513e-6ef3-4aee-c6ca-d11c0c08845e",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 122
                }
            },
            "id": "ii1us2rifEmp",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'## Quantized model --only available on GPU\\nfrom transformers import BitsAndBytesConfig\\n\\n# Configure the quantization parameters\\nquantization_config = BitsAndBytesConfig(\\n    # Load the model in 4-bit quantized format\\n    load_in_4bit=True,\\n    # Enable double quantization for better accuracy\\n    bnb_4bit_use_double_quant=True,\\n    # Use non-uniform 4-bit quantization (nf4)\\n    bnb_4bit_quant_type=\"nf4\",\\n    # Use bfloat16 as the computation data type during quantization\\n    bnb_4bit_compute_dtype=torch.bfloat16\\n)\\n\\n# Load GPT-2 model with the specified quantization configuration\\nmodel = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\\n\\n# Load a reference model with the same quantization configuration\\nmodel_ref = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\\n\\n# Load GPT-2 tokenizer\\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\\n\\n# Set the pad token to the end-of-sequence token\\ntokenizer.pad_token = tokenizer.eos_token\\n# Set the padding side to \"right\" to fix the overflow issue with FP16 training\\ntokenizer.padding_side = \"right\"\\n\\n# Disable the use of the cache during the model\\'s forward pass\\nmodel.config.use_cache = False'"
                        ],
                        "application/vnd.google.colaboratory.intrinsic+json": {
                            "type": "string"
                        }
                    },
                    "metadata": {},
                    "execution_count": 5
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Preprocess data set"
            ],
            "metadata": {
                "id": "vpgfbmC9fIqC"
            },
            "id": "vpgfbmC9fIqC"
        },
        {
            "cell_type": "code",
            "source": [
                "from datasets import load_dataset\n",
                "\n",
                "# Load the dataset from the specified location\n",
                "ds = load_dataset(\"BarraHome/ultrafeedback_binarized\")"
            ],
            "metadata": {
                "id": "JHVSe2DyfFbu"
            },
            "id": "JHVSe2DyfFbu",
            "execution_count": 6,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "ds.keys()"
            ],
            "metadata": {
                "id": "rILDsO6YfL-A",
                "outputId": "24389c24-e9e3-4cff-b84d-33c36f68b95c",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "rILDsO6YfL-A",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "dict_keys(['train_prefs', 'train_sft', 'test_prefs', 'test_sft', 'train_gen', 'test_gen'])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "ds[\"train_prefs\"][0].keys()"
            ],
            "metadata": {
                "id": "kOtdU5NIfNtx",
                "outputId": "09c33f06-2367-41c3-ca2a-7af26f0309e7",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "kOtdU5NIfNtx",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "dict_keys(['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 8
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "ds[\"train_prefs\"][0]"
            ],
            "metadata": {
                "id": "pqEiQiAqfm7P",
                "outputId": "76a3c387-f73e-4852-97db-9edd86f2153f",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "pqEiQiAqfm7P",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'prompt': 'how can i develop a habit of drawing daily',\n",
                            " 'prompt_id': '086b3e24f29b8956a01059f79c56db35d118a06fb6b844b095737d042795cd43',\n",
                            " 'chosen': [{'content': 'how can i develop a habit of drawing daily',\n",
                            "   'role': 'user'},\n",
                            "  {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
                            "   'role': 'assistant'}],\n",
                            " 'rejected': [{'content': 'how can i develop a habit of drawing daily',\n",
                            "   'role': 'user'},\n",
                            "  {'content': \"One way to develop a habit of drawing daily is to allocate a specific time interval for drawing each day, whether it's early in the morning or before going to bed at night. You can also find inspiration or motivation to draw by joining drawing communities, following artists on social media, or going out into nature and sketching what you see. Additionally, practicing drawing every day can help you improve your skills over time.\",\n",
                            "   'role': 'assistant'}],\n",
                            " 'messages': [{'content': 'how can i develop a habit of drawing daily',\n",
                            "   'role': 'user'},\n",
                            "  {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
                            "   'role': 'assistant'}],\n",
                            " 'score_chosen': 8.5,\n",
                            " 'score_rejected': 7.5}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 9
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "import multiprocessing\n",
                "\n",
                "# You can reduce the volume of data (due to resource limitations) by selecting the first 5% examples from each split of the dataset\n",
                "for key in ds:\n",
                "    #cnt = round(ds[key].__len__()*0.05)\n",
                "    cnt=50\n",
                "    ds[key] = ds[key].select(range(cnt))\n",
                "\n",
                "# Define a function to process the data\n",
                "def process(row):\n",
                "    # delete unwanted columns\n",
                "    del row[\"prompt_id\"]\n",
                "    del row[\"messages\"]\n",
                "    del row[\"score_chosen\"]\n",
                "    del row[\"score_rejected\"]\n",
                "    # retrieve the actual response text\n",
                "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
                "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
                "\n",
                "    return row\n",
                "\n",
                "# Apply the data processing function to the dataset\n",
                "ds = ds.map(\n",
                "    process,\n",
                "    num_proc=multiprocessing.cpu_count(),\n",
                "    load_from_cache_file=False,\n",
                ")\n",
                "\n",
                "# Split the dataset into training and evaluation sets\n",
                "train_dataset = ds['train_prefs']\n",
                "eval_dataset = ds['test_prefs']"
            ],
            "metadata": {
                "id": "ZjNkBy5hgQZt",
                "outputId": "39bf4650-ce9e-4aa8-8be5-556f24c6a81a",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 209,
                    "referenced_widgets": [
                        "df76a2f48d374a998976927440351361",
                        "0121c2540f854c84874fda67c7f50b0d",
                        "eaf15ad22da14798b24084234b27a69a",
                        "fd7086ae0ed9403b9f3494cbb288386a",
                        "c9e3265dde194b1d9f3ce9323feb36c6",
                        "8cf8affdfd684e3c8440f963843e9eba",
                        "84404515cc13457fa4d330641faee74f",
                        "dce5166df98f4e0b9ccdd411ac074b80",
                        "76ad414830044db18420c0db081162bb",
                        "6c61ef0d6f4b44e1a71182897a477df4",
                        "960483758a254915bf3c87d35579aa34",
                        "456e4c7c3cc3488ab4c42404ab5ddd77",
                        "7ad99668a6dd40db8f89faff427b0e79",
                        "67a22a6400c647b39be74eac71ef84c6",
                        "3c25c17648ef46b880b7264fcc174b85",
                        "2c0a4062fd8c4146ace02815e801b078",
                        "a0e30103e5c349bf905e74aa8763b5d1",
                        "2c35f7416fd94b289282cb670725c698",
                        "6f59da2cfd1b489d91cbc327e8fa74e6",
                        "392e40cba4e34bad9570db44a35f2d9f",
                        "52167ab1f2f34f24bbf55be50636e70e",
                        "27df054be7b449ea8dc09cd701d86248",
                        "f79088f62e124893b5947f679d7bcd87",
                        "8b7925302a6043fead64867e533fb7b9",
                        "7920674414e547a59d6593dec2d4f432",
                        "ffc47ed1c5134328857c9fa60e3be703",
                        "185854104ba04b8aab362fbdaed21958",
                        "79b9790969a24158b765329cc7ed26f1",
                        "4185725e344e4ca4b97b70d0adbf36e8",
                        "2e815d173503426cb2b3a7397626951c",
                        "736d5a37462c441b97ff2c75fdbe43a5",
                        "539280e9172f4f55b18f33783d3b804a",
                        "2f74f686ff70462295a63de217ba3592",
                        "3c5aabbd7b2b4c099ea620c9c98c7ee5",
                        "6a99230bdcfe419fb147a8eee452737c",
                        "1c90dc66c7cf4d3abec2ea0ee58137c0",
                        "93ada00928794bfebae46db782a3cff6",
                        "121fec0a0c5449b89ce42e80d8d87d05",
                        "d0cc3d41126b4b4980df0f50f7add2d1",
                        "6e41935035044b6da517c10927eaf7d5",
                        "974867a0f60d4d8388167038188bdef3",
                        "b92e08b87f6341ba9365b426b564d596",
                        "9b18cafad083437bbacedadd9e87ddfb",
                        "e3b09d98531643c6b4166ded513d0d6e",
                        "3e10fd1656464bc7b72c1a93610bb336",
                        "63d0e2f641224ec496deb9f768f8adae",
                        "cca9998200e145e1a58f6d79ed45287b",
                        "55a6682c84894580a1022895fd58d1ee",
                        "d761b87710d74b76812537617c6dfbd0",
                        "453f32bf17c34a1d9021bae9a63447be",
                        "41f0bacea536404fb00fd3a06090a49b",
                        "a8b48dbe526d4f7db0aae3bec9dcd8bf",
                        "e40b5c4404cf4593a7c13694a3de9dcb",
                        "1e54f240f7ef406bb4b281e04dcefe57",
                        "1cd77601550441fdb3447a6279a30013",
                        "95bafb95e33249289c294ffb2c8c30ee",
                        "bb02f464331d4db189e0f340a6480a01",
                        "5f81a1555fe74953aadc79258a56d035",
                        "eaca6c6243324cc993b72741439add24",
                        "f26eb7b174f24e74b2d4a07a0adca5a7",
                        "37338c7311cf4814b3623fc0dc350a7b",
                        "aacbdf1e44ab4893bff91bafe08f6cb5",
                        "691327ab831544579726106e686c895d",
                        "3fd580a30666433ab62d325b78675869",
                        "7d3ccef4f39c4a66a7cc5bea41febee6",
                        "468598f3802a4461a730abe760d9fc1b"
                    ]
                }
            },
            "id": "ZjNkBy5hgQZt",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "df76a2f48d374a998976927440351361"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "456e4c7c3cc3488ab4c42404ab5ddd77"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "f79088f62e124893b5947f679d7bcd87"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "3c5aabbd7b2b4c099ea620c9c98c7ee5"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "3e10fd1656464bc7b72c1a93610bb336"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "95bafb95e33249289c294ffb2c8c30ee"
                        }
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "train_dataset[0]"
            ],
            "metadata": {
                "id": "DnAWHt1IgYfg",
                "outputId": "6b757c0e-5117-4ddc-c52d-10b974bb136d",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "DnAWHt1IgYfg",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'prompt': 'how can i develop a habit of drawing daily',\n",
                            " 'chosen': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
                            " 'rejected': \"One way to develop a habit of drawing daily is to allocate a specific time interval for drawing each day, whether it's early in the morning or before going to bed at night. You can also find inspiration or motivation to draw by joining drawing communities, following artists on social media, or going out into nature and sketching what you see. Additionally, practicing drawing every day can help you improve your skills over time.\"}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 11
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "from peft import LoraConfig\n",
                "\n",
                "# PEFT (Parameter-Efficient Finetuning) configuration\n",
                "peft_config = LoraConfig(\n",
                "        # The rank of the low-rank adaptation weights\n",
                "        r=4,\n",
                "        # The target modules to apply the low-rank adaptation to\n",
                "        target_modules=['c_proj','c_attn'],\n",
                "        # The task type for the low-rank adaptation\n",
                "        task_type=\"CAUSAL_LM\",\n",
                "        # The scaling factor for the low-rank adaptation weights\n",
                "        lora_alpha=8,\n",
                "        # The dropout probability for the low-rank adaptation weights\n",
                "        lora_dropout=0.1,\n",
                "        # The bias mode for the low-rank adaptation\n",
                "        bias=\"none\",\n",
                ")"
            ],
            "metadata": {
                "id": "yCPq626ggfx_"
            },
            "id": "yCPq626ggfx_",
            "execution_count": 12,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "### DPO configuration"
            ],
            "metadata": {
                "id": "UZRViKiKgmaS"
            },
            "id": "UZRViKiKgmaS"
        },
        {
            "cell_type": "code",
            "source": [
                "from trl import DPOConfig\n",
                "\n",
                "# DPO configuration\n",
                "training_args = DPOConfig(\n",
                "    # The beta parameter for the DPO loss function\n",
                "    #beta is the temperature parameter for the DPO loss, typically something in the range of 0.1 to 0.5 .\n",
                "    beta=0.1,\n",
                "    # The output directory for the training\n",
                "    output_dir=\"dpo\",\n",
                "    # The number of training epochs\n",
                "    num_train_epochs=5,\n",
                "    # The batch size per device during training\n",
                "    per_device_train_batch_size=1,\n",
                "    # The batch size per device during evaluation\n",
                "    per_device_eval_batch_size=1,\n",
                "    # Whether to remove unused columns from the dataset\n",
                "    remove_unused_columns=False,\n",
                "    # The number of steps between logging training progress\n",
                "    logging_steps=10,\n",
                "    # The number of gradient accumulation steps\n",
                "    gradient_accumulation_steps=1,\n",
                "    # The learning rate for the optimization\n",
                "    learning_rate=1e-4,\n",
                "    # The evaluation strategy (e.g., after each step or epoch)\n",
                "    # evaluation_strategy=\"epoch\",\n",
                "    # The number of warmup steps for the learning rate scheduler\n",
                "    warmup_steps=2,\n",
                "    # Whether to use 16-bit (float16) precision\n",
                "    fp16=False,\n",
                "    # The number of steps between saving checkpoints\n",
                "    save_steps=500,\n",
                "    # The maximum number of checkpoints to keep\n",
                "    #save_total_limit=2,\n",
                "    # The reporting backend to use (set to 'none' to disable, you can also report to wandb or tensorboard)\n",
                "    report_to='none'\n",
                ")"
            ],
            "metadata": {
                "id": "-jUa9dJGgj9g"
            },
            "id": "-jUa9dJGgj9g",
            "execution_count": 14,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "### DPO training"
            ],
            "metadata": {
                "id": "JHCsf9wAhw3B"
            },
            "id": "JHCsf9wAhw3B"
        },
        {
            "cell_type": "code",
            "source": [
                "from trl import DPOTrainer\n",
                "\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "\n",
                "# Create a DPO trainer\n",
                "# This trainer will handle the fine-tuning of the model using the DPO technique\n",
                "trainer = DPOTrainer(\n",
                "        # The model to be fine-tuned\n",
                "        model=model,\n",
                "        # The reference model (not used in this case because LoRA has been used)\n",
                "        ref_model=None,\n",
                "        # The DPO training configuration\n",
                "        args=training_args,\n",
                "        # The beta parameter for the DPO loss function\n",
                "\n",
                "        # The training dataset\n",
                "        train_dataset=train_dataset,\n",
                "        # The evaluation dataset\n",
                "        eval_dataset=eval_dataset,\n",
                "        # The tokenizer for the model\n",
                "        tokenizer=tokenizer,\n",
                "        # The PEFT (Parallel Efficient Finetuning) configuration\n",
                "        peft_config=peft_config,\n",
                "        # The maximum prompt length\n",
                "        #max_prompt_length=512,\n",
                "        # The maximum sequence length\n",
                "        max_length=512,\n",
                "    )\n"
            ],
            "metadata": {
                "id": "Wup1hKFTgs8e",
                "outputId": "21261529-494e-4920-c9e6-868ea60ffc69",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 413,
                    "referenced_widgets": [
                        "af9e905b45b740f78ff8667330571900",
                        "27975574b1874986bdc09a44aed7339a",
                        "eda831437128434faf30150759be5cb7",
                        "c94b1b70736a44cebfc9f760cc59c826",
                        "60c7e05f03fd47f0ae449ee2c16dc8d5",
                        "88260cbaef764a8ca57023d8f7ce3fef",
                        "afe7f2d263414ca197e26e5fa9238818",
                        "0d403a945c324927922c71970665befb",
                        "962959def2ac4c00ab4afdb04a7f2233",
                        "66b2ebb8da464c76a6caf332bd39d844",
                        "060733c7543945d1a39f6e1a423eab68",
                        "1f8b1a4a36fe460db02d97bd07dafc35",
                        "074cda3584fe4b12be1fbb01e1e96564",
                        "77e8f927bad64d7eb81c48f78443f980",
                        "6e3a9f717d48450f955aee7ab1628e90",
                        "f6446273eae94a5890a1dc16d87bec03",
                        "7f1984aa06f24ee8b328155e3aae70d3",
                        "ac4183bf669d4064983e6d48ba057a6e",
                        "415bdafadbd34e5f86e7b01c4a5f3154",
                        "07b8caca2144411d89bde03a361e7be0",
                        "0eb0dfe87a134dada76d2b815986020a",
                        "df79af433de64fa495ddc9911c00384f"
                    ]
                }
            },
            "id": "Wup1hKFTgs8e",
            "execution_count": 17,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_length. Will not be supported from version '1.0.0'.\n",
                        "\n",
                        "Deprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n",
                        "  warnings.warn(message, FutureWarning)\n",
                        "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
                        "  warnings.warn(\n",
                        "Trainer.tokenizer is now deprecated. You should use `Trainer.processing_class = processing_class` instead.\n",
                        "/usr/local/lib/python3.11/dist-packages/trl/trainer/dpo_trainer.py:655: UserWarning: You passed `max_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
                        "  warnings.warn(\n",
                        "/usr/local/lib/python3.11/dist-packages/trl/trainer/dpo_trainer.py:673: UserWarning: `max_prompt_length` is not set in the DPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
                        "  warnings.warn(\n",
                        "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
                        "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
                        "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Tokenizing train dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "af9e905b45b740f78ff8667330571900"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Tokenizing eval dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "1f8b1a4a36fe460db02d97bd07dafc35"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.11/dist-packages/trl/trainer/dpo_trainer.py:822: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DPOTrainer.__init__`. Use `processing_class` instead.\n",
                        "  super().__init__(\n",
                        "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Training model"
            ],
            "metadata": {
                "id": "Ba-mCoXpiEiP"
            },
            "id": "Ba-mCoXpiEiP"
        },
        {
            "cell_type": "code",
            "source": [
                "# import matplotlib.pyplot as plt\n",
                "# import pandas as pd\n",
                "\n",
                "# # Start the training process\n",
                "# trainer.train()\n",
                "\n",
                "# # Retrieve log_history and save it to a dataframe\n",
                "# log = pd.DataFrame(trainer.state.log_history)\n",
                "# log_t = log[log['loss'].notna()]\n",
                "# log_e = log[log['eval_loss'].notna()]\n",
                "\n",
                "# # Plot train and evaluation losses\n",
                "# plt.plot(log_t[\"epoch\"], log_t[\"loss\"], label = \"train_loss\")\n",
                "# plt.plot(log_e[\"epoch\"], log_e[\"eval_loss\"], label = \"eval_loss\")\n",
                "# plt.legend()\n",
                "# plt.show()\n",
                "\n",
                "# # Load the trained DPO model you just trained\n",
                "# dpo_model = AutoModelForCausalLM.from_pretrained('./dpo/checkpoint-250')"
            ],
            "metadata": {
                "id": "I7OVh937h2Se"
            },
            "id": "I7OVh937h2Se",
            "execution_count": 18,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Loading trained model"
            ],
            "metadata": {
                "id": "2fSMHa7PiYz7"
            },
            "id": "2fSMHa7PiYz7"
        },
        {
            "cell_type": "code",
            "source": [
                "import requests\n",
                "import tarfile\n",
                "\n",
                "# Define the URL and the filename\n",
                "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/YIDeT3qihEpWChdXN_RmTg/DPO-tar.gz'\n",
                "filename = './DPO.tar'\n",
                "\n",
                "# Download the file\n",
                "response = requests.get(url)\n",
                "\n",
                "# Save the file locally\n",
                "with open(filename, 'wb') as f:\n",
                "    f.write(response.content)\n",
                "\n",
                "# Extract the tar file\n",
                "if tarfile.is_tarfile(filename):\n",
                "    with tarfile.open(filename, 'r') as tar:\n",
                "        tar.extractall()\n",
                "        print(\"Files extracted:\", tar.getnames())\n",
                "else:\n",
                "    print(\"The adownloaded file is not a tar file.\")"
            ],
            "metadata": {
                "id": "0DhdOoHhiXdC",
                "outputId": "1f5e8f61-c4e5-400e-9624-6a187c48b872",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "0DhdOoHhiXdC",
            "execution_count": 21,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Files extracted: ['DPO', 'DPO/adapter_config.json', 'DPO/tokenizer_config.json', 'DPO/merges.txt', 'DPO/adapter_model.safetensors', 'DPO/special_tokens_map.json', 'DPO/training_args.bin', 'DPO/README.md', 'DPO/vocab.json']\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Load the trained DPO model tiy just trained\n",
                "dpo_model = AutoModelForCausalLM.from_pretrained('./DPO')"
            ],
            "metadata": {
                "id": "o_ikA-02iaWH"
            },
            "id": "o_ikA-02iaWH",
            "execution_count": 22,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Generation"
            ],
            "metadata": {
                "id": "dwC99qgyii5_"
            },
            "id": "dwC99qgyii5_"
        },
        {
            "cell_type": "code",
            "source": [
                "# Load the GPT-2 tokenizer\n",
                "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
            ],
            "metadata": {
                "id": "FzIf3V4-ihO4"
            },
            "id": "FzIf3V4-ihO4",
            "execution_count": 23,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "from transformers import set_seed, GenerationConfig\n",
                "\n",
                "# Set a seed for reproducibility\n",
                "set_seed(42)\n",
                "\n",
                "\n",
                "# Define the generation configuration for the DPO model\n",
                "# This sets the parameters for text generation\n",
                "generation_config = GenerationConfig(\n",
                "        # Use sampling to generate diverse text\n",
                "        do_sample=True,\n",
                "        # Top-k sampling parameter\n",
                "        top_k=1,\n",
                "        # Temperature parameter to control the randomness of the generated text\n",
                "        temperature=0.1,\n",
                "        # Maximum number of new tokens to generate\n",
                "        max_new_tokens=25,\n",
                "        # Use the end-of-sequence token as the padding token\n",
                "        pad_token_id=tokenizer.eos_token_id\n",
                "    )\n",
                "\n",
                "# Define the input prompt for text generation\n",
                "PROMPT = \"Is a higher octane gasoline better for your car?\"\n",
                "# Encode the prompt using the tokenizer\n",
                "inputs = tokenizer(PROMPT, return_tensors='pt')\n",
                "\n",
                "# Generate text using the DPO model\n",
                "outputs = dpo_model.generate(**inputs, generation_config=generation_config)\n",
                "# Decode the generated text and print it\n",
                "print(\"DPO response:\\t\",tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
                "\n",
                "# Load the pre-trained GPT-2 model\n",
                "gpt2_model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
                "# Generate text using the GPT-2 model\n",
                "outputs = gpt2_model.generate(**inputs, generation_config=generation_config)\n",
                "# Decode the generated text and print it\n",
                "print(\"\\nGPT2 response:\\t\",tokenizer.decode(outputs[0], skip_special_tokens=True))"
            ],
            "metadata": {
                "id": "jrmWPTR3ik75",
                "outputId": "e3dd46b9-8017-43de-bedc-dc96ab6a552e",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "jrmWPTR3ik75",
            "execution_count": 25,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "DPO response:\t Is a higher octane gasoline better for your car?\n",
                        "\n",
                        "The answer is yes. The higher octane gasoline is better for your car.\n",
                        "\n",
                        "The higher octane gasoline\n",
                        "\n",
                        "GPT2 response:\t Is a higher octane gasoline better for your car?\n",
                        "\n",
                        "The answer is yes. The higher octane gasoline is more efficient and more fuel efficient.\n",
                        "\n",
                        "The higher oct\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Exercise\n",
                "\n",
                "## Exercise 1: Preprocess the `argilla/ultrafeedback-binarized-preferences-cleaned` Dataset"
            ],
            "metadata": {
                "id": "ZY1M5F43i8Jh"
            },
            "id": "ZY1M5F43i8Jh"
        },
        {
            "cell_type": "code",
            "source": [
                "dataset = load_dataset(\"argilla/ultrafeedback-binarized-preferences-cleaned\")\n",
                "\n",
                "cnt = 50\n",
                "\n",
                "# Select the first 5% of examples\n",
                "dataset['train'] = dataset['train'].select(range(cnt))\n",
                "\n",
                "def process(row):\n",
                "    # Delete unwanted columns\n",
                "    del row[\"source\"]\n",
                "    del row[\"chosen-rating\"]\n",
                "    del row[\"chosen-model\"]\n",
                "    del row[\"rejected-rating\"]\n",
                "    del row[\"rejected-model\"]\n",
                "\n",
                "    # Retrieve the actual response text\n",
                "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
                "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
                "\n",
                "    return row\n",
                "\n",
                "# Apply the data processing function to the dataset\n",
                "dataset['train'] = dataset['train'].map(\n",
                "    process,\n",
                "    num_proc=multiprocessing.cpu_count(),\n",
                "    load_from_cache_file=False,\n",
                ")\n",
                "\n",
                "train_size = int(0.8 * len(dataset['train']))  # 80% for training\n",
                "eval_size = len(dataset['train']) - train_size  # Remaining 20% for evaluation\n",
                "\n",
                "train_dataset = dataset['train'].select(range(train_size))\n",
                "eval_dataset = dataset['train'].select(range(train_size, train_size + eval_size))"
            ],
            "metadata": {
                "id": "37CXj0_VimVP",
                "outputId": "35dbc538-5aec-47e2-a8b5-b97f551819bb",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 145,
                    "referenced_widgets": [
                        "9b1dd4c513744b8299d78558ea1231d3",
                        "17ad479f2fff45f4aae05fdd3ee85d9f",
                        "2edb56a7a1a1407cb8b053dda83c2c6e",
                        "efded1716faf4410a20a3a13044a25c8",
                        "6503b9ae67204ccd9d103b293a065d39",
                        "3d61381eb8eb41329c5f0b4c6e93c128",
                        "c19b21c64e8e42d488b7da1b14b77303",
                        "ecc7b8217a48422b9d38cd4a491736e2",
                        "fd98d1167bb94ec88343a2b5e3620cc4",
                        "4ad7cc7b0d6a4b20a95cf8e1983e91fa",
                        "5cf2d9a45a564e878c81953ccb0c38e0",
                        "e24b4b0bd21e4053a62b917b39c9dc15",
                        "cd8b795db9dc49358f07eb4986e51d1e",
                        "a0fab2225883423fae0635f8f341b4bf",
                        "ab2f27d190414c52ab3ad9939e51686b",
                        "cf7ff0fca64d47f48107bbedfc2497a2",
                        "2befcee9c1c5494ba2af95bb0813b73c",
                        "3aa0ab40a2d641adad011fe5e29f898b",
                        "2e2b06a745444f4aa452e15ea3c1f751",
                        "81a224f95f94486d89c09f353d4e3a9a",
                        "3efb96c010b646968c8544aa8db8edda",
                        "930fdd553e9b491f9972ad72a7b7ab67",
                        "c48539e6e58f4f23a4e62ac3d295bdb5",
                        "3b482a76e5ed446b9af24368fc0c644c",
                        "a3bf0490fab44bd08779557be29a4f6f",
                        "8bfe71aeefb04ce885d7e427a4936b13",
                        "ec55c53e411f4f4797f4742a4797ebda",
                        "b177790066b4420d981dd568b859e006",
                        "727fadd964ad4e29812e6d9522750434",
                        "f85dd9ce3e20498bb709a288e47c71c3",
                        "5f91baaaf0894a028268b4a93231179f",
                        "c0b097e612d84532bfd49b1ba6b072a4",
                        "8b7a9fd42ca64ce7bcd8bcb55902a5bc",
                        "21b0ec4bfa2642dda3321de0c1a54605",
                        "67f23e3c2cab4d8e946292b51d494aba",
                        "4107e2f8fb4a48d99ce88a4471bb21b4",
                        "1edd77384e9048d4bba906883df8a750",
                        "d44b9959d4304f5ab143f9795aa0e3b8",
                        "1710f98e7a0f4539abe6dee8a3e894fc",
                        "706f1a831a434958a77072b2ae5bcba2",
                        "d72ec11a747a486fb622239c96c50ef1",
                        "96b78a738ba74e6eb7b41bfff4da6cf4",
                        "265f59f3db5d47808fcfde9918479896",
                        "d71e76d112f845af8443b46106897c55"
                    ]
                }
            },
            "id": "37CXj0_VimVP",
            "execution_count": 28,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "README.md:   0%|          | 0.00/4.46k [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "9b1dd4c513744b8299d78558ea1231d3"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "train-00000-of-00001.parquet:   0%|          | 0.00/143M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "e24b4b0bd21e4053a62b917b39c9dc15"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Generating train split:   0%|          | 0/60917 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "c48539e6e58f4f23a4e62ac3d295bdb5"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "21b0ec4bfa2642dda3321de0c1a54605"
                        }
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "train_dataset"
            ],
            "metadata": {
                "id": "UjnFS5gKi9r4",
                "outputId": "dd0e9604-1cf3-4450-a002-cb2d780d136a",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "UjnFS5gKi9r4",
            "execution_count": 29,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "Dataset({\n",
                            "    features: ['prompt', 'chosen', 'rejected'],\n",
                            "    num_rows: 40\n",
                            "})"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 29
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "train_dataset[0]"
            ],
            "metadata": {
                "id": "y9QpuXIIjSI-",
                "outputId": "8a84b484-e404-41f1-8d46-10f4374cb370",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "y9QpuXIIjSI-",
            "execution_count": 30,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'prompt': 'Can you write a C++ program that prompts the user to enter the name of a country and checks if it borders the Mediterranean Sea? Here\\'s some starter code to help you out:\\n#include <iostream>\\n#include <string>\\nusing namespace std;\\nint main() {\\n    string country;\\n    // prompt user for input\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n    // check if country borders the Mediterranean Sea\\n    // [C++ code]\\n    return 0;\\n}',\n",
                            " 'chosen': 'Here\\'s a C++ program that prompts the user to enter the name of a country and checks if it borders the Mediterranean Sea:\\n\\n#include <iostream>\\n#include <string>\\n#include <set>\\n#include <map>\\n#include <algorithm>\\n\\nusing namespace std;\\n\\nint main() {\\n    // store countries and their bordering seas in a map\\n    map<string, set<string>> countries;\\n    countries[\"Algeria\"] = {\"Mediterranean Sea\", \"North African Coast\"};\\n    countries[\"France\"] = {\"Mediterranean Sea\", \"English Channel\"};\\n    countries[\"Italy\"] = {\"Mediterranean Sea\", \"Adriatic Sea\"};\\n    countries[\"Malta\"] = {\"Mediterranean Sea\", \"North African Coast\"};\\n    countries[\"Spain\"] = {\"Mediterranean Sea\", \"Atlantic Ocean\"};\\n    countries[\"Tunisia\"] = {\"Mediterranean Sea\", \"North African Coast\"};\\n\\n    string country;\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n\\n    // check if country is in the map\\n    if (countries.find(country)!= countries.end()) {\\n        // check if country borders the Mediterranean Sea\\n        set<string> borders = countries.at(country);\\n        if (borders.find(\"Mediterranean Sea\")!= borders.end()) {\\n            cout << country << \" borders the Mediterranean Sea.\" << endl;\\n        } else {\\n            cout << country << \" does not border the Mediterranean Sea.\" << endl;\\n        }\\n    } else {\\n        cout << country << \" is not a recognized country.\" << endl;\\n    }\\n\\n    return 0;\\n}\\n\\nIn this program, we first define a map called countries that stores each country\\'s name as a key and a set of its surrounding seas as the value. We use a set to store each sea name so that we can easily check if a country borders a certain sea.\\n\\nWe then present the user with a prompt to enter the name of a country. We use a while loop to ensure that the user enters a valid country name. We check if the country is in the map, and if so, we retrieve its bordering seas from the map.\\n\\nFinally, we check if the Mediterranean Sea is among the set of borders. If it is, we inform the user that the country borders the Mediterranean Sea. If not, we inform the user that the country does not border the Mediterranean Sea.',\n",
                            " 'rejected': 'Sure, here is the program using the C++11 algorithm \"cds::algorithm::GreaterEqual\":\\n#include <iostream>\\n#include <string>\\n#include <algorithm>\\n#include <vector>\\n#include <cctype>\\n\\nusing namespace std;\\n\\nint main() {\\n    string country;\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n    std::vector<string> vec;\\n    vec.push_back(country);\\n    size_t index = std::find_if(vec.begin(), vec.end(), [](const string& s) {\\n        return std::any_of(s.begin(), s.end(), [](const char& c) {\\n            return c == \\'}}\\';\\n    });\\n    if (index != vec.end()) {\\n        if ((*index)[0] == \\'M\\') {\\n            cout << \"Country is bordered by the Mediterranean Sea.\" << endl;\\n        } else {\\n            cout << \"Country does not border the Mediterranean Sea.\" << endl;\\n        }\\n    } else {\\n        cout << \"Country is not found.\" << endl;\\n    }\\n    return 0;\\n}'}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 30
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Exercise 2: Prompt Inferencing and Comparison with GPT-2"
            ],
            "metadata": {
                "id": "mAua1Syxj7kj"
            },
            "id": "mAua1Syxj7kj"
        },
        {
            "cell_type": "code",
            "source": [
                "PROMPT = input()"
            ],
            "metadata": {
                "id": "dXl9c5ETj2h-",
                "outputId": "902c6794-a42c-46ec-f708-2f9569c34ee4",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "dXl9c5ETj2h-",
            "execution_count": 35,
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "What is DPO?\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
                "\n",
                "generation_config = GenerationConfig(\n",
                "    # Use sampling to generate diverse text\n",
                "    do_sample=True,\n",
                "    # Top-k sampling parameter: controls the number of highest probability tokens to consider\n",
                "    top_k=1,\n",
                "    # Temperature parameter: controls the randomness of the generated text\n",
                "    temperature=0.1,\n",
                "    # Maximum number of new tokens to generate\n",
                "    max_new_tokens=25,\n",
                "    # Use the end-of-sequence token as the padding token\n",
                "    pad_token_id=tokenizer.eos_token_id\n",
                ")\n",
                "\n",
                "def generate_dpo_response(prompt):\n",
                "    # Tokenize the prompt\n",
                "    inputs = tokenizer(prompt, return_tensors='pt')\n",
                "\n",
                "    # Generate text using the DPO model\n",
                "    outputs = dpo_model.generate(**inputs, generation_config=generation_config)\n",
                "\n",
                "    # Decode and return the response\n",
                "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "\n",
                "def generate_gpt2_response(prompt):\n",
                "    # Tokenize the prompt\n",
                "    inputs = tokenizer(prompt, return_tensors='pt')\n",
                "\n",
                "    # Generate text using the GPT-2 model\n",
                "    outputs = gpt2_model.generate(**inputs, generation_config=generation_config)\n",
                "\n",
                "    # Decode and return the response\n",
                "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "\n",
                "# Generate responses\n",
                "dpo_response = generate_dpo_response(PROMPT)\n",
                "gpt2_response = generate_gpt2_response(PROMPT)\n",
                "\n",
                "# Print the responses\n",
                "print(\"DPO response:\\t\", dpo_response)\n",
                "print(\"\\nGPT-2 response:\\t\", gpt2_response)"
            ],
            "metadata": {
                "id": "qx1l6_UckBJX",
                "outputId": "d712ebe2-f28a-4bca-e45b-d4fb700699b9",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "qx1l6_UckBJX",
            "execution_count": 36,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "DPO response:\t What is DPO?\n",
                        "\n",
                        "DPO is a service that allows you to send and receive emails from your Gmail account. It is a service that\n",
                        "\n",
                        "GPT-2 response:\t What is DPO?\n",
                        "\n",
                        "DPO is a service that allows you to send and receive emails from your Gmail account. It is a service that\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!pip freeze > requirements.txt"
            ],
            "metadata": {
                "id": "rtp7SaznkMkK"
            },
            "id": "rtp7SaznkMkK",
            "execution_count": 37,
            "outputs": []
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        },
        "colab": {
            "provenance": [],
            "include_colab_link": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}