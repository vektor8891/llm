{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/18_adapters_pytorch/18_adapters_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adapters in PyTorch\n",
        "\n",
        "- Adapters: one technique for parameter efficient fine-tuning (PEFT)\n",
        "- Adapters enable modular training within the model without changing the pre-existing pretrained parameters\n",
        "\n",
        "## Define helper functions"
      ],
      "metadata": {
        "id": "Obecf41ciDBU"
      },
      "id": "Obecf41ciDBU"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "59150307",
      "metadata": {
        "id": "59150307"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "\n",
        "def plot(COST,ACC):\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    color = 'tab:red'\n",
        "    ax1.plot(COST, color=color)\n",
        "    ax1.set_xlabel('epoch', color=color)\n",
        "    ax1.set_ylabel('total loss', color=color)\n",
        "    ax1.tick_params(axis='y', color=color)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel('accuracy', color=color)  # you already handled the x-label with ax1\n",
        "    ax2.plot(ACC, color=color)\n",
        "    ax2.tick_params(axis='y', color=color)\n",
        "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def save_list_to_file(lst, filename):\n",
        "    \"\"\"\n",
        "    Save a list to a file using pickle serialization.\n",
        "\n",
        "    Parameters:\n",
        "        lst (list): The list to be saved.\n",
        "        filename (str): The name of the file to save the list to.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(lst, file)\n",
        "\n",
        "def load_list_from_file(filename):\n",
        "    \"\"\"\n",
        "    Load a list from a file using pickle deserialization.\n",
        "\n",
        "    Parameters:\n",
        "        filename (str): The name of the file to load the list from.\n",
        "\n",
        "    Returns:\n",
        "        list: The loaded list.\n",
        "    \"\"\"\n",
        "    with open(filename, 'rb') as file:\n",
        "        loaded_list = pickle.load(file)\n",
        "    return loaded_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional encodings"
      ],
      "metadata": {
        "id": "k1supvKOjMcc"
      },
      "id": "k1supvKOjMcc"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.set_num_threads(1)\n",
        "from torch import nn\n",
        "import math\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, vocab_size=5000, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(vocab_size, d_model)\n",
        "        position = torch.arange(0, vocab_size, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2).float()\n",
        "            * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, : x.size(1), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "cW2426-sjKcT"
      },
      "id": "cW2426-sjKcT",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import IMDB data set"
      ],
      "metadata": {
        "id": "FLf7rXaojaq9"
      },
      "id": "FLf7rXaojaq9"
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "import io\n",
        "import tarfile\n",
        "import tempfile\n",
        "\n",
        "\n",
        "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/35t-FeC-2uN1ozOwPs7wFg.gz')\n",
        "tar = tarfile.open(fileobj=io.BytesIO(urlopened.read()))\n",
        "tempdir = tempfile.TemporaryDirectory()\n",
        "tar.extractall(tempdir.name)\n",
        "tar.close()"
      ],
      "metadata": {
        "id": "l2cFWCUXjbQr"
      },
      "id": "l2cFWCUXjbQr",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4UM6Sg5gjjoS"
      },
      "id": "4UM6Sg5gjjoS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}