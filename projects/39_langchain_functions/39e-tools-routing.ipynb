{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b815ef73",
   "metadata": {},
   "source": [
    "# Tools and Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139c45e6-65a4-4fcb-a109-e5ba41a80835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a17f623-9342-46bd-a913-9ea6be32a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for weather online\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db510949-acb8-4f69-b6c9-242b84fdc63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c12426-5e1a-4057-8ae5-6dfb6beace97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Search for weather online'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d1c4e6-8313-41a0-ae7a-61343699cb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8765af16-17fc-4490-98ab-4e9dd59337cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"Thing to search for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d20261-e18f-4989-808c-c4f36643d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(args_schema=SearchInput)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for the weather online.\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b3f7d0-a856-4842-82da-6c00df53e9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'Thing to search for',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "060dc15b-f95f-47ab-b081-d6736f277ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42f'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"sf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e93b85b2-1786-4f63-8e65-cd6a8b5c0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(\n",
    "        ..., description=\"Latitude of the location to fetch weather data for\"\n",
    "    )\n",
    "    longitude: float = Field(\n",
    "        ..., description=\"Longitude of the location to fetch weather data for\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "\n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"hourly\": \"temperature_2m\",\n",
    "        \"forecast_days\": 1,\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "    time_list = [\n",
    "        datetime.fromisoformat(time_str.replace(\"Z\", \"+00:00\"))\n",
    "        for time_str in results[\"hourly\"][\"time\"]\n",
    "    ]\n",
    "    temperature_list = results[\"hourly\"][\"temperature_2m\"]\n",
    "\n",
    "    closest_time_index = min(\n",
    "        range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time)\n",
    "    )\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "\n",
    "    return f\"The current temperature is {current_temperature}°C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "731ed353-a27d-42df-89a8-9767bafb23be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f62eb8-c528-4e4a-b078-22e9d9b20a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fetch current temperature for given coordinates.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38ebb59f-cf0f-4281-99c3-87c8cfd3377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
       "  'title': 'Latitude',\n",
       "  'type': 'number'},\n",
       " 'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
       "  'title': 'Longitude',\n",
       "  'type': 'number'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36aacbec-9cdd-414a-b502-168cea350a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6277b6a8-f197-4057-a96a-5ebb61e18520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_temperature',\n",
       " 'description': 'Fetch current temperature for given coordinates.',\n",
       " 'parameters': {'properties': {'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
       "    'type': 'number'},\n",
       "   'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
       "    'type': 'number'}},\n",
       "  'required': ['latitude', 'longitude'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_openai_function(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e088eceb-424b-4da6-981f-63322c9ac56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 26.7°C'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.invoke({\"latitude\": 13, \"longitude\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eefc272-d205-4bad-ab00-282ccb3cc2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            wikipedia.exceptions.PageError,\n",
    "            wikipedia.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "289c5d0c-0e71-4d70-963f-9d9f58e53d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_wikipedia'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69756d79-ec2f-4185-89af-d14de817fc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Run Wikipedia search and get page summaries.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b876cd-cc6c-484d-a3fa-d8810e22d564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_wikipedia',\n",
       " 'description': 'Run Wikipedia search and get page summaries.',\n",
       " 'parameters': {'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_openai_function(search_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dfb10e9-5d1e-474a-9c8f-7abdf7939a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Model Context Protocol\n",
      "Summary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information. With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM's pre-existing training data. This allows LLMs to use domain-specific and/or updated information that is not available in the training data. For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\n",
      "RAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have caused chatbots to describe policies that don't exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.\n",
      "RAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs. Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\n",
      "The term RAG was first introduced in a 2020 research paper from Meta.\n"
     ]
    }
   ],
   "source": [
    "print(search_wikipedia.invoke({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54cbe57e-f64c-4392-bcdd-9621fe1e46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
    "from langchain_community.utilities.openapi import OpenAPISpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fe38e50-874c-49bd-8681-f95dcab0b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "{\n",
    "  \"openapi\": \"3.1.0\",\n",
    "  \"info\": {\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"title\": \"Swagger Petstore\",\n",
    "    \"license\": {\n",
    "      \"name\": \"MIT\"\n",
    "    }\n",
    "  },\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"url\": \"http://petstore.swagger.io/v1\"\n",
    "    }\n",
    "  ],\n",
    "  \"paths\": {\n",
    "    \"/pets\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"List all pets\",\n",
    "        \"operationId\": \"listPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"limit\",\n",
    "            \"in\": \"query\",\n",
    "            \"description\": \"How many items to return at one time (max 100)\",\n",
    "            \"required\": false,\n",
    "            \"schema\": {\n",
    "              \"type\": \"integer\",\n",
    "              \"maximum\": 100,\n",
    "              \"format\": \"int32\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"A paged array of pets\",\n",
    "            \"headers\": {\n",
    "              \"x-next\": {\n",
    "                \"description\": \"A link to the next page of responses\",\n",
    "                \"schema\": {\n",
    "                  \"type\": \"string\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pets\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"post\": {\n",
    "        \"summary\": \"Create a pet\",\n",
    "        \"operationId\": \"createPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"201\": {\n",
    "            \"description\": \"Null response\"\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"/pets/{petId}\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"Info for a specific pet\",\n",
    "        \"operationId\": \"showPetById\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"petId\",\n",
    "            \"in\": \"path\",\n",
    "            \"required\": true,\n",
    "            \"description\": \"The id of the pet to retrieve\",\n",
    "            \"schema\": {\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"Expected response to a valid request\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pet\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"components\": {\n",
    "    \"schemas\": {\n",
    "      \"Pet\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"id\",\n",
    "          \"name\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"id\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int64\"\n",
    "          },\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"tag\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Pets\": {\n",
    "        \"type\": \"array\",\n",
    "        \"maxItems\": 100,\n",
    "        \"items\": {\n",
    "          \"$ref\": \"#/components/schemas/Pet\"\n",
    "        }\n",
    "      },\n",
    "      \"Error\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"code\",\n",
    "          \"message\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"code\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int32\"\n",
    "          },\n",
    "          \"message\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "653156d4-d6a4-499b-aab3-cf4f7b1f0c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = OpenAPISpec.from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9ba6100-3c88-4b05-af93-784b57bf7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91199697-c662-438f-8c68-e6daa8aad07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'listPets',\n",
       "  'description': 'List all pets',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'params': {'type': 'object',\n",
       "     'properties': {'limit': {'type': 'integer',\n",
       "       'maximum': 100.0,\n",
       "       'schema_format': 'int32',\n",
       "       'description': 'How many items to return at one time (max 100)'}},\n",
       "     'required': []}}}},\n",
       " {'name': 'createPets',\n",
       "  'description': 'Create a pet',\n",
       "  'parameters': {'type': 'object', 'properties': {}}},\n",
       " {'name': 'showPetById',\n",
       "  'description': 'Info for a specific pet',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'path_params': {'type': 'object',\n",
       "     'properties': {'petId': {'type': 'string',\n",
       "       'description': 'The id of the pet to retrieve'}},\n",
       "     'required': ['petId']}}}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_openai_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae8b3c1b-7a30-4b1b-abfd-e56f90b1d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed100888-f3d4-4739-bba5-f839033850a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0).bind(functions=pet_openai_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4063cdea-627c-4cc1-a2b5-9b5b6dcf179e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"params\":{\"limit\":3}}', 'name': 'listPets'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 123, 'total_tokens': 139, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxJLxNva8jkJdCLqJqvyezO0OFPcM', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--dcb9e996-ffd3-412c-8445-11c12ba762fb-0', usage_metadata={'input_tokens': 123, 'output_tokens': 16, 'total_tokens': 139, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what are three pets names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a1f5534-cf06-4baf-b710-f169ea7434ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"path_params\":{\"petId\":\"42\"}}', 'name': 'showPetById'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 126, 'total_tokens': 145, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxJLxbqwlRQDGzCXMf3IG0JD5UDiu', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--54a3b77c-2b42-4ea0-92c1-faf438eec3fc-0', usage_metadata={'input_tokens': 126, 'output_tokens': 19, 'total_tokens': 145, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"tell me about pet with id 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b21dd-c9de-491d-9a0c-71ae56727689",
   "metadata": {},
   "source": [
    "### Routing\n",
    "\n",
    "In lesson 3, we show an example of function calling deciding between two candidate functions.\n",
    "\n",
    "Given our tools above, let's format these as OpenAI functions and show this same behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8137758c-c5d3-47df-9062-5e31d43657e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    convert_to_openai_function(f)\n",
    "    for f in [search_wikipedia, get_current_temperature]\n",
    "]\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99120542-36bc-4ed1-aa9e-e2294e282c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 105, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxJLyUjqUrbO64H4Wpqrct3c9xala', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--eb81c464-c672-4cd6-a75d-be91952efb08-0', usage_metadata={'input_tokens': 105, 'output_tokens': 25, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the weather in sf right now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a20047d9-4b34-4e6c-9407-570af1559bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 101, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxJLy2skBTXsxYtCwuEKmY4qyDwd2', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--52a788bb-b4c5-4592-b443-b43d3167daf1-0', usage_metadata={'input_tokens': 101, 'output_tokens': 16, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "831a0506-1d5c-4bc3-b67f-24e201a4fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9c32ccc-6691-4dd5-98dc-aabf02563ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 113, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BxJMjAeBq68pnpkB1Q8y8fyHvZF1w', 'service_tier': 'default', 'finish_reason': 'function_call', 'logprobs': None}, id='run--596bff2f-ee6f-4c3e-a427-403eb73ab051-0', usage_metadata={'input_tokens': 113, 'output_tokens': 25, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "921e808c-6618-4d2f-85df-1f3089497724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "094baef1-4140-41f4-9111-ff9710826e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f105e8e8-d418-4d4a-95eb-52636d4e890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "409b26c0-a1e0-4225-ae2e-396c1f76bf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentActionMessageLog"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cdde008-4b11-4ab2-a01c-6ae394a7dccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66ffb308-3d77-4acb-b4b5-e2b0d38f3860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07e661b1-6d0d-43b9-9de4-19c6cceff291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 17.6°C'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.invoke(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "057e3072-a203-4a5e-b1f6-b250cd7bd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5be6bc0f-5b81-49fa-ac16-b8896847d87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentFinish"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd128d20-f552-4cc5-a45e-f47b58c9982b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'Well, hello there! How can I assist you today?'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.return_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "134f422a-b72b-40df-9552-cf9f9fc2d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "\n",
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result.tool].run(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fefc329-b270-4ebb-b884-430e4e541e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2dcb4b2-0e0d-425b-bff8-db7cd33afa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "498d487b-ceba-4e9f-8a24-0f8c27438a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 17.6°C'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c93eb1b-044f-4c52-bcd4-dcd0e01f42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"What is langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c0de3e7-2367-4cef-b3dd-efa69b701061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Model Context Protocol\\nSummary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.\\n\\nPage: Retrieval-augmented generation\\nSummary: Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information. With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM\\'s pre-existing training data. This allows LLMs to use domain-specific and/or updated information that is not available in the training data. For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\\nRAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have caused chatbots to describe policies that don\\'t exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.\\nRAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs. Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\\nThe term RAG was first introduced in a 2020 research paper from Meta.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a353363e-27b8-440f-a8b7-31bc2e861a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hi!\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-agents-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
