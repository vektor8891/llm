{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/13_translation/13_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "\n",
                "# A Transformer Model for Language Translation"
            ],
            "metadata": {
                "id": "dixAaSDb6bD3"
            },
            "id": "dixAaSDb6bD3"
        },
        {
            "cell_type": "code",
            "source": [
                "# !pip install torchtext==0.15.1\n",
                "# !pip install portalocker\n",
                "# !pip install torch==2.0.0\n",
                "# !pip install pdfplumber==0.9.0\n",
                "# !pip install fpdf==1.7.2\n",
                "\n",
                "# !python -m spacy download de_core_news_sm\n",
                "# !python -m spacy download en_core_web_sm\n",
                "\n",
                "# !wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/Multi30K_de_en_dataloader.py'\n",
                "# !wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/transformer.pt'\n",
                "# !wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf'"
            ],
            "metadata": {
                "id": "MHAyHNYQfn3_"
            },
            "id": "MHAyHNYQfn3_",
            "execution_count": 1,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## DataLoader"
            ],
            "metadata": {
                "id": "ZZZcm6fH_Z9D"
            },
            "id": "ZZZcm6fH_Z9D"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "fec843df",
            "metadata": {
                "id": "fec843df"
            },
            "outputs": [],
            "source": [
                "%run Multi30K_de_en_dataloader.py"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "train_dataloader, _ = get_translation_dataloaders(batch_size = 1)\n",
                "data_itr=iter(train_dataloader)\n",
                "for n in range(1000):\n",
                "    german, english= next(data_itr)\n",
                "german=german.T\n",
                "english=english.T\n",
                "\n",
                "for n in range(10):\n",
                "    german, english= next(data_itr)\n",
                "\n",
                "    print(\"sample {}\".format(n))\n",
                "    print(\"german input\")\n",
                "    print(index_to_german(german))\n",
                "    print(\"english target\")\n",
                "    print(index_to_eng(english))\n",
                "    print(\"_________\\n\")"
            ],
            "metadata": {
                "id": "_wWKnSNY_bqI",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "outputId": "51dc041f-7261-4ce9-d553-dc771713055c"
            },
            "id": "_wWKnSNY_bqI",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/content/Multi30K_de_en_dataloader.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  src_sequences = torch.tensor(src_sequences, dtype=torch.int64)\n",
                        "/content/Multi30K_de_en_dataloader.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  tgt_sequences = torch.tensor(tgt_sequences, dtype=torch.int64)\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "sample 0\n",
                        "german input\n",
                        "<bos> Ein Feuerwehrangeh\u00f6riger arbeitet bei einem Brand . <eos>\n",
                        "english target\n",
                        "<bos> A firefighter is working at a fire . <eos>\n",
                        "_________\n",
                        "\n",
                        "sample 1\n",
                        "german input\n",
                        "<bos> Ein Mann spielt auf einem Fl\u00fcgel . <eos>\n",
                        "english target\n",
                        "<bos> A man playing a black grand piano . <eos>\n",
                        "_________\n",
                        "\n",
                        "sample 2\n",
                        "german input\n",
                        "<bos> Ein brauner Hund spielt im Schnee . <eos>\n",
                        "english target\n",
                        "<bos> A brown dog plays in the snow . <eos>\n",
                        "_________\n",
                        "\n",
                        "sample 3\n",
                        "german input\n",
                        "<bos> Mehrere Hunde in einem winterlichen Ambiente . <eos>\n",
                        "english target\n",
                        "<bos> Several dogs grouped together in a winter setting . <eos>\n",
                        "_________\n",
                        "\n",
                        "sample 4\n",
                        "german input\n",
                        "<bos> Ein Mann klettert einen Felsen hoch . <eos>\n",
                        "english target\n",
                        "<bos> A man climbs up a rock . <eos>\n",
                        "_________\n",
                        "\n",
                        "sample 5\n",
                        "german input\n",
                        "<bos> Zwei Teams k\u00e4mpfen um den Sieg . <eos>\n",
                        "english target\n",
                        "<bos> Two teams battle it out for the win ! <eos>\n",
                        "_________\n",
                        "\n",
                        "sample 6\n",
                        "german input\n",
                        "<bos> Kinder spielen in einem aufblasbaren Spielplatz . <eos>\n",
                        "english target\n",
                        "<bos> Kids play in a blow up playground . <eos>\n",
                        "_________\n",
                        "\n",
                        "sample 7\n",
                        "german input\n",
                        "<bos> Ein kleiner Junge malt einen Teller . <eos>\n",
                        "english target\n",
                        "<bos> A little boy is paining a plate . <eos>\n",
                        "_________\n",
                        "\n",
                        "sample 8\n",
                        "german input\n",
                        "<bos> Die beiden Frauen blicken auf etwas . <eos>\n",
                        "english target\n",
                        "<bos> The two woman are looking at something . <eos>\n",
                        "_________\n",
                        "\n",
                        "sample 9\n",
                        "german input\n",
                        "<bos> F\u00fcnf Kricketspieler liegen auf dem Gras . <eos>\n",
                        "english target\n",
                        "<bos> Five cricket players are lounging on the grass . <eos>\n",
                        "_________\n",
                        "\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "import torch\n",
                "\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "DEVICE"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "yBq_DoRhoRVC",
                "outputId": "da4a18b7-418f-43aa-8d6d-4adc4bab63c8"
            },
            "id": "yBq_DoRhoRVC",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "device(type='cpu')"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Important concepts\n",
                "\n",
                "### Masking"
            ],
            "metadata": {
                "id": "QBDa5tzooj06"
            },
            "id": "QBDa5tzooj06"
        },
        {
            "cell_type": "code",
            "source": [
                "# produces an upper triangular matrix, which ensures that during decoding, a token can't attend to future tokens\n",
                "def generate_square_subsequent_mask(sz,device=DEVICE):\n",
                "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
                "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
                "    return mask\n",
                "\n",
                "# generates both source and target masks, as well as padding masks\n",
                "def create_mask(src, tgt,device=DEVICE):\n",
                "    src_seq_len = src.shape[0]\n",
                "    tgt_seq_len = tgt.shape[0]\n",
                "\n",
                "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
                "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
                "\n",
                "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
                "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
                "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
            ],
            "metadata": {
                "id": "18wQZyvyogA9"
            },
            "id": "18wQZyvyogA9",
            "execution_count": 5,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Positional encoding"
            ],
            "metadata": {
                "id": "1fLtRzhfpCbQ"
            },
            "id": "1fLtRzhfpCbQ"
        },
        {
            "cell_type": "code",
            "source": [
                "import torch.nn as nn\n",
                "from torch import Tensor\n",
                "\n",
                "# Add positional information to the input tokens\n",
                "class PositionalEncoding(nn.Module):\n",
                "    def __init__(self,\n",
                "                 emb_size: int,\n",
                "                 dropout: float,\n",
                "                 maxlen: int = 5000):\n",
                "        super(PositionalEncoding, self).__init__()\n",
                "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
                "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
                "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
                "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
                "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
                "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
                "\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        self.register_buffer('pos_embedding', pos_embedding)\n",
                "\n",
                "    def forward(self, token_embedding: Tensor):\n",
                "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
            ],
            "metadata": {
                "id": "SsENiBXWo_La"
            },
            "id": "SsENiBXWo_La",
            "execution_count": 6,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Token embedding"
            ],
            "metadata": {
                "id": "hyb-5d3upKOL"
            },
            "id": "hyb-5d3upKOL"
        },
        {
            "cell_type": "code",
            "source": [
                "import math\n",
                "\n",
                "class TokenEmbedding(nn.Module):\n",
                "    def __init__(self, vocab_size: int, emb_size):\n",
                "        super(TokenEmbedding, self).__init__()\n",
                "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
                "        self.emb_size = emb_size\n",
                "\n",
                "    def forward(self, tokens: Tensor):\n",
                "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
            ],
            "metadata": {
                "id": "Yx-GjJn3pD2a"
            },
            "id": "Yx-GjJn3pD2a",
            "execution_count": 7,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Seq2SeqTransformer"
            ],
            "metadata": {
                "id": "P9sypxQ4pRe8"
            },
            "id": "P9sypxQ4pRe8"
        },
        {
            "cell_type": "code",
            "source": [
                "from torch.nn import Transformer\n",
                "\n",
                "class Seq2SeqTransformer(nn.Module):\n",
                "    def __init__(self,\n",
                "                 num_encoder_layers: int,\n",
                "                 num_decoder_layers: int,\n",
                "                 emb_size: int,\n",
                "                 nhead: int,\n",
                "                 src_vocab_size: int,\n",
                "                 tgt_vocab_size: int,\n",
                "                 dim_feedforward: int = 512,\n",
                "                 dropout: float = 0.1):\n",
                "        super(Seq2SeqTransformer, self).__init__()\n",
                "\n",
                "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
                "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
                "        self.positional_encoding = PositionalEncoding(\n",
                "            emb_size, dropout=dropout)\n",
                "        self.transformer = Transformer(d_model=emb_size,\n",
                "                                       nhead=nhead,\n",
                "                                       num_encoder_layers=num_encoder_layers,\n",
                "                                       num_decoder_layers=num_decoder_layers,\n",
                "                                       dim_feedforward=dim_feedforward,\n",
                "                                       dropout=dropout)\n",
                "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
                "\n",
                "    def forward(self,\n",
                "                src: Tensor,\n",
                "                trg: Tensor,\n",
                "                src_mask: Tensor,\n",
                "                tgt_mask: Tensor,\n",
                "                src_padding_mask: Tensor,\n",
                "                tgt_padding_mask: Tensor,\n",
                "                memory_key_padding_mask: Tensor):\n",
                "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
                "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
                "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
                "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
                "        outs =outs.to(DEVICE)\n",
                "        return self.generator(outs)\n",
                "\n",
                "    def encode(self, src: Tensor, src_mask: Tensor):\n",
                "        return self.transformer.encoder(self.positional_encoding(\n",
                "                            self.src_tok_emb(src)), src_mask)\n",
                "\n",
                "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
                "        return self.transformer.decoder(self.positional_encoding(\n",
                "                          self.tgt_tok_emb(tgt)), memory,\n",
                "                          tgt_mask)"
            ],
            "metadata": {
                "id": "PAKKubTRpMO4"
            },
            "id": "PAKKubTRpMO4",
            "execution_count": 8,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Inference"
            ],
            "metadata": {
                "id": "HybJvw_npxWv"
            },
            "id": "HybJvw_npxWv"
        },
        {
            "cell_type": "code",
            "source": [
                "torch.manual_seed(0)\n",
                "\n",
                "SRC_LANGUAGE = 'de'\n",
                "TGT_LANGUAGE = 'en'\n",
                "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
                "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
                "EMB_SIZE = 512\n",
                "NHEAD = 8\n",
                "FFN_HID_DIM = 512\n",
                "BATCH_SIZE = 128\n",
                "NUM_ENCODER_LAYERS = 3\n",
                "NUM_DECODER_LAYERS = 3\n",
                "\n",
                "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
                "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
                "\n",
                "for p in transformer.parameters():\n",
                "    if p.dim() > 1:\n",
                "        nn.init.xavier_uniform_(p)\n",
                "\n",
                "transformer = transformer.to(DEVICE)"
            ],
            "metadata": {
                "id": "Qx9XPtHDpxrI"
            },
            "id": "Qx9XPtHDpxrI",
            "execution_count": 9,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# load transformer model weights from file\n",
                "transformer.load_state_dict(torch.load('transformer.pt', map_location=DEVICE, ))\n",
                "\n",
                "# iterate through dataset to get longer sequence\n",
                "for n in range(100):\n",
                "    src ,tgt= next(data_itr)\n",
                "\n",
                "# display source & target\n",
                "print(\"engish target\",index_to_eng(tgt))\n",
                "print(\"german input\",index_to_german(src))"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "Lp8NPevFp0NA",
                "outputId": "878d3ae9-253c-4264-a72b-031d21523014"
            },
            "id": "Lp8NPevFp0NA",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "engish target <bos> A worker taking a reading on a subway train . <eos>\n",
                        "german input <bos> Ein Arbeiter liest in einem U-Bahn-Zug . <eos>\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
                "    src = src.to(DEVICE)\n",
                "    src_mask = src_mask.to(DEVICE)\n",
                "\n",
                "    memory = model.encode(src, src_mask)\n",
                "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
                "    for i in range(max_len-1):\n",
                "        memory = memory.to(DEVICE)\n",
                "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
                "                    .type(torch.bool)).to(DEVICE)\n",
                "        out = model.decode(ys, memory, tgt_mask)\n",
                "        out = out.transpose(0, 1)\n",
                "        prob = model.generator(out[:, -1])\n",
                "        _, next_word = torch.max(prob, dim=1)\n",
                "        next_word = next_word.item()\n",
                "\n",
                "        ys = torch.cat([ys,\n",
                "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
                "        if next_word == EOS_IDX:\n",
                "            break\n",
                "    return ys"
            ],
            "metadata": {
                "id": "gnParpPup53d"
            },
            "id": "gnParpPup53d",
            "execution_count": 11,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "num_tokens = src.shape[0]\n",
                "src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool).to(DEVICE )\n",
                "max_len=src.shape[0]+5\n",
                "ys=greedy_decode(transformer, src, src_mask, max_len, start_symbol=BOS_IDX)\n",
                "\n",
                "# compare translation using greedy decode\n",
                "print(\"engish \",index_to_eng(ys))\n",
                "print(\"engish \",index_to_eng(tgt))"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "x6pPvQsHqXhV",
                "outputId": "c2dc761b-9c60-452c-b9f7-5370ae05d1f4"
            },
            "id": "x6pPvQsHqXhV",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "engish  <bos> A worker is reading a subway book . <eos>\n",
                        "engish  <bos> A worker taking a reading on a subway train . <eos>\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Evaluate"
            ],
            "metadata": {
                "id": "Hb5IadxUrDMn"
            },
            "id": "Hb5IadxUrDMn"
        },
        {
            "cell_type": "code",
            "source": [
                "def evaluate(model):\n",
                "    model.eval()\n",
                "    losses = 0\n",
                "\n",
                "    for src, tgt in val_dataloader:\n",
                "        src = src.to(DEVICE)\n",
                "        tgt = tgt.to(DEVICE)\n",
                "\n",
                "        tgt_input = tgt[:-1, :]\n",
                "\n",
                "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
                "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
                "\n",
                "        tgt_out = tgt[1:, :]\n",
                "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
                "        losses += loss.item()\n",
                "\n",
                "    return losses / len(list(val_dataloader))"
            ],
            "metadata": {
                "id": "x2WHxdkHqw1-"
            },
            "id": "x2WHxdkHqw1-",
            "execution_count": 14,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Training the model"
            ],
            "metadata": {
                "id": "VLLo7xrkrIAg"
            },
            "id": "VLLo7xrkrIAg"
        },
        {
            "cell_type": "code",
            "source": [
                "# def train_epoch(model, optimizer, train_dataloader):\n",
                "#     model.train()\n",
                "#     losses = 0\n",
                "\n",
                "#     # Wrap train_dataloader with tqdm for progress logging\n",
                "#     train_iterator = tqdm(train_dataloader, desc=\"Training\", leave=False)\n",
                "\n",
                "#     for src, tgt in train_iterator:\n",
                "#         src = src.to(DEVICE)\n",
                "#         tgt = tgt.to(DEVICE)\n",
                "\n",
                "#         tgt_input = tgt[:-1, :]\n",
                "\n",
                "#         src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
                "#         src_mask = src_mask.to(DEVICE)\n",
                "#         tgt_mask = tgt_mask.to(DEVICE)\n",
                "#         src_padding_mask = src_padding_mask.to(DEVICE)\n",
                "#         tgt_padding_mask = tgt_padding_mask.to(DEVICE)\n",
                "\n",
                "#         logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
                "#         logits = logits.to(DEVICE)\n",
                "\n",
                "#         optimizer.zero_grad()\n",
                "\n",
                "#         tgt_out = tgt[1:, :]\n",
                "#         loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
                "#         loss.backward()\n",
                "\n",
                "#         optimizer.step()\n",
                "#         losses += loss.item()\n",
                "\n",
                "#         # Update tqdm progress bar with the current loss\n",
                "#         train_iterator.set_postfix(loss=loss.item())\n",
                "\n",
                "#     return losses / len(list(train_dataloader))\n",
                "\n",
                "# torch.manual_seed(0)\n",
                "\n",
                "# SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
                "# TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
                "# EMB_SIZE = 512\n",
                "# NHEAD = 8\n",
                "# FFN_HID_DIM = 512\n",
                "# BATCH_SIZE = 128\n",
                "# NUM_ENCODER_LAYERS = 3\n",
                "# NUM_DECODER_LAYERS = 3\n",
                "\n",
                "\n",
                "# train_dataloader, val_dataloader = get_translation_dataloaders(batch_size = BATCH_SIZE)\n",
                "# transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
                "#                                  NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
                "# transformer = transformer.to(DEVICE)\n",
                "# optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
                "# TrainLoss=[]\n",
                "# ValLoss=[]\n",
                "\n",
                "# # Train the model for 10 epochs\n",
                "# from timeit import default_timer as timer\n",
                "# NUM_EPOCHS = 10\n",
                "\n",
                "# for epoch in range(1, NUM_EPOCHS+1):\n",
                "#     start_time = timer()\n",
                "#     train_loss = train_epoch(transformer, optimizer, train_dataloader)\n",
                "#     TrainLoss.append(train_loss)\n",
                "#     end_time = timer()\n",
                "#     val_loss = evaluate(transformer)\n",
                "#     ValLoss.append(val_loss)\n",
                "#     print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
                "# torch.save(transformer.state_dict(), 'transformer_de_to_en_model.pt')\n",
                "\n",
                "# # Plot the loss for the training and validation data.\n",
                "# import matplotlib.pyplot as plt\n",
                "\n",
                "# epochs = range(1, len(TrainLoss) + 1)\n",
                "\n",
                "# plt.figure(figsize=(10, 5))\n",
                "# plt.plot(epochs, TrainLoss, 'r', label='Training loss')\n",
                "# plt.plot(epochs,ValLoss, 'b', label='Validation loss')\n",
                "# plt.title('Training and Validation loss')\n",
                "# plt.xlabel('Epochs')\n",
                "# plt.ylabel('Loss')\n",
                "# plt.legend()\n",
                "# plt.show()"
            ],
            "metadata": {
                "id": "HuPPLzhZrGHs"
            },
            "id": "HuPPLzhZrGHs",
            "execution_count": 15,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Loading the saved model"
            ],
            "metadata": {
                "id": "fFph8AbHrmMQ"
            },
            "id": "fFph8AbHrmMQ"
        },
        {
            "cell_type": "code",
            "source": [
                "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/transformer_de_to_en_model.pt'\n",
                "transformer.load_state_dict(torch.load('transformer_de_to_en_model.pt',map_location=torch.device('cpu')))"
            ],
            "metadata": {
                "id": "Bt8WsjHArl4C",
                "outputId": "e876bd38-ef84-4a79-9946-9679178c8236",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "Bt8WsjHArl4C",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "--2025-04-25 20:46:08--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/transformer_de_to_en_model.pt\n",
                        "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
                        "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
                        "HTTP request sent, awaiting response... 200 OK\n",
                        "Length: 144561810 (138M) [binary/octet-stream]\n",
                        "Saving to: \u2018transformer_de_to_en_model.pt.1\u2019\n",
                        "\n",
                        "transformer_de_to_e 100%[===================>] 137.86M  91.6MB/s    in 1.5s    \n",
                        "\n",
                        "2025-04-25 20:46:10 (91.6 MB/s) - \u2018transformer_de_to_en_model.pt.1\u2019 saved [144561810/144561810]\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<All keys matched successfully>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 16
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Translation and evaluation"
            ],
            "metadata": {
                "id": "D7hzuNFXr4gN"
            },
            "id": "D7hzuNFXr4gN"
        },
        {
            "cell_type": "code",
            "source": [
                "# translate input sentence into target language\n",
                "def translate(model: torch.nn.Module, src_sentence: str):\n",
                "    model.eval()\n",
                "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
                "    num_tokens = src.shape[0]\n",
                "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
                "    tgt_tokens = greedy_decode(\n",
                "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
                "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
            ],
            "metadata": {
                "id": "fToQr9A0r2b6"
            },
            "id": "fToQr9A0r2b6",
            "execution_count": 17,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# !pip install \"numpy<2\""
            ],
            "metadata": {
                "id": "wQuhFpfasVLl"
            },
            "id": "wQuhFpfasVLl",
            "execution_count": 18,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "for n in range(5):\n",
                "    german, english= next(data_itr)\n",
                "\n",
                "    print(\"German Sentence:\",index_to_german(german).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
                "    print(\"English Translation:\",index_to_eng(english).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\"))\n",
                "    print(\"Model Translation:\",translate(transformer,index_to_german(german)))\n",
                "    print(\"_________\\n\")"
            ],
            "metadata": {
                "id": "MeqaIIzir5-t",
                "outputId": "43ec83aa-8009-451e-c09b-25d2df8fad45",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "MeqaIIzir5-t",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "German Sentence:  M\u00e4nner stehen neben irgendeiner hydraulischen Maschine . \n",
                        "English Translation:  Men are standing next to some sort of hydraulic machine . \n",
                        "Model Translation:  Men are standing next to some sort of fishing concrete concrete concrete concrete concrete concrete concrete concrete concrete concrete\n",
                        "_________\n",
                        "\n",
                        "German Sentence:  Zwei Arbeiter reinigen nachts ein Bauwerk . \n",
                        "English Translation:  Two workers are cleaning a structure at night . \n",
                        "Model Translation:  Two workers are installing a bunch of concrete concrete concrete concrete concrete concrete concrete concrete concrete concrete concrete concrete\n",
                        "_________\n",
                        "\n",
                        "German Sentence:  Sieben Bauarbeiter arbeiten an einem Geb\u00e4ude . \n",
                        "English Translation:  Seven construction workers working on a building . \n",
                        "Model Translation:  Seven construction workers are working on a concrete building . \n",
                        "_________\n",
                        "\n",
                        "German Sentence:  Die Kinder spielen nachts mit Wunderkerzen . \n",
                        "English Translation:  The children play with sparklers at night . \n",
                        "Model Translation:  The children play with a bike . \n",
                        "_________\n",
                        "\n",
                        "German Sentence:  Ein \u00e4lteres Paar geht zusammen spazieren . \n",
                        "English Translation:  An older couple taking a walk together . \n",
                        "Model Translation:  An older couple walk together in a park area where there are a couple is a body of water\n",
                        "_________\n",
                        "\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Evaluation with BLEU score"
            ],
            "metadata": {
                "id": "DqLayF0bs-gQ"
            },
            "id": "DqLayF0bs-gQ"
        },
        {
            "cell_type": "code",
            "source": [
                "from nltk.translate.bleu_score import sentence_bleu\n",
                "\n",
                "def calculate_bleu_score(generated_translation, reference_translations):\n",
                "    # convert the generated translations and reference translations into the expected format for sentence_bleu\n",
                "    references = [reference.split() for reference in reference_translations]\n",
                "    hypothesis = generated_translation.split()\n",
                "\n",
                "    # calculate the BLEU score\n",
                "    bleu_score = sentence_bleu(references, hypothesis)\n",
                "\n",
                "    return bleu_score"
            ],
            "metadata": {
                "id": "jzSu2lz8r79F"
            },
            "id": "jzSu2lz8r79F",
            "execution_count": 22,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "generated_translation = translate(transformer,\"Ein brauner Hund spielt im Schnee .\")\n",
                "\n",
                "reference_translations = [\n",
                "    \"A brown dog is playing in the snow .\",\n",
                "    \"A brown dog plays in the snow .\",\n",
                "    \"A brown dog is frolicking in the snow .\",\n",
                "    \"In the snow, a brown dog is playing .\"\n",
                "\n",
                "]\n",
                "\n",
                "bleu_score = calculate_bleu_score(generated_translation, reference_translations)\n",
                "print(\"BLEU Score:\", bleu_score, \"for\",generated_translation)"
            ],
            "metadata": {
                "id": "dnXwwSmTtAxD",
                "outputId": "efc51723-7830-45e4-ceb7-8547414f5e55",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "dnXwwSmTtAxD",
            "execution_count": 23,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "BLEU Score: 1.0 for  A brown dog plays in the snow . \n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Exercise: Translating a document"
            ],
            "metadata": {
                "id": "0Nw0d8V1tJph"
            },
            "id": "0Nw0d8V1tJph"
        },
        {
            "cell_type": "code",
            "source": [
                "import pdfplumber\n",
                "import textwrap\n",
                "from fpdf import FPDF\n",
                "\n",
                "def translate_pdf(input_file, translator_model,output_file):\n",
                "    translated_text = \"\"\n",
                "\n",
                "    # Read the input PDF file\n",
                "    with pdfplumber.open(input_file) as pdf:\n",
                "\n",
                "\n",
                "        # Extract text from each page of the PDF\n",
                "        for page in pdf.pages:\n",
                "            text_content = page.extract_text()\n",
                "            num_pages = len(pdf.pages)\n",
                "            a4_width_mm = 210\n",
                "            pt_to_mm = 0.35\n",
                "            fontsize_pt = 10\n",
                "            fontsize_mm = fontsize_pt * pt_to_mm\n",
                "            margin_bottom_mm = 10\n",
                "            character_width_mm = 7 * pt_to_mm\n",
                "            width_text = a4_width_mm / character_width_mm\n",
                "\n",
                "            pdf = FPDF(orientation='P', unit='mm', format='A4')\n",
                "            pdf.set_auto_page_break(True, margin=margin_bottom_mm)\n",
                "            pdf.add_page()\n",
                "            pdf.set_font(family='Courier', size=fontsize_pt)\n",
                "            # Split the text into sentences\n",
                "            sentences = text_content.split(\".\")\n",
                "\n",
                "            # Translate each sentence using the custom translator model\n",
                "            for sentence in sentences:\n",
                "                translated_sentence = translate(translator_model,sentence)\n",
                "                lines = textwrap.wrap(translated_sentence, width_text)\n",
                "\n",
                "                if len(lines) == 0:\n",
                "                    pdf.ln()\n",
                "\n",
                "                for wrap in lines:\n",
                "                    pdf.cell(0, fontsize_mm, wrap, ln=1)\n",
                "\n",
                "            pdf.output(output_file, 'F')\n"
            ],
            "metadata": {
                "id": "P0ga14LbtY4x"
            },
            "id": "P0ga14LbtY4x",
            "execution_count": 31,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf'"
            ],
            "metadata": {
                "id": "NKp8-FbPtBHM",
                "outputId": "cef42895-75b0-4277-f87c-1cd6b09db5a5",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "NKp8-FbPtBHM",
            "execution_count": 32,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "--2025-04-25 20:49:50--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/input_de.pdf\n",
                        "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
                        "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
                        "HTTP request sent, awaiting response... 200 OK\n",
                        "Length: 27628 (27K) [application/pdf]\n",
                        "Saving to: \u2018input_de.pdf.3\u2019\n",
                        "\n",
                        "input_de.pdf.3      100%[===================>]  26.98K  --.-KB/s    in 0.02s   \n",
                        "\n",
                        "2025-04-25 20:49:50 (1.39 MB/s) - \u2018input_de.pdf.3\u2019 saved [27628/27628]\n",
                        "\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "input_file_path = \"input_de.pdf\"\n",
                "output_file = 'output_en.pdf'\n",
                "translate_pdf(input_file_path, transformer,output_file)\n",
                "print(\"Translated PDF file is saved as:\", output_file)"
            ],
            "metadata": {
                "id": "jPMfLO_itM_9",
                "outputId": "c7e6234a-f2fc-4def-e923-282b095536d9",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                }
            },
            "id": "jPMfLO_itM_9",
            "execution_count": 33,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Translated PDF file is saved as: output_en.pdf\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!pip freeze > requirements.txt"
            ],
            "metadata": {
                "id": "ZQoOVsFtt4SQ"
            },
            "id": "ZQoOVsFtt4SQ",
            "execution_count": 34,
            "outputs": []
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        },
        "colab": {
            "provenance": [],
            "include_colab_link": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}