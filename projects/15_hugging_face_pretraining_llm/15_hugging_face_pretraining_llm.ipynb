{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "18ac9bdb",
            "metadata": {
                "colab_type": "text",
                "id": "view-in-github"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/15_hugging_face_pretraining_llm/15_hugging_face_pretraining_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4O757ln0ynB4",
            "metadata": {
                "id": "4O757ln0ynB4"
            },
            "source": [
                "# Pretraining and self-supervised fine-tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "zfAW1NfrzVzj",
            "metadata": {
                "id": "zfAW1NfrzVzj"
            },
            "outputs": [],
            "source": [
                "# !pip install datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "5c15035b",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 325,
                    "referenced_widgets": [
                        "07753c56ea1f45cfa1cb7fe17b6922d1",
                        "b4134e5c9ef648be9a3400f082b6768b",
                        "9c4ac74a91194d488cd8f2757b9e8d7e",
                        "afdbb9820c34407dadd20ef0f289a729",
                        "04b8ea0087564d8d87c73c582ffd3c97",
                        "ff9cbcbea6be4f1da3b756babc00e954",
                        "59160e7adae949e6814f481029ab7cac",
                        "dff3a974d0674b868be516852e8f101c",
                        "ce1cba3eaee24e5988602d16854795f6",
                        "66285677fc154b3aadf4eab2a545c003",
                        "1b725a89c1d8479ab30c4c0917e4358f",
                        "dccd5ae8c90b4fe99a64e35a3cd168d3",
                        "dbf66253db8548288201d64cd85f7b8f",
                        "d978ad83a828412999f3477745493611",
                        "ffe5f96d35844914a51bc3cad8dc7802",
                        "70dc8d4601a94adcb4066359609fbd33",
                        "29b8056270024f8584711256d774dbb6",
                        "ea665c37e2054a32974ebf616e41f3a4",
                        "d018f3a7cd9243f8a6a5cdc837e5c31c",
                        "5e796b750a494c138814021290589991",
                        "2e6ad35f01bf49cc9a65297032e1b08b",
                        "c39a1be0628547e495d7556ad3ed69a6",
                        "01df2bbfeb03481f8224caebf0fb51cf",
                        "e4eb15274d7f440ba486a76eab654f6d",
                        "cf58fee0a63f41148259d668085979e9",
                        "eba558b1751b46a3a0be43f7b9ec05a4",
                        "b9062f11bd6e4256a2db7db5e3ef57d8",
                        "b995456d8da34ea1b96f41c4f90b37ce",
                        "f922962e6fc341b4a683d471270e1289",
                        "7a32cb94dcf64806bb216a21d51b0672",
                        "a23670add785492db644e6fc49cc959b",
                        "84a4596a8fa3436a91203dd2b7bf297e",
                        "0a8494f9a2644840a9ae962cd3e99399",
                        "4d9b06cdca3b46fe84c4de8fc73e06a0",
                        "624841c7b81f4d8f9193291a7aaeccdf",
                        "11984face09940ddaa7269e075d2de79",
                        "4b3d9e3efb0d469cb85d5bb811cc53f4",
                        "ab3660831fd4493c82242d167acb3162",
                        "50eec8b2bf784b6c980cbac55a4a615e",
                        "d31b0b59f7d0400aae6100ae424da109",
                        "9c79bde111e74e028655299ec343915c",
                        "117d7cff19974dc098de9bac1e5f3b79",
                        "8c9108fe4f714fcba0fae5da1f07554a",
                        "03aea08cce4c423c9e09e8c50ff5713f",
                        "ec531693ad17432ea77d906e7892be6e",
                        "a37f57e20f7042678804dfe88b265c38",
                        "b427e4a5fd754e7896479a8e7ce2f93d",
                        "ce44dc1f9a5c43179094c3994a8a84f9",
                        "59a3b44e4c014a9faefb4743d70e1239",
                        "248f757b2c004b8cbc23d91c39360914",
                        "4be63fb914634b5d8c0fc679fc216465",
                        "a3f89d18a79f477eb19859437cd78527",
                        "1be0ef78a5e24ba4bff6a8a12e7b8519",
                        "afbd077252a6409d8ad689d9e73538a6",
                        "1050f6d952b54741a5589cd6c450b586",
                        "601d4961d28b48798d4fcb0d9b0a1976",
                        "4d6424c8131548159c16cc0edb193c2b",
                        "45ab2eafb5604dc689756717461ae59a",
                        "e248b4ce54c74b1c88a93a67fea0770d",
                        "dc0e213763c346beacd53ac626740624",
                        "3a87a299db824239a6d790aadafcd66b",
                        "d43092836d4a49ed808df4abde410bb4",
                        "8b7117e794de4cbf9e6ef887b4615a6a",
                        "675409a361954cd38aefd857ec674185",
                        "9fe392849d0b412c8e94f9c5800fe6b0",
                        "0b16a83ca9e84a57a94c3cd986386033",
                        "0e5affb0708744a0a9a040f0089a3689",
                        "5849e78da0654ffeb401c3ff32fb6cec",
                        "4944cd72455f47419fe21909f9815381",
                        "a7b0b068070148cc8b5b4ed59070650d",
                        "35c48a67688c4ce8a58b40c8976f011e",
                        "6af1413883c24227ad034e07e30b293e",
                        "972ea3d9303b41e480b340e1fe2b5dc0",
                        "8d3e3bbbb2dc4c37b18e109aa62e12ef",
                        "f9cf0499137a4ab59e472e29444d6d95",
                        "d55f067c30424063a07355c154fada48",
                        "f1a739b35c6941928f0e6888df38195a",
                        "250da7e017634dc28ce8fe3bc91e85d6",
                        "54783cef20624112a494ea74753b0969",
                        "25f9830f60614f26834fc640d3c1e693",
                        "e6c9055836f94f4abff69489fc0e31f6",
                        "6cb360a3959b4f2e80a778db827bc443",
                        "408a4e92e7bc45278ce38ceb37c29b6e",
                        "225c8056f7394fec8356c8ec4fb4abd2",
                        "fe8895d1408840999a4e20a30f093de5",
                        "1bac861c730545a59639e7ea68aa468f",
                        "b7f48e9753dc404198a1ca5542ec14b8",
                        "cacd3866ff814213b5e270eeab6ce60c"
                    ]
                },
                "id": "5c15035b",
                "outputId": "9152f946-4f77-436c-fed9-4d53b9eda25f"
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "07753c56ea1f45cfa1cb7fe17b6922d1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dccd5ae8c90b4fe99a64e35a3cd168d3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "01df2bbfeb03481f8224caebf0fb51cf",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/662M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4d9b06cdca3b46fe84c4de8fc73e06a0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ec531693ad17432ea77d906e7892be6e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "601d4961d28b48798d4fcb0d9b0a1976",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0e5affb0708744a0a9a040f0089a3689",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "250da7e017634dc28ce8fe3bc91e85d6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Device set to use cpu\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "This movie was really good. I was really surprised by how good it was.\n",
                        "I was\n"
                    ]
                }
            ],
            "source": [
                "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
                "\n",
                "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
                "\n",
                "pipe = pipeline(\"text-generation\", model=model,tokenizer=tokenizer)\n",
                "print(pipe(\"This movie was really\")[0][\"generated_text\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "VQeoAkGrzJh4",
            "metadata": {
                "id": "VQeoAkGrzJh4"
            },
            "source": [
                "## Self-supervised training of a BERT model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "gKTi8BW6yrQo",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "gKTi8BW6yrQo",
                "outputId": "dd4881cc-e391-4356-f2c1-99fb3ddc3d3b"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "DatasetDict({\n",
                        "    test: Dataset({\n",
                        "        features: ['text'],\n",
                        "        num_rows: 4358\n",
                        "    })\n",
                        "    train: Dataset({\n",
                        "        features: ['text'],\n",
                        "        num_rows: 36718\n",
                        "    })\n",
                        "    validation: Dataset({\n",
                        "        features: ['text'],\n",
                        "        num_rows: 3760\n",
                        "    })\n",
                        "})\n",
                        "{'text': \" When Mason was injured in warm @-@ ups late in the year , Columbus was without an active goaltender on their roster . To remedy the situation , the team signed former University of Michigan goaltender Shawn Hunwick to a one @-@ day , amateur tryout contract . After being eliminated from the NCAA Tournament just days prior , Hunwick skipped an astronomy class and drove his worn down 2003 Ford Ranger to Columbus to make the game . He served as the back @-@ up to Allen York during the game , and the following day , he signed a contract for the remainder of the year . With Mason returning from injury , Hunwick was third on the team 's depth chart when an injury to York allowed Hunwick to remain as the back @-@ up for the final two games of the year . In the final game of the season , the Blue Jackets were leading the Islanders 7 \u2013 3 with 2 : 33 remaining when , at the behest of his teammates , Head Coach Todd Richards put Hunwick in to finish the game . He did not face a shot . Hunwick was the franchise record ninth player to make his NHL debut during the season . Conversely , Vaclav Prospal played in his 1,000th NHL game during the year . \\n\"}\n"
                    ]
                }
            ],
            "source": [
                "from datasets import load_dataset\n",
                "\n",
                "# Load the datasets\n",
                "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
                "print(dataset)\n",
                "\n",
                "# Check a sample record\n",
                "print(dataset[\"train\"][400])\n",
                "\n",
                "# Path to save the datasets to text files\n",
                "output_file_train = \"wikitext_dataset_train.txt\"\n",
                "output_file_test = \"wikitext_dataset_test.txt\"\n",
                "\n",
                "# Open the output file in write mode\n",
                "with open(output_file_train, \"w\", encoding=\"utf-8\") as f:\n",
                "    # Iterate over each example in the dataset\n",
                "    for example in dataset[\"train\"]:\n",
                "        # Write the example text to the file\n",
                "        f.write(example[\"text\"] + \"\\n\")\n",
                "\n",
                "# Open the output file in write mode\n",
                "with open(output_file_test, \"w\", encoding=\"utf-8\") as f:\n",
                "    # Iterate over each example in the dataset\n",
                "    for example in dataset[\"test\"]:\n",
                "        # Write the example text to the file\n",
                "        f.write(example[\"text\"] + \"\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "j5YYgC-SzSaq",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 229,
                    "referenced_widgets": [
                        "73e797cfe06046df8491397c85ab5565",
                        "9e73b26221644407ab493771430cb370",
                        "a9ccd265946047d7b23d6aad60ce7ceb",
                        "c5e8bbe061d641e3b968fa95a94de821",
                        "911334b3a6a445ccb900f0caa0e3e53b",
                        "ef75ca41890c43e6b9c9ca28ec194516",
                        "0502f5b47e0b47b6a76e264966459e5d",
                        "85bd802d14f64788b70ab5d71f1adaee",
                        "8fbc47e4cce945ecb9c72ea023fe3184",
                        "ca15dfbd0500408bb76ed2496b271d13",
                        "457a35ecef724f76a27837d49d4ebcb5",
                        "362755b991fb4d0480706ddd0ed1f227",
                        "5c551e55185746619de756f38e87370d",
                        "9017c5545d5c431eaa9a39011f71f09e",
                        "79be4c80e2cb4fc9be2ee3e557604cdf",
                        "2e1f33da446f4b9d840678eca656a47c",
                        "3c4c0b85173b42cb9b365aaa36ecf023",
                        "5afe4e9523474919868c76689ac1fae8",
                        "25c9e25b36b74d47aadf2c22dac18983",
                        "eae6d38e8303453ba398a249a4099512",
                        "b7912dbbe0694268b4dba572b0d4d99c",
                        "e470b8af60ac4c208c171505247367e3",
                        "b603459ce0fb49cc87e9dee4c9618cbd",
                        "b11611a8b33446f3a20012a7029d03d8",
                        "a1bedffa5ca744479cef4302f3a5e4fb",
                        "8887257a2b8d4acbacb0fde17aff6d7a",
                        "ac08ddb0d73b4c33903953929c0bdc86",
                        "8bd33d46f2e64dd48cd189df9bee27da",
                        "b4ff24605fc442bea298f20708654a92",
                        "a1d545c934a44afba727a76caad58bbf",
                        "526a8d51ce9b479b8d3693041141f593",
                        "b69226793b8a419692576e6548769f86",
                        "ec310e689c484acab38e678ca1906e8d",
                        "b4a519b0851140babf228dec498a9769",
                        "c912728b41294266a72e986d71c0c9ed",
                        "8ae6c24f950744fcbd4ca6246bceb49b",
                        "50e44b6b8ca640afb4d5f5906346a581",
                        "96d60dce49424b3b9c7421d54eb3a9d6",
                        "9bbaf37df2c545158a1d8a06dfd3aa11",
                        "59f7088c885f408994d7dbc615482f4d",
                        "f4326750d7ef4fa9ad835a39ad49481b",
                        "ce09c1e62fd9468a9f5a72e9266de162",
                        "9665710676c246528fca42d3449d9025",
                        "a672eba07a9e4c16bf9e9428eda0db60",
                        "c9d483fa74f14e9aa5f2f54b1c6381c9",
                        "7f6a985e56e34ce6abd8f1b0427ba7c0",
                        "3936cd38058d4081bdc46b131deaf8c6",
                        "6c17eb82b9574a3dbfecc72262619fd0",
                        "61a6230821284ce88e847e4df3de8325",
                        "db979b0935884bb8b9fa2032c93813d6",
                        "0de641a5bce043bab7314ed56ea5c9a8",
                        "78ef767d6e97482f8935dfb6820e3990",
                        "575ee6c9b8d044a488639101f5abfd30",
                        "661ffdd864f74b8297c308701050bb07",
                        "b5f50fa88a184798a64765c3ca8824d2"
                    ]
                },
                "id": "j5YYgC-SzSaq",
                "outputId": "b7ea3f0c-89ad-4743-81e2-451fbac4bfbc"
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "73e797cfe06046df8491397c85ab5565",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "362755b991fb4d0480706ddd0ed1f227",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b603459ce0fb49cc87e9dee4c9618cbd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b4a519b0851140babf228dec498a9769",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
                        "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c9d483fa74f14e9aa5f2f54b1c6381c9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
                    ]
                }
            ],
            "source": [
                "from transformers import BertTokenizerFast\n",
                "\n",
                "# create a tokenizer from existing one to re-use special tokens\n",
                "bert_tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
                "\n",
                "model_name = 'bert-base-uncased'\n",
                "\n",
                "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name, is_decoder=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "LGt3w6y80W9U",
            "metadata": {
                "id": "LGt3w6y80W9U"
            },
            "source": [
                "### Training a Tokenizer on Custom Dataset (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "CKljgh69zrEj",
            "metadata": {
                "id": "CKljgh69zrEj"
            },
            "outputs": [],
            "source": [
                "# ## create a python generator to dynamically load the data\n",
                "# def batch_iterator(batch_size=10000):\n",
                "#     for i in tqdm(range(0, len(dataset), batch_size)):\n",
                "#         yield dataset['train'][i : i + batch_size][\"text\"]\n",
                "\n",
                "# ## create a tokenizer from existing one to re-use special tokens\n",
                "# bert_tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
                "\n",
                "# ## train the tokenizer using our own dataset\n",
                "# bert_tokenizer = bert_tokenizer.train_new_from_iterator(text_iterator=batch_iterator(), vocab_size=30522)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tAjeS1ry0g3F",
            "metadata": {
                "id": "tAjeS1ry0g3F"
            },
            "source": [
                "### Pretraining"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "6JPM6Fjm0hN9",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "6JPM6Fjm0hN9",
                "outputId": "37556187-ef9d-42b6-b3d4-764bd3c70934"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "BertForMaskedLM(\n",
                            "  (bert): BertModel(\n",
                            "    (embeddings): BertEmbeddings(\n",
                            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
                            "      (position_embeddings): Embedding(512, 768)\n",
                            "      (token_type_embeddings): Embedding(2, 768)\n",
                            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
                            "      (dropout): Dropout(p=0.1, inplace=False)\n",
                            "    )\n",
                            "    (encoder): BertEncoder(\n",
                            "      (layer): ModuleList(\n",
                            "        (0-11): 12 x BertLayer(\n",
                            "          (attention): BertAttention(\n",
                            "            (self): BertSdpaSelfAttention(\n",
                            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
                            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
                            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
                            "              (dropout): Dropout(p=0.1, inplace=False)\n",
                            "            )\n",
                            "            (output): BertSelfOutput(\n",
                            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
                            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
                            "              (dropout): Dropout(p=0.1, inplace=False)\n",
                            "            )\n",
                            "          )\n",
                            "          (intermediate): BertIntermediate(\n",
                            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
                            "            (intermediate_act_fn): GELUActivation()\n",
                            "          )\n",
                            "          (output): BertOutput(\n",
                            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
                            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
                            "            (dropout): Dropout(p=0.1, inplace=False)\n",
                            "          )\n",
                            "        )\n",
                            "      )\n",
                            "    )\n",
                            "  )\n",
                            "  (cls): BertOnlyMLMHead(\n",
                            "    (predictions): BertLMPredictionHead(\n",
                            "      (transform): BertPredictionHeadTransform(\n",
                            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
                            "        (transform_act_fn): GELUActivation()\n",
                            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
                            "      )\n",
                            "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
                            "    )\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from transformers import BertConfig, BertForMaskedLM\n",
                "\n",
                "# Define the BERT configuration\n",
                "config = BertConfig(\n",
                "    vocab_size=len(bert_tokenizer.get_vocab()),  # Specify the vocabulary size(Make sure this number equals the vocab_size of the tokenizer)\n",
                "    hidden_size=768,  # Set the hidden size\n",
                "    num_hidden_layers=12,  # Set the number of layers\n",
                "    num_attention_heads=12,  # Set the number of attention heads\n",
                "    intermediate_size=3072,  # Set the intermediate size\n",
                ")\n",
                "\n",
                "# Create the BERT model for pre-training\n",
                "model = BertForMaskedLM(config)\n",
                "\n",
                "# check model configuration\n",
                "model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "yn3nWLkZ08pm",
            "metadata": {
                "id": "yn3nWLkZ08pm"
            },
            "source": [
                "### Tokenize Dataset Dynamically"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "nNlRo-YI0qWu",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 150,
                    "referenced_widgets": [
                        "9b246bd7966949218e77e70d9b7abfff",
                        "5818dd9a23a64755bc9321af6445de48",
                        "6ed60b91009945a6aaa0f61fb3a639ff",
                        "03ef7bcc76054e7d8d3053a61548f054",
                        "82cd7ea5d71441209c99af042b7f33d4",
                        "593f04545c9e42d89ac44b2f34f0b997",
                        "d7cf1aaf83d34829a4b0b91db7f21067",
                        "6bb1ba63ddf54d78aa18ccafa6d8b47b",
                        "5a87eea77d4d43e7a6a567cdc6ebd41c",
                        "71185b0427744d27ac427d2fd10d09e5",
                        "765ad2e562db45ae82c3b4749dc40276",
                        "35fd964bc9c3428aad489ea4764818a2",
                        "5429c77d40f54afeb9259b918d2f0df0",
                        "a88bb22baaa94998aff331c8e8bdf468",
                        "26b5f190ebd64398b0ceb99e2cfbbb64",
                        "d5c4b2422a024025974c3058bdb41b52",
                        "3acf23adda3b492382c8f9ea161a8a02",
                        "17179814f0a64d77ae49432911d5a502",
                        "fef3d7aff6bd479fa6db589d83545480",
                        "112f8def3b894d52b6a97eb8a29948b8",
                        "54c6b06c575d48eba08d7c5b6d1b0fad",
                        "d7ccffa5dad4431dab2ad24343d94fa0",
                        "5f430e5f4d9a45729ee5c6edad90aeb0",
                        "3b3374ac82ef47298a2b7432b2e14134",
                        "89376abdfd73414c94a3e22c8772e009",
                        "e1702f2e56254ccdbc57a2a0d13eb47a",
                        "b0ada86d6f5e4cf2b0b3fd26ac67a2c9",
                        "354ed4ccfb50401e9071027891743c4a",
                        "24bec57d024741f482b890a6133bdf78",
                        "c432e96c2e8048b99a088bf8f95d7a27",
                        "d364e1c085a44cba8918ba069f5da16e",
                        "9b6f21db7ae24b349c385b2221cf3fe6",
                        "ae588fc059814bbf92e222b7e37cd39a"
                    ]
                },
                "id": "nNlRo-YI0qWu",
                "outputId": "bf5755f1-7329-4a42-9122-b3597db16b0e"
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9b246bd7966949218e77e70d9b7abfff",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "35fd964bc9c3428aad489ea4764818a2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5f430e5f4d9a45729ee5c6edad90aeb0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'input_ids': [101, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
                    ]
                }
            ],
            "source": [
                "# Tokenize dataset dynamically\n",
                "def tokenize_function(examples):\n",
                "    return bert_tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
                "\n",
                "# Tokenize train and test datasets\n",
                "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
                "\n",
                "# Print tokenized dataset sample\n",
                "print(tokenized_datasets[\"train\"][0])\n",
                "\n",
                "# Split into training and test sets\n",
                "train_dataset = tokenized_datasets[\"train\"]\n",
                "test_dataset = tokenized_datasets[\"test\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "ItWdBGiD0-xS",
            "metadata": {
                "id": "ItWdBGiD0-xS"
            },
            "outputs": [],
            "source": [
                "from transformers import DataCollatorForLanguageModeling\n",
                "\n",
                "# Prepare the data collator for language modeling\n",
                "data_collator = DataCollatorForLanguageModeling(\n",
                "    tokenizer=bert_tokenizer, mlm=True, mlm_probability=0.15\n",
                ")\n",
                "\n",
                "# check how collator transforms a sample input data record\n",
                "# data_collator([train_dataset[0]])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5HVeE6ZZ1sLF",
            "metadata": {
                "id": "5HVeE6ZZ1sLF"
            },
            "source": [
                "### Train the BERT Model using the Trainer module (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "K6-ZIJ9K1QxO",
            "metadata": {
                "id": "K6-ZIJ9K1QxO"
            },
            "outputs": [],
            "source": [
                "# from transformers import TrainingArguments, Trainer\n",
                "# import math\n",
                "\n",
                "# # Define the training arguments\n",
                "# training_args = TrainingArguments(\n",
                "#     output_dir=\"./trained_model\",  # Specify the output directory for the trained model\n",
                "#     overwrite_output_dir=True,\n",
                "#     do_eval=True,\n",
                "#     evaluation_strategy=\"epoch\",\n",
                "#     learning_rate=5e-5,\n",
                "#     num_train_epochs=10,  # Specify the number of training epochs\n",
                "#     per_device_train_batch_size=2,  # Set the batch size for training\n",
                "#     save_total_limit=2,  # Limit the total number of saved checkpoints\n",
                "#     logging_steps = 20\n",
                "# )\n",
                "\n",
                "# # Instantiate the Trainer\n",
                "# trainer = Trainer(\n",
                "#     model=model,\n",
                "#     args=training_args,\n",
                "#     data_collator=data_collator,\n",
                "#     train_dataset=train_dataset,\n",
                "#     eval_dataset=test_dataset,\n",
                "# )\n",
                "\n",
                "# # Start the pre-training\n",
                "# trainer.train()\n",
                "\n",
                "# # Evaluate model performance\n",
                "# eval_results = trainer.evaluate()\n",
                "# print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "Rz9j-SHp11g3",
            "metadata": {
                "id": "Rz9j-SHp11g3"
            },
            "source": [
                "## Loading the saved model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "Hdg_K3Oj1xQZ",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "Hdg_K3Oj1xQZ",
                "outputId": "468f327d-6bfd-49fa-a8cc-d2e837eec045"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--2025-04-30 17:56:33--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/BeXRxFT2EyQAmBHvxVaMYQ/bert-scratch-model.pt\n",
                        "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
                        "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
                        "HTTP request sent, awaiting response... 200 OK\n",
                        "Length: 438141816 (418M) [binary/octet-stream]\n",
                        "Saving to: \u2018bert-scratch-model.pt.1\u2019\n",
                        "\n",
                        "bert-scratch-model. 100%[===================>] 417.84M  18.6MB/s    in 23s     \n",
                        "\n",
                        "2025-04-30 17:56:57 (17.9 MB/s) - \u2018bert-scratch-model.pt.1\u2019 saved [438141816/438141816]\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<All keys matched successfully>"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/BeXRxFT2EyQAmBHvxVaMYQ/bert-scratch-model.pt'\n",
                "model.resize_token_embeddings(30522)\n",
                "model.load_state_dict(torch.load('bert-scratch-model.pt',map_location=torch.device('cpu')))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "XjBDIfUM14of",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "XjBDIfUM14of",
                "outputId": "d4ef5d2b-4967-4e5f-a318-19a8fbe67b6e"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Device set to use cpu\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicted token: [unused17], Confidence: 0.04\n",
                        "Predicted token: [unused539], Confidence: 0.04\n",
                        "Predicted token: [unused15], Confidence: 0.03\n",
                        "Predicted token: [unused557], Confidence: 0.02\n",
                        "Predicted token: [unused551], Confidence: 0.02\n"
                    ]
                }
            ],
            "source": [
                "# Define the input text with a masked token\n",
                "text = \"This is a [MASK] movie!\"\n",
                "\n",
                "# Create a pipeline for the \"fill-mask\" task\n",
                "mask_filler = pipeline(\"fill-mask\", model=model,tokenizer=bert_tokenizer)\n",
                "\n",
                "# Generate predictions by filling the mask in the input text\n",
                "results = mask_filler(text) #top_k parameter can be set\n",
                "\n",
                "# Print the predicted sequences\n",
                "for result in results:\n",
                "    print(f\"Predicted token: {result['token_str']}, Confidence: {result['score']:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "q9qPqY852OOv",
            "metadata": {
                "id": "q9qPqY852OOv"
            },
            "source": [
                "## Inferencing a pretrained BERT model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "-WYqaDOE2GJC",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "-WYqaDOE2GJC",
                "outputId": "96399f0e-bbb4-45a2-8272-120ce556c863"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
                        "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
                        "Device set to use cpu\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicted token: great, Confidence: 0.16\n",
                        "Predicted token: horror, Confidence: 0.08\n",
                        "Predicted token: good, Confidence: 0.08\n",
                        "Predicted token: bad, Confidence: 0.05\n",
                        "Predicted token: fantastic, Confidence: 0.04\n"
                    ]
                }
            ],
            "source": [
                "# Load the pretrained BERT model and tokenizer\n",
                "pretrained_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
                "pretrained_tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
                "\n",
                "# Define the input text with a masked token\n",
                "text = \"This is a [MASK] movie!\"\n",
                "\n",
                "# Create the pipeline\n",
                "mask_filler = pipeline(task='fill-mask', model=pretrained_model,tokenizer=pretrained_tokenizer)\n",
                "\n",
                "# Perform inference using the pipeline\n",
                "results = mask_filler(text)\n",
                "for result in results:\n",
                "    print(f\"Predicted token: {result['token_str']}, Confidence: {result['score']:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "glWyygjK2XwX",
            "metadata": {
                "id": "glWyygjK2XwX"
            },
            "source": [
                "## Exercise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "MXA8_23e2QS2",
            "metadata": {
                "id": "MXA8_23e2QS2"
            },
            "outputs": [],
            "source": [
                "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "# from datasets import load_dataset\n",
                "\n",
                "# # Load the SNLI dataset\n",
                "# snli = load_dataset(\"stanfordnlp/snli\")\n",
                "\n",
                "# # Preprocessing function\n",
                "# def preprocess_function(examples):\n",
                "#   premise = examples[\"premise\"]\n",
                "#   hypothesis = examples[\"hypothesis\"]\n",
                "#   return tokenizer(premise, hypothesis, padding=\"max_length\", truncation=True)\n",
                "\n",
                "# model_name = \"bert-base-uncased\"\n",
                "\n",
                "# # Load tokenizer and model\n",
                "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
                "\n",
                "# # Apply preprocessing to training and validation sets\n",
                "# train_encoded = snli[\"train\"].map(preprocess_function, batched=True)\n",
                "# val_encoded = snli[\"validation\"].map(preprocess_function, batched=True)\n",
                "\n",
                "# # Training function (replace with your training loop)\n",
                "# from transformers import TrainingArguments, Trainer\n",
                "\n",
                "# training_args = TrainingArguments(\n",
                "#     output_dir=\"./results\",  # Replace with your output directory\n",
                "#     per_device_train_batch_size=2,\n",
                "#     per_device_eval_batch_size=2,\n",
                "#     num_train_epochs=1,\n",
                "# )\n",
                "\n",
                "# trainer = Trainer(\n",
                "#     model=model,\n",
                "#     args=training_args,\n",
                "#     train_dataset=train_encoded,\n",
                "#     eval_dataset=val_encoded,\n",
                "# )\n",
                "\n",
                "# trainer.train()\n",
                "\n",
                "# # Evaluation function (replace with your metrics)\n",
                "# from sklearn.metrics import accuracy_score\n",
                "\n",
                "# predictions, labels = trainer.predict(val_encoded)\n",
                "# accuracy = accuracy_score(labels, predictions.argmax(-1))\n",
                "# print(f\"Accuracy on validation set: {accuracy:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "WAT6ZPk12hUI",
            "metadata": {
                "id": "WAT6ZPk12hUI"
            },
            "outputs": [],
            "source": [
                "!pip freeze > requirements.txt"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "include_colab_link": true,
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}