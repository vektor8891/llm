{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/11_bert_pretraining/11_bert_pretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretraining a BERT model\n",
        "\n",
        "## Loading data"
      ],
      "metadata": {
        "id": "ht5t3ND0W14q"
      },
      "id": "ht5t3ND0W14q"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "834d2d6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "834d2d6d",
        "outputId": "bcdd19b5-c101-4e6f-86e7-66da7406985f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-24 15:13:19--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/bZaoQD52DcMpE7-kxwAG8A.zip\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88958506 (85M) [application/zip]\n",
            "Saving to: ‘BERT_dataset.zip’\n",
            "\n",
            "BERT_dataset.zip    100%[===================>]  84.84M  23.7MB/s    in 3.9s    \n",
            "\n",
            "2025-04-24 15:13:23 (22.0 MB/s) - ‘BERT_dataset.zip’ saved [88958506/88958506]\n",
            "\n",
            "Archive:  BERT_dataset.zip\n",
            "   creating: bert_dataset/\n",
            "  inflating: bert_dataset/.DS_Store  \n",
            "  inflating: bert_dataset/bert_train_data.csv  \n",
            "  inflating: bert_dataset/bert_test_data_sampled.csv  \n",
            "  inflating: bert_dataset/bert_test_data.csv  \n",
            "  inflating: bert_dataset/bert_train_data_sampled.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget -O BERT_dataset.zip https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/bZaoQD52DcMpE7-kxwAG8A.zip\n",
        "!unzip BERT_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "\n",
        "class BERTCSVDataset(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.data = pd.read_csv(filename)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        try:\n",
        "\n",
        "            bert_input = torch.tensor(json.loads(row['BERT Input']), dtype=torch.long)\n",
        "            bert_label = torch.tensor(json.loads(row['BERT Label']), dtype=torch.long)\n",
        "            segment_label = torch.tensor([int(x) for x in row['Segment Label'].split(',')], dtype=torch.long)\n",
        "            is_next = torch.tensor(row['Is Next'], dtype=torch.long)\n",
        "            original_text = row['Original Text']  # If you want to use it\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON for row {idx}: {e}\")\n",
        "            print(\"BERT Input:\", row['BERT Input'])\n",
        "            print(\"BERT Label:\", row['BERT Label'])\n",
        "            # Handle the error, e.g., by skipping this row or using default values\n",
        "            return None  # or some default values\n",
        "\n",
        "            # Tokenizing the original text with BERT\n",
        "        encoded_input = self.tokenizer.encode_plus(\n",
        "            original_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = encoded_input['input_ids'].squeeze()\n",
        "        attention_mask = encoded_input['attention_mask'].squeeze()\n",
        "\n",
        "        return(bert_input, bert_label, segment_label, is_next, input_ids, attention_mask, original_text)"
      ],
      "metadata": {
        "id": "1q7jk9mRXCZD"
      },
      "id": "1q7jk9mRXCZD",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# create a collate function that applies transformations on batches of data iterator\n",
        "PAD_IDX = 0\n",
        "def collate_batch(batch):\n",
        "\n",
        "\n",
        "    bert_inputs_batch, bert_labels_batch, segment_labels_batch, is_nexts_batch,input_ids_batch,attention_mask_batch,original_text_battch = [], [], [], [],[],[],[]\n",
        "\n",
        "    for bert_input, bert_label, segment_label, is_next,input_ids,attention_mask,original_text in batch:\n",
        "        # Convert each sequence to a tensor and append to the respective list\n",
        "        bert_inputs_batch.append(bert_input.clone().detach())\n",
        "        bert_labels_batch.append(bert_label.clone().detach())\n",
        "        segment_labels_batch.append(segment_label.clone().detach())\n",
        "        is_nexts_batch.append(is_next)\n",
        "        input_ids_batch.append(input_ids)\n",
        "        attention_mask_batch.append(attention_mask)\n",
        "        original_text_battch.append(original_text)\n",
        "\n",
        "    # Pad the sequences in the batch\n",
        "    bert_inputs_final = pad_sequence(bert_inputs_batch, padding_value=PAD_IDX, batch_first=False)\n",
        "    bert_labels_final = pad_sequence(bert_labels_batch, padding_value=PAD_IDX, batch_first=False)\n",
        "    segment_labels_final = pad_sequence(segment_labels_batch, padding_value=PAD_IDX, batch_first=False)\n",
        "    is_nexts_batch = torch.tensor(is_nexts_batch, dtype=torch.long)\n",
        "\n",
        "    return bert_inputs_final, bert_labels_final, segment_labels_final, is_nexts_batch"
      ],
      "metadata": {
        "id": "AwwZtZl9XW15"
      },
      "id": "AwwZtZl9XW15",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create train and test dataloaders\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "train_dataset_path = './bert_dataset/bert_train_data.csv'\n",
        "test_dataset_path = './bert_dataset/bert_test_data.csv'\n",
        "\n",
        "train_dataset = BERTCSVDataset(train_dataset_path)\n",
        "test_dataset = BERTCSVDataset(test_dataset_path)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "S_gmGw2fXm3V"
      },
      "id": "S_gmGw2fXm3V",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model creation\n",
        "\n",
        "3 types of embeddings used in BERT to represent input tokens:\n",
        "\n",
        "1. Token Embedding: initial representation of each token\n",
        "2. Positional Embedding: captures the order of tokens\n",
        "3. Segment Embedding: differentiates between different segments (e.g. sentences)\n",
        "\n",
        "Model components:\n",
        "\n",
        "1. Initialization: subclass of `torch.nn.Module`\n",
        "2. Embedding Layer: combines token embeddings and segment embeddings\n",
        "3. Transformer Encoder: encodes the input embeddings\n",
        "4. Next Sentence Prediction: predicts the relationship between two consecutive sentences using the output of Transformer encoder\n",
        "5. Masked Language Modeling: predicts the masked tokens in the input sequence\n",
        "6. Forward Pass: defines the forward pass. Returns predictions for Next Sentence Prediction and Masked Language Modeling using input tokens and segment labels\n"
      ],
      "metadata": {
        "id": "bbB6PlgrXzro"
      },
      "id": "bbB6PlgrXzro"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "import math\n",
        "\n",
        "EMBEDDING_DIM = 10\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Define the PositionalEncoding class as a PyTorch module for adding positional information to token embeddings\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        # Create a positional encoding matrix as per the Transformer paper's formula\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: torch.Tensor):\n",
        "        # Apply the positional encodings to the input token embeddings\n",
        "\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "class BERTEmbedding (nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, emb_size ,dropout=0.1,train=True):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embedding = TokenEmbedding( vocab_size,emb_size )\n",
        "        self.positional_encoding = PositionalEncoding(emb_size,dropout)\n",
        "        self.segment_embedding = nn.Embedding(3, emb_size)\n",
        "        self.dropout = torch.nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, bert_inputs, segment_labels=False):\n",
        "        my_embeddings=self.token_embedding(bert_inputs)\n",
        "        if self.train:\n",
        "          x = self.dropout(my_embeddings + self.positional_encoding(my_embeddings) + self.segment_embedding(segment_labels))\n",
        "        else:\n",
        "          x = my_embeddings + self.positional_encoding(my_embeddings)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "o9HyfMDHXtQq"
      },
      "id": "o9HyfMDHXtQq",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "VOCAB_SIZE=147161\n",
        "batch = 2\n",
        "count = 0\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# load sample batches from dataloader\n",
        "for batch in train_dataloader:\n",
        "    bert_inputs, bert_labels, segment_labels, is_nexts = [b.to(device) for b in batch]\n",
        "    count += 1\n",
        "    if count == 5:\n",
        "        break\n",
        "\n",
        "print(bert_inputs.shape)\n",
        "print(bert_inputs[:,0])\n",
        "print(segment_labels.shape)\n",
        "print(segment_labels[:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK5F-9sbYJsd",
        "outputId": "7fcce83d-8799-4bed-992c-2e88942b120e"
      },
      "id": "EK5F-9sbYJsd",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([102, 2])\n",
            "tensor([    1,     3,  2929,    13,   103,    11,  8245, 44449,    51,     5,\n",
            "         3455,  9236,    12,    19,  3545,     3, 15441,    31,     3,  2665,\n",
            "            7,   599,    13,  1638,     6,     2,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,    47,     7,     5,  2428,    15,     5,  2541,   213,     7,\n",
            "           15,     3,   946,    10,     3, 13541,    28,    10,     3,  3769,\n",
            "         2541,     3,     8,   240,   335,    12,    19,     3, 14294,    27,\n",
            "            7,    13,     9,  2644,  3555,     7,   383,  1573,   156,    25,\n",
            "           32,   171, 15549,    43,     5, 18301, 10077,     3,     5,   527,\n",
            "            6,     2])\n",
            "torch.Size([102, 2])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the TokenEmbedding\n",
        "token_embedding = TokenEmbedding(VOCAB_SIZE, emb_size=EMBEDDING_DIM )\n",
        "\n",
        "# Get the token embeddings for a sample input\n",
        "t_embeddings = token_embedding(bert_inputs)\n",
        "# Each token is transformed into a tensor of size emb_size\n",
        "print(f\"Dimensions of token embeddings: {t_embeddings.size()}\") # Expected: (sequence_length, batch_size, EMBEDDING_DIM)\n",
        "# Check the embedded vectors for first 3 tokens of the first sample in the batch\n",
        "# you get embeddings[i,0,:] where i refers to the i'th token of the first sample in the batch (b=0)\n",
        "for i in range(3):\n",
        "    print(f\"Token Embeddings for the {i}th token of the first sample: {t_embeddings[i,0,:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7-AUZWEYpLP",
        "outputId": "7cbd2ae6-3e99-4d98-abe1-d688d5df16c1"
      },
      "id": "M7-AUZWEYpLP",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of token embeddings: torch.Size([102, 2, 10])\n",
            "Token Embeddings for the 0th token of the first sample: tensor([-0.1569, -0.0639, -1.7253,  1.4022,  4.4875, -1.4307, -2.1106,  2.2914,\n",
            "         0.6288,  0.9770], grad_fn=<SliceBackward0>)\n",
            "Token Embeddings for the 1th token of the first sample: tensor([ 0.0359,  2.3731,  4.1027, -3.1912, -4.3995,  1.3404, -5.1265, -3.3133,\n",
            "        -2.1321, -6.6937], grad_fn=<SliceBackward0>)\n",
            "Token Embeddings for the 2th token of the first sample: tensor([-1.5487, -5.3569,  0.9062,  2.2734,  0.6782, -3.8600, -0.8670,  1.4534,\n",
            "        -2.2636, -4.3005], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoding = PositionalEncoding(emb_size=EMBEDDING_DIM,dropout=0)\n",
        "\n",
        "# Apply positional encoding to token embeddings\n",
        "p_embedding = positional_encoding(t_embeddings)\n",
        "\n",
        "print(f\"Dimensions of positionally encoded tokens: {p_embedding.size()}\") # Expected: (sequence_length, batch_size, EMBEDDING_DIM)\n",
        "# Check the positional encoded vectors for first 3 tokens of the first sample in the batch\n",
        "# you get encoded_tokens[i,0,:] where i refers to the i'th token of the first sample(b=0) in the batch\n",
        "for i in range(3):\n",
        "    print(f\"Positional Embeddings for the {i}th token of the first sample: {p_embedding[i,0,:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opNSdoOha_Ci",
        "outputId": "3ce11422-d9a6-4a49-8a35-f8ba618a3943"
      },
      "id": "opNSdoOha_Ci",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of positionally encoded tokens: torch.Size([102, 2, 10])\n",
            "Positional Embeddings for the 0th token of the first sample: tensor([-0.1569,  0.9361, -1.7253,  2.4022,  4.4875, -0.4307, -2.1106,  3.2914,\n",
            "         0.6288,  1.9770], grad_fn=<SliceBackward0>)\n",
            "Positional Embeddings for the 1th token of the first sample: tensor([ 0.8774,  2.9134,  4.2605, -2.2037, -4.3743,  2.3401, -5.1225, -2.3134,\n",
            "        -2.1315, -5.6937], grad_fn=<SliceBackward0>)\n",
            "Positional Embeddings for the 2th token of the first sample: tensor([-0.6394, -5.7731,  1.2179,  3.2236,  0.7285, -2.8613, -0.8590,  2.4534,\n",
            "        -2.2623, -3.3005], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segment_embedding = nn.Embedding(3, EMBEDDING_DIM)\n",
        "s_embedding = segment_embedding(segment_labels)\n",
        "print(f\"Dimensions of segment embedding: {s_embedding.size()}\") # Expected: (sequence_length, batch_size, EMBEDDING_DIM)\n",
        "# Check the Segment Embedding vectors for first 3 tokens of the first sample in the batch\n",
        "# you get segment_embedded[i,0,:] where i refers to the i'th token of the first sample(b=0) in the batch\n",
        "for i in range(3):\n",
        "    print(f\"Segment Embeddings for the {i}th token of the first sample: {s_embedding[i,0,:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZeEI7ekYvA3",
        "outputId": "1ef5bc3a-3e13-4ba1-bb37-6f560748f3ff"
      },
      "id": "7ZeEI7ekYvA3",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of segment embedding: torch.Size([102, 2, 10])\n",
            "Segment Embeddings for the 0th token of the first sample: tensor([ 0.3030, -0.3011,  0.5643,  0.4439, -0.8016, -0.4365, -0.0510, -1.6664,\n",
            "         0.9397,  2.7754], grad_fn=<SliceBackward0>)\n",
            "Segment Embeddings for the 1th token of the first sample: tensor([ 0.3030, -0.3011,  0.5643,  0.4439, -0.8016, -0.4365, -0.0510, -1.6664,\n",
            "         0.9397,  2.7754], grad_fn=<SliceBackward0>)\n",
            "Segment Embeddings for the 2th token of the first sample: tensor([ 0.3030, -0.3011,  0.5643,  0.4439, -0.8016, -0.4365, -0.0510, -1.6664,\n",
            "         0.9397,  2.7754], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the combined embedding vectors\n",
        "bert_embeddings = t_embeddings + p_embedding + s_embedding\n",
        "print(f\"Dimensions of token + position + segment encoded tokens: {bert_embeddings.size()}\")\n",
        "#Check the BERT Embedding vectors for first 3 tokens of the first sample in the batch\n",
        "# you get bert_embeddings[i,0,:] where i refers to the i'th token of the first sample(b=0) in the batch\n",
        "for i in range(3):\n",
        "    print(f\"BERT_Embedding for {i}th token: {bert_embeddings[i,0,:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGiHwdOIaog0",
        "outputId": "26504dce-2be9-4a1b-8c9a-8770ceb3c482"
      },
      "id": "pGiHwdOIaog0",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensions of token + position + segment encoded tokens: torch.Size([102, 2, 10])\n",
            "BERT_Embedding for 0th token: tensor([-0.0108,  0.5711, -2.8862,  4.2483,  8.1734, -2.2979, -4.2722,  3.9164,\n",
            "         2.1972,  5.7294], grad_fn=<SliceBackward0>)\n",
            "BERT_Embedding for 1th token: tensor([  1.2163,   4.9854,   8.9276,  -4.9510,  -9.5754,   3.2440, -10.3000,\n",
            "         -7.2931,  -3.3239,  -9.6120], grad_fn=<SliceBackward0>)\n",
            "BERT_Embedding for 2th token: tensor([ -1.8851, -11.4311,   2.6883,   5.9409,   0.6051,  -7.1578,  -1.7770,\n",
            "          2.2404,  -3.5863,  -4.8256], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, d_model=768, n_layers=12, heads=12, dropout=0.1):\n",
        "        \"\"\"\n",
        "        vocab_size: The size of the vocabulary.\n",
        "        d_model: The size of the embeddings (hidden size).\n",
        "        n_layers: The number of Transformer layers.\n",
        "        heads: The number of attention heads in each Transformer layer.\n",
        "        dropout: The dropout rate applied to embeddings and Transformer layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_layers = n_layers\n",
        "        self.heads = heads\n",
        "\n",
        "        # Embedding layer that combines token embeddings and segment embeddings\n",
        "        self.bert_embedding = BERTEmbedding(vocab_size, d_model, dropout)\n",
        "\n",
        "        # Transformer Encoder layers\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=heads, dropout=dropout,batch_first=False)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        # Linear layer for Next Sentence Prediction\n",
        "        self.nextsentenceprediction = nn.Linear(d_model, 2)\n",
        "\n",
        "        # Linear layer for Masked Language Modeling\n",
        "        self.masked_language = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, bert_inputs, segment_labels):\n",
        "        \"\"\"\n",
        "        bert_inputs: Input tokens.\n",
        "        segment_labels: Segment IDs for distinguishing different segments in the input.\n",
        "        mask: Attention mask to prevent attention to padding tokens.\n",
        "\n",
        "        return: Predictions for next sentence task and masked language modeling task.\n",
        "        \"\"\"\n",
        "\n",
        "        padding_mask = (bert_inputs == PAD_IDX).transpose(0, 1)\n",
        "        # Generate embeddings from input tokens and segment labels\n",
        "        my_bert_embedding = self.bert_embedding(bert_inputs, segment_labels)\n",
        "\n",
        "        # Pass embeddings through the Transformer encoder\n",
        "        transformer_encoder_output = self.transformer_encoder(my_bert_embedding,src_key_padding_mask=padding_mask)\n",
        "\n",
        "\n",
        "        next_sentence_prediction = self.nextsentenceprediction(transformer_encoder_output[ 0,:])\n",
        "\n",
        "\n",
        "        # Masked Language Modeling: Predict all tokens in the sequence\n",
        "        masked_language = self.masked_language(transformer_encoder_output)\n",
        "\n",
        "        return  next_sentence_prediction, masked_language"
      ],
      "metadata": {
        "id": "3pJeJYUFa5OT"
      },
      "id": "3pJeJYUFa5OT",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of the model\n",
        "EMBEDDING_DIM = 10\n",
        "\n",
        "# Define parameters\n",
        "vocab_size = 147161  # Replace VOCAB_SIZE with your vocabulary size\n",
        "d_model = EMBEDDING_DIM  # Replace EMBEDDING_DIM with your embedding dimension\n",
        "n_layers = 2  # Number of Transformer layers\n",
        "initial_heads = 12 # Initial number of attention heads\n",
        "initial_heads = 2\n",
        "# Ensure the number of heads is a factor of the embedding dimension\n",
        "heads = initial_heads - d_model % initial_heads\n",
        "\n",
        "dropout = 0.1  # Dropout rate\n",
        "\n",
        "# Create an instance of the BERT model\n",
        "model = BERT(vocab_size, d_model, n_layers, heads, dropout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5a9nr0RbUhU",
        "outputId": "f0941bf3-b500-4a65-fc26-4e22dbe13d1c"
      },
      "id": "z5a9nr0RbUhU",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padding_mask = (bert_inputs == PAD_IDX).transpose(0, 1)\n",
        "padding_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVuV41nibbkO",
        "outputId": "cb733340-0275-4902-8c91-2cfb72b1fa88"
      },
      "id": "AVuV41nibbkO",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 102])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=heads, dropout=dropout,batch_first=False)\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "# Pass embeddings through the Transformer encoder\n",
        "transformer_encoder_output = transformer_encoder(bert_embeddings,src_key_padding_mask=padding_mask)\n",
        "transformer_encoder_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM_tp6iBblH1",
        "outputId": "9f538c58-c982-4fe6-9bac-92f073953587"
      },
      "id": "xM_tp6iBblH1",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([102, 2, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nextsentenceprediction = nn.Linear(d_model, 2)\n",
        "nsp = nextsentenceprediction(transformer_encoder_output[ 0,:])\n",
        "#logits for NSP task\n",
        "print(f\"NSP Output Shape: {nsp.shape}\")  # Expected shape: (batch_size, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsTNyIqObnch",
        "outputId": "321f8ad2-5697-4a7b-8f2a-23c400772849"
      },
      "id": "DsTNyIqObnch",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSP Output Shape: torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_language = nn.Linear(d_model, vocab_size)\n",
        "# Masked Language Modeling: Predict all tokens in the sequence\n",
        "mlm = masked_language(transformer_encoder_output)\n",
        "#logits for MLM task\n",
        "print(f\"MLM Output Shape: {mlm.shape}\")  # Expected shape: (seq_length, batch_size, vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Peocm1oqbvQs",
        "outputId": "ca1da743-446a-4ef5-d6ba-4564246bacf8"
      },
      "id": "Peocm1oqbvQs",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLM Output Shape: torch.Size([102, 2, 147161])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IGlFQ3gibyHg"
      },
      "id": "IGlFQ3gibyHg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}