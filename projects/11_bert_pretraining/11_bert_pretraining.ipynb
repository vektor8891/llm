{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/11_bert_pretraining/11_bert_pretraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Pretraining a BERT model\n",
                "\n",
                "## Loading data"
            ],
            "metadata": {
                "id": "ht5t3ND0W14q"
            },
            "id": "ht5t3ND0W14q"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "834d2d6d",
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "834d2d6d",
                "outputId": "bcdd19b5-c101-4e6f-86e7-66da7406985f"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "--2025-04-24 15:13:19--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/bZaoQD52DcMpE7-kxwAG8A.zip\n",
                        "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
                        "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
                        "HTTP request sent, awaiting response... 200 OK\n",
                        "Length: 88958506 (85M) [application/zip]\n",
                        "Saving to: \u2018BERT_dataset.zip\u2019\n",
                        "\n",
                        "BERT_dataset.zip    100%[===================>]  84.84M  23.7MB/s    in 3.9s    \n",
                        "\n",
                        "2025-04-24 15:13:23 (22.0 MB/s) - \u2018BERT_dataset.zip\u2019 saved [88958506/88958506]\n",
                        "\n",
                        "Archive:  BERT_dataset.zip\n",
                        "   creating: bert_dataset/\n",
                        "  inflating: bert_dataset/.DS_Store  \n",
                        "  inflating: bert_dataset/bert_train_data.csv  \n",
                        "  inflating: bert_dataset/bert_test_data_sampled.csv  \n",
                        "  inflating: bert_dataset/bert_test_data.csv  \n",
                        "  inflating: bert_dataset/bert_train_data_sampled.csv  \n"
                    ]
                }
            ],
            "source": [
                "!wget -O BERT_dataset.zip https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/bZaoQD52DcMpE7-kxwAG8A.zip\n",
                "!unzip BERT_dataset.zip"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from transformers import BertTokenizer\n",
                "import pandas as pd\n",
                "import json\n",
                "\n",
                "\n",
                "class BERTCSVDataset(Dataset):\n",
                "    def __init__(self, filename):\n",
                "        self.data = pd.read_csv(filename)\n",
                "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.data)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        row = self.data.iloc[idx]\n",
                "        try:\n",
                "\n",
                "            bert_input = torch.tensor(json.loads(row['BERT Input']), dtype=torch.long)\n",
                "            bert_label = torch.tensor(json.loads(row['BERT Label']), dtype=torch.long)\n",
                "            segment_label = torch.tensor([int(x) for x in row['Segment Label'].split(',')], dtype=torch.long)\n",
                "            is_next = torch.tensor(row['Is Next'], dtype=torch.long)\n",
                "            original_text = row['Original Text']  # If you want to use it\n",
                "        except json.JSONDecodeError as e:\n",
                "            print(f\"Error decoding JSON for row {idx}: {e}\")\n",
                "            print(\"BERT Input:\", row['BERT Input'])\n",
                "            print(\"BERT Label:\", row['BERT Label'])\n",
                "            # Handle the error, e.g., by skipping this row or using default values\n",
                "            return None  # or some default values\n",
                "\n",
                "            # Tokenizing the original text with BERT\n",
                "        encoded_input = self.tokenizer.encode_plus(\n",
                "            original_text,\n",
                "            add_special_tokens=True,\n",
                "            max_length=512,\n",
                "            padding='max_length',\n",
                "            truncation=True,\n",
                "            return_tensors=\"pt\"\n",
                "        )\n",
                "\n",
                "        input_ids = encoded_input['input_ids'].squeeze()\n",
                "        attention_mask = encoded_input['attention_mask'].squeeze()\n",
                "\n",
                "        return(bert_input, bert_label, segment_label, is_next, input_ids, attention_mask, original_text)"
            ],
            "metadata": {
                "id": "1q7jk9mRXCZD"
            },
            "id": "1q7jk9mRXCZD",
            "execution_count": 2,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "from torch.nn.utils.rnn import pad_sequence\n",
                "\n",
                "# create a collate function that applies transformations on batches of data iterator\n",
                "PAD_IDX = 0\n",
                "def collate_batch(batch):\n",
                "\n",
                "\n",
                "    bert_inputs_batch, bert_labels_batch, segment_labels_batch, is_nexts_batch,input_ids_batch,attention_mask_batch,original_text_battch = [], [], [], [],[],[],[]\n",
                "\n",
                "    for bert_input, bert_label, segment_label, is_next,input_ids,attention_mask,original_text in batch:\n",
                "        # Convert each sequence to a tensor and append to the respective list\n",
                "        bert_inputs_batch.append(bert_input.clone().detach())\n",
                "        bert_labels_batch.append(bert_label.clone().detach())\n",
                "        segment_labels_batch.append(segment_label.clone().detach())\n",
                "        is_nexts_batch.append(is_next)\n",
                "        input_ids_batch.append(input_ids)\n",
                "        attention_mask_batch.append(attention_mask)\n",
                "        original_text_battch.append(original_text)\n",
                "\n",
                "    # Pad the sequences in the batch\n",
                "    bert_inputs_final = pad_sequence(bert_inputs_batch, padding_value=PAD_IDX, batch_first=False)\n",
                "    bert_labels_final = pad_sequence(bert_labels_batch, padding_value=PAD_IDX, batch_first=False)\n",
                "    segment_labels_final = pad_sequence(segment_labels_batch, padding_value=PAD_IDX, batch_first=False)\n",
                "    is_nexts_batch = torch.tensor(is_nexts_batch, dtype=torch.long)\n",
                "\n",
                "    return bert_inputs_final, bert_labels_final, segment_labels_final, is_nexts_batch"
            ],
            "metadata": {
                "id": "AwwZtZl9XW15"
            },
            "id": "AwwZtZl9XW15",
            "execution_count": 10,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# create train and test dataloaders\n",
                "BATCH_SIZE = 2\n",
                "\n",
                "train_dataset_path = './bert_dataset/bert_train_data.csv'\n",
                "test_dataset_path = './bert_dataset/bert_test_data.csv'\n",
                "\n",
                "train_dataset = BERTCSVDataset(train_dataset_path)\n",
                "test_dataset = BERTCSVDataset(test_dataset_path)\n",
                "\n",
                "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
                "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)"
            ],
            "metadata": {
                "id": "S_gmGw2fXm3V"
            },
            "id": "S_gmGw2fXm3V",
            "execution_count": 11,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Model creation\n",
                "\n",
                "3 types of embeddings used in BERT to represent input tokens:\n",
                "\n",
                "1. Token Embedding: initial representation of each token\n",
                "2. Positional Embedding: captures the order of tokens\n",
                "3. Segment Embedding: differentiates between different segments (e.g. sentences)\n",
                "\n",
                "Model components:\n",
                "\n",
                "1. Initialization: subclass of `torch.nn.Module`\n",
                "2. Embedding Layer: combines token embeddings and segment embeddings\n",
                "3. Transformer Encoder: encodes the input embeddings\n",
                "4. Next Sentence Prediction: predicts the relationship between two consecutive sentences using the output of Transformer encoder\n",
                "5. Masked Language Modeling: predicts the masked tokens in the input sequence\n",
                "6. Forward Pass: defines the forward pass. Returns predictions for Next Sentence Prediction and Masked Language Modeling using input tokens and segment labels\n"
            ],
            "metadata": {
                "id": "bbB6PlgrXzro"
            },
            "id": "bbB6PlgrXzro"
        },
        {
            "cell_type": "code",
            "source": [
                "import torch.nn as nn\n",
                "from torch import Tensor\n",
                "import math\n",
                "\n",
                "EMBEDDING_DIM = 10\n",
                "\n",
                "class TokenEmbedding(nn.Module):\n",
                "    def __init__(self, vocab_size, emb_size):\n",
                "        super(TokenEmbedding, self).__init__()\n",
                "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
                "        self.emb_size = emb_size\n",
                "\n",
                "    def forward(self, tokens: Tensor):\n",
                "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
                "\n",
                "# Define the PositionalEncoding class as a PyTorch module for adding positional information to token embeddings\n",
                "class PositionalEncoding(nn.Module):\n",
                "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
                "        super(PositionalEncoding, self).__init__()\n",
                "        # Create a positional encoding matrix as per the Transformer paper's formula\n",
                "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
                "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
                "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
                "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
                "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
                "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
                "\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        self.register_buffer('pos_embedding', pos_embedding)\n",
                "\n",
                "    def forward(self, token_embedding: torch.Tensor):\n",
                "        # Apply the positional encodings to the input token embeddings\n",
                "\n",
                "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
                "\n",
                "class BERTEmbedding (nn.Module):\n",
                "\n",
                "    def __init__(self, vocab_size, emb_size ,dropout=0.1,train=True):\n",
                "\n",
                "        super().__init__()\n",
                "\n",
                "        self.token_embedding = TokenEmbedding( vocab_size,emb_size )\n",
                "        self.positional_encoding = PositionalEncoding(emb_size,dropout)\n",
                "        self.segment_embedding = nn.Embedding(3, emb_size)\n",
                "        self.dropout = torch.nn.Dropout(p=dropout)\n",
                "\n",
                "    def forward(self, bert_inputs, segment_labels=False):\n",
                "        my_embeddings=self.token_embedding(bert_inputs)\n",
                "        if self.train:\n",
                "          x = self.dropout(my_embeddings + self.positional_encoding(my_embeddings) + self.segment_embedding(segment_labels))\n",
                "        else:\n",
                "          x = my_embeddings + self.positional_encoding(my_embeddings)\n",
                "\n",
                "        return x"
            ],
            "metadata": {
                "id": "o9HyfMDHXtQq"
            },
            "id": "o9HyfMDHXtQq",
            "execution_count": 24,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# example\n",
                "VOCAB_SIZE=147161\n",
                "batch = 2\n",
                "count = 0\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "# load sample batches from dataloader\n",
                "for batch in train_dataloader:\n",
                "    bert_inputs, bert_labels, segment_labels, is_nexts = [b.to(device) for b in batch]\n",
                "    count += 1\n",
                "    if count == 5:\n",
                "        break\n",
                "\n",
                "print(bert_inputs.shape)\n",
                "print(bert_inputs[:,0])\n",
                "print(segment_labels.shape)\n",
                "print(segment_labels[:,0])"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "EK5F-9sbYJsd",
                "outputId": "7fcce83d-8799-4bed-992c-2e88942b120e"
            },
            "id": "EK5F-9sbYJsd",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "torch.Size([102, 2])\n",
                        "tensor([    1,     3,  2929,    13,   103,    11,  8245, 44449,    51,     5,\n",
                        "         3455,  9236,    12,    19,  3545,     3, 15441,    31,     3,  2665,\n",
                        "            7,   599,    13,  1638,     6,     2,     0,     0,     0,     0,\n",
                        "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
                        "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
                        "            0,    47,     7,     5,  2428,    15,     5,  2541,   213,     7,\n",
                        "           15,     3,   946,    10,     3, 13541,    28,    10,     3,  3769,\n",
                        "         2541,     3,     8,   240,   335,    12,    19,     3, 14294,    27,\n",
                        "            7,    13,     9,  2644,  3555,     7,   383,  1573,   156,    25,\n",
                        "           32,   171, 15549,    43,     5, 18301, 10077,     3,     5,   527,\n",
                        "            6,     2])\n",
                        "torch.Size([102, 2])\n",
                        "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
                        "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                        "        0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
                        "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
                        "        2, 2, 2, 2, 2, 2])\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Instantiate the TokenEmbedding\n",
                "token_embedding = TokenEmbedding(VOCAB_SIZE, emb_size=EMBEDDING_DIM )\n",
                "\n",
                "# Get the token embeddings for a sample input\n",
                "t_embeddings = token_embedding(bert_inputs)\n",
                "# Each token is transformed into a tensor of size emb_size\n",
                "print(f\"Dimensions of token embeddings: {t_embeddings.size()}\") # Expected: (sequence_length, batch_size, EMBEDDING_DIM)\n",
                "# Check the embedded vectors for first 3 tokens of the first sample in the batch\n",
                "# you get embeddings[i,0,:] where i refers to the i'th token of the first sample in the batch (b=0)\n",
                "for i in range(3):\n",
                "    print(f\"Token Embeddings for the {i}th token of the first sample: {t_embeddings[i,0,:]}\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "M7-AUZWEYpLP",
                "outputId": "7cbd2ae6-3e99-4d98-abe1-d688d5df16c1"
            },
            "id": "M7-AUZWEYpLP",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Dimensions of token embeddings: torch.Size([102, 2, 10])\n",
                        "Token Embeddings for the 0th token of the first sample: tensor([-0.1569, -0.0639, -1.7253,  1.4022,  4.4875, -1.4307, -2.1106,  2.2914,\n",
                        "         0.6288,  0.9770], grad_fn=<SliceBackward0>)\n",
                        "Token Embeddings for the 1th token of the first sample: tensor([ 0.0359,  2.3731,  4.1027, -3.1912, -4.3995,  1.3404, -5.1265, -3.3133,\n",
                        "        -2.1321, -6.6937], grad_fn=<SliceBackward0>)\n",
                        "Token Embeddings for the 2th token of the first sample: tensor([-1.5487, -5.3569,  0.9062,  2.2734,  0.6782, -3.8600, -0.8670,  1.4534,\n",
                        "        -2.2636, -4.3005], grad_fn=<SliceBackward0>)\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "positional_encoding = PositionalEncoding(emb_size=EMBEDDING_DIM,dropout=0)\n",
                "\n",
                "# Apply positional encoding to token embeddings\n",
                "p_embedding = positional_encoding(t_embeddings)\n",
                "\n",
                "print(f\"Dimensions of positionally encoded tokens: {p_embedding.size()}\") # Expected: (sequence_length, batch_size, EMBEDDING_DIM)\n",
                "# Check the positional encoded vectors for first 3 tokens of the first sample in the batch\n",
                "# you get encoded_tokens[i,0,:] where i refers to the i'th token of the first sample(b=0) in the batch\n",
                "for i in range(3):\n",
                "    print(f\"Positional Embeddings for the {i}th token of the first sample: {p_embedding[i,0,:]}\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "opNSdoOha_Ci",
                "outputId": "3ce11422-d9a6-4a49-8a35-f8ba618a3943"
            },
            "id": "opNSdoOha_Ci",
            "execution_count": 18,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Dimensions of positionally encoded tokens: torch.Size([102, 2, 10])\n",
                        "Positional Embeddings for the 0th token of the first sample: tensor([-0.1569,  0.9361, -1.7253,  2.4022,  4.4875, -0.4307, -2.1106,  3.2914,\n",
                        "         0.6288,  1.9770], grad_fn=<SliceBackward0>)\n",
                        "Positional Embeddings for the 1th token of the first sample: tensor([ 0.8774,  2.9134,  4.2605, -2.2037, -4.3743,  2.3401, -5.1225, -2.3134,\n",
                        "        -2.1315, -5.6937], grad_fn=<SliceBackward0>)\n",
                        "Positional Embeddings for the 2th token of the first sample: tensor([-0.6394, -5.7731,  1.2179,  3.2236,  0.7285, -2.8613, -0.8590,  2.4534,\n",
                        "        -2.2623, -3.3005], grad_fn=<SliceBackward0>)\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "segment_embedding = nn.Embedding(3, EMBEDDING_DIM)\n",
                "s_embedding = segment_embedding(segment_labels)\n",
                "print(f\"Dimensions of segment embedding: {s_embedding.size()}\") # Expected: (sequence_length, batch_size, EMBEDDING_DIM)\n",
                "# Check the Segment Embedding vectors for first 3 tokens of the first sample in the batch\n",
                "# you get segment_embedded[i,0,:] where i refers to the i'th token of the first sample(b=0) in the batch\n",
                "for i in range(3):\n",
                "    print(f\"Segment Embeddings for the {i}th token of the first sample: {s_embedding[i,0,:]}\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "7ZeEI7ekYvA3",
                "outputId": "1ef5bc3a-3e13-4ba1-bb37-6f560748f3ff"
            },
            "id": "7ZeEI7ekYvA3",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Dimensions of segment embedding: torch.Size([102, 2, 10])\n",
                        "Segment Embeddings for the 0th token of the first sample: tensor([ 0.3030, -0.3011,  0.5643,  0.4439, -0.8016, -0.4365, -0.0510, -1.6664,\n",
                        "         0.9397,  2.7754], grad_fn=<SliceBackward0>)\n",
                        "Segment Embeddings for the 1th token of the first sample: tensor([ 0.3030, -0.3011,  0.5643,  0.4439, -0.8016, -0.4365, -0.0510, -1.6664,\n",
                        "         0.9397,  2.7754], grad_fn=<SliceBackward0>)\n",
                        "Segment Embeddings for the 2th token of the first sample: tensor([ 0.3030, -0.3011,  0.5643,  0.4439, -0.8016, -0.4365, -0.0510, -1.6664,\n",
                        "         0.9397,  2.7754], grad_fn=<SliceBackward0>)\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Create the combined embedding vectors\n",
                "bert_embeddings = t_embeddings + p_embedding + s_embedding\n",
                "print(f\"Dimensions of token + position + segment encoded tokens: {bert_embeddings.size()}\")\n",
                "#Check the BERT Embedding vectors for first 3 tokens of the first sample in the batch\n",
                "# you get bert_embeddings[i,0,:] where i refers to the i'th token of the first sample(b=0) in the batch\n",
                "for i in range(3):\n",
                "    print(f\"BERT_Embedding for {i}th token: {bert_embeddings[i,0,:]}\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "pGiHwdOIaog0",
                "outputId": "26504dce-2be9-4a1b-8c9a-8770ceb3c482"
            },
            "id": "pGiHwdOIaog0",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Dimensions of token + position + segment encoded tokens: torch.Size([102, 2, 10])\n",
                        "BERT_Embedding for 0th token: tensor([-0.0108,  0.5711, -2.8862,  4.2483,  8.1734, -2.2979, -4.2722,  3.9164,\n",
                        "         2.1972,  5.7294], grad_fn=<SliceBackward0>)\n",
                        "BERT_Embedding for 1th token: tensor([  1.2163,   4.9854,   8.9276,  -4.9510,  -9.5754,   3.2440, -10.3000,\n",
                        "         -7.2931,  -3.3239,  -9.6120], grad_fn=<SliceBackward0>)\n",
                        "BERT_Embedding for 2th token: tensor([ -1.8851, -11.4311,   2.6883,   5.9409,   0.6051,  -7.1578,  -1.7770,\n",
                        "          2.2404,  -3.5863,  -4.8256], grad_fn=<SliceBackward0>)\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "class BERT(torch.nn.Module):\n",
                "\n",
                "    def __init__(self, vocab_size, d_model=768, n_layers=12, heads=12, dropout=0.1):\n",
                "        \"\"\"\n",
                "        vocab_size: The size of the vocabulary.\n",
                "        d_model: The size of the embeddings (hidden size).\n",
                "        n_layers: The number of Transformer layers.\n",
                "        heads: The number of attention heads in each Transformer layer.\n",
                "        dropout: The dropout rate applied to embeddings and Transformer layers.\n",
                "        \"\"\"\n",
                "        super().__init__()\n",
                "        self.d_model = d_model\n",
                "        self.n_layers = n_layers\n",
                "        self.heads = heads\n",
                "\n",
                "        # Embedding layer that combines token embeddings and segment embeddings\n",
                "        self.bert_embedding = BERTEmbedding(vocab_size, d_model, dropout)\n",
                "\n",
                "        # Transformer Encoder layers\n",
                "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=heads, dropout=dropout,batch_first=False)\n",
                "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=n_layers)\n",
                "\n",
                "        # Linear layer for Next Sentence Prediction\n",
                "        self.nextsentenceprediction = nn.Linear(d_model, 2)\n",
                "\n",
                "        # Linear layer for Masked Language Modeling\n",
                "        self.masked_language = nn.Linear(d_model, vocab_size)\n",
                "\n",
                "    def forward(self, bert_inputs, segment_labels):\n",
                "        \"\"\"\n",
                "        bert_inputs: Input tokens.\n",
                "        segment_labels: Segment IDs for distinguishing different segments in the input.\n",
                "        mask: Attention mask to prevent attention to padding tokens.\n",
                "\n",
                "        return: Predictions for next sentence task and masked language modeling task.\n",
                "        \"\"\"\n",
                "\n",
                "        padding_mask = (bert_inputs == PAD_IDX).transpose(0, 1)\n",
                "        # Generate embeddings from input tokens and segment labels\n",
                "        my_bert_embedding = self.bert_embedding(bert_inputs, segment_labels)\n",
                "\n",
                "        # Pass embeddings through the Transformer encoder\n",
                "        transformer_encoder_output = self.transformer_encoder(my_bert_embedding,src_key_padding_mask=padding_mask)\n",
                "\n",
                "\n",
                "        next_sentence_prediction = self.nextsentenceprediction(transformer_encoder_output[ 0,:])\n",
                "\n",
                "\n",
                "        # Masked Language Modeling: Predict all tokens in the sequence\n",
                "        masked_language = self.masked_language(transformer_encoder_output)\n",
                "\n",
                "        return  next_sentence_prediction, masked_language"
            ],
            "metadata": {
                "id": "3pJeJYUFa5OT"
            },
            "id": "3pJeJYUFa5OT",
            "execution_count": 22,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# create an instance of the model\n",
                "EMBEDDING_DIM = 10\n",
                "\n",
                "# Define parameters\n",
                "vocab_size = 147161  # Replace VOCAB_SIZE with your vocabulary size\n",
                "d_model = EMBEDDING_DIM  # Replace EMBEDDING_DIM with your embedding dimension\n",
                "n_layers = 2  # Number of Transformer layers\n",
                "initial_heads = 12 # Initial number of attention heads\n",
                "initial_heads = 2\n",
                "# Ensure the number of heads is a factor of the embedding dimension\n",
                "heads = initial_heads - d_model % initial_heads\n",
                "\n",
                "dropout = 0.1  # Dropout rate\n",
                "\n",
                "# Create an instance of the BERT model\n",
                "model = BERT(vocab_size, d_model, n_layers, heads, dropout)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "z5a9nr0RbUhU",
                "outputId": "f0941bf3-b500-4a65-fc26-4e22dbe13d1c"
            },
            "id": "z5a9nr0RbUhU",
            "execution_count": 25,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
                        "  warnings.warn(\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "padding_mask = (bert_inputs == PAD_IDX).transpose(0, 1)\n",
                "padding_mask.shape"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "AVuV41nibbkO",
                "outputId": "cb733340-0275-4902-8c91-2cfb72b1fa88"
            },
            "id": "AVuV41nibbkO",
            "execution_count": 26,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "torch.Size([2, 102])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 26
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=heads, dropout=dropout,batch_first=False)\n",
                "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
                "# Pass embeddings through the Transformer encoder\n",
                "transformer_encoder_output = transformer_encoder(bert_embeddings,src_key_padding_mask=padding_mask)\n",
                "transformer_encoder_output.shape"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "xM_tp6iBblH1",
                "outputId": "9f538c58-c982-4fe6-9bac-92f073953587"
            },
            "id": "xM_tp6iBblH1",
            "execution_count": 27,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "torch.Size([102, 2, 10])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 27
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "nextsentenceprediction = nn.Linear(d_model, 2)\n",
                "nsp = nextsentenceprediction(transformer_encoder_output[ 0,:])\n",
                "#logits for NSP task\n",
                "print(f\"NSP Output Shape: {nsp.shape}\")  # Expected shape: (batch_size, 2)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "DsTNyIqObnch",
                "outputId": "321f8ad2-5697-4a7b-8f2a-23c400772849"
            },
            "id": "DsTNyIqObnch",
            "execution_count": 28,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "NSP Output Shape: torch.Size([2, 2])\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "masked_language = nn.Linear(d_model, vocab_size)\n",
                "# Masked Language Modeling: Predict all tokens in the sequence\n",
                "mlm = masked_language(transformer_encoder_output)\n",
                "#logits for MLM task\n",
                "print(f\"MLM Output Shape: {mlm.shape}\")  # Expected shape: (seq_length, batch_size, vocab_size)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "Peocm1oqbvQs",
                "outputId": "ca1da743-446a-4ef5-d6ba-4564246bacf8"
            },
            "id": "Peocm1oqbvQs",
            "execution_count": 29,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "MLM Output Shape: torch.Size([102, 2, 147161])\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Evaluation"
            ],
            "metadata": {
                "id": "gR06nPH8dJHt"
            },
            "id": "gR06nPH8dJHt"
        },
        {
            "cell_type": "code",
            "source": [
                "PAD_IDX=0\n",
                "loss_fn_mlm = nn.CrossEntropyLoss(ignore_index=PAD_IDX)# The loss function must ignore PAD tokens and only calculates loss for the masked tokens\n",
                "loss_fn_nsp = nn.CrossEntropyLoss()\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "model.to(device)\n",
                "device\n",
                "\n",
                "def evaluate(dataloader=test_dataloader, model=model, loss_fn_mlm=loss_fn_mlm, loss_fn_nsp=loss_fn_nsp, device=device):\n",
                "    model.eval()  # Turn off dropout and other training-specific behaviors\n",
                "\n",
                "    total_loss = 0\n",
                "    total_next_sentence_loss = 0\n",
                "    total_mask_loss = 0\n",
                "    total_batches = 0\n",
                "    with torch.no_grad():  # Turn off gradients for validation, saves memory and computations\n",
                "        for batch in dataloader:\n",
                "            bert_inputs, bert_labels, segment_labels, is_nexts = [b.to(device) for b in batch]\n",
                "\n",
                "            # Forward pass\n",
                "            next_sentence_prediction, masked_language = model(bert_inputs, segment_labels)\n",
                "\n",
                "            # Calculate loss for next sentence prediction\n",
                "            # Ensure is_nexts is of the correct shape for CrossEntropyLoss\n",
                "            next_loss = loss_fn_nsp(next_sentence_prediction, is_nexts.view(-1))\n",
                "\n",
                "            # Calculate loss for predicting masked tokens\n",
                "            # Flatten both masked_language predictions and bert_labels to match CrossEntropyLoss input requirements\n",
                "            mask_loss = loss_fn_mlm(masked_language.view(-1, masked_language.size(-1)), bert_labels.view(-1))\n",
                "\n",
                "            # Sum up the two losses\n",
                "            loss = next_loss + mask_loss\n",
                "            if torch.isnan(loss):\n",
                "                continue\n",
                "            else:\n",
                "                total_loss += loss.item()\n",
                "                total_next_sentence_loss += next_loss.item()\n",
                "                total_mask_loss += mask_loss.item()\n",
                "                total_batches += 1\n",
                "\n",
                "    avg_loss = total_loss / (total_batches + 1)\n",
                "    avg_next_sentence_loss = total_next_sentence_loss / (total_batches + 1)\n",
                "    avg_mask_loss = total_mask_loss / (total_batches + 1)\n",
                "\n",
                "    print(f\"Average Loss: {avg_loss:.4f}, Average Next Sentence Loss: {avg_next_sentence_loss:.4f}, Average Mask Loss: {avg_mask_loss:.4f}\")\n",
                "    return avg_loss"
            ],
            "metadata": {
                "id": "IGlFQ3gibyHg"
            },
            "id": "IGlFQ3gibyHg",
            "execution_count": 30,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Training\n",
                "\n",
                "(Use randomly sampled dataset to reduce processing time.)"
            ],
            "metadata": {
                "id": "Jc6-my1Mdmh7"
            },
            "id": "Jc6-my1Mdmh7"
        },
        {
            "cell_type": "code",
            "source": [
                "BATCH_SIZE = 3\n",
                "\n",
                "train_dataset_path = './bert_dataset/bert_train_data_sampled.csv'\n",
                "test_dataset_path = './bert_dataset/bert_test_data_sampled.csv'\n",
                "\n",
                "train_dataset = BERTCSVDataset(train_dataset_path)\n",
                "test_dataset = BERTCSVDataset(test_dataset_path)\n",
                "\n",
                "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
                "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)"
            ],
            "metadata": {
                "id": "_Op7m_rmdj3A"
            },
            "id": "_Op7m_rmdj3A",
            "execution_count": 31,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "from torch.optim import Adam\n",
                "from transformers import get_linear_schedule_with_warmup\n",
                "from tqdm import tqdm\n",
                "\n",
                "\n",
                "# Define the optimizer\n",
                "optimizer = Adam(model.parameters(), lr=1e-4, weight_decay=0.01, betas=(0.9, 0.999))\n",
                "\n",
                "# Training loop setup\n",
                "num_epochs = 1\n",
                "total_steps = num_epochs * len(train_dataloader)\n",
                "\n",
                "# Define the number of warmup steps, e.g., 10% of total\n",
                "warmup_steps = int(total_steps * 0.1)\n",
                "\n",
                "# Create the learning rate scheduler\n",
                "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
                "                                            num_warmup_steps=warmup_steps,\n",
                "                                            num_training_steps=total_steps)\n",
                "\n",
                "# Lists to store losses for plotting\n",
                "train_losses = []\n",
                "eval_losses = []\n",
                "\n",
                "for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "\n",
                "    for step, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")):\n",
                "        bert_inputs, bert_labels, segment_labels, is_nexts = [b.to(device) for b in batch]\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        next_sentence_prediction, masked_language = model(bert_inputs, segment_labels)\n",
                "\n",
                "        next_loss = loss_fn_nsp(next_sentence_prediction, is_nexts)\n",
                "        mask_loss = loss_fn_mlm(masked_language.view(-1, masked_language.size(-1)), bert_labels.view(-1))\n",
                "\n",
                "        loss = next_loss + mask_loss\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "        optimizer.step()\n",
                "        scheduler.step()  # Update the learning rate\n",
                "\n",
                "        total_loss += loss.item()\n",
                "\n",
                "        if torch.isnan(loss):\n",
                "            continue\n",
                "        else:\n",
                "            total_loss += loss.item()\n",
                "\n",
                "    avg_train_loss = total_loss / len(train_dataloader) + 1\n",
                "    train_losses.append(avg_train_loss)\n",
                "    print(f\"Epoch {epoch+1} - Average training loss: {avg_train_loss:.4f}\")\n",
                "\n",
                "    # Evaluation after each epoch\n",
                "    eval_loss = evaluate(test_dataloader, model, loss_fn_nsp, loss_fn_mlm, device)\n",
                "    eval_losses.append(eval_loss)"
            ],
            "metadata": {
                "id": "3hlCAVM_d6Ji"
            },
            "id": "3hlCAVM_d6Ji",
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Plotting the loss values\n",
                "plt.figure(figsize=(6, 4))\n",
                "plt.scatter(range(1,num_epochs+1), train_losses, label=\"Training Loss\", color='blue')\n",
                "plt.scatter(range(1,num_epochs+1), eval_losses, label=\"Evaluation Loss\", color='orange')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.title('Training and Evaluation Loss')\n",
                "plt.legend()\n",
                "plt.show()"
            ],
            "metadata": {
                "id": "Ju5Un4f-d7jC"
            },
            "id": "Ju5Un4f-d7jC",
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Inference\n",
                "\n",
                "(load model from pt file)"
            ],
            "metadata": {
                "id": "sA5hEd34e7bo"
            },
            "id": "sA5hEd34e7bo"
        },
        {
            "cell_type": "code",
            "source": [
                "model = BERT(vocab_size, d_model, n_layers, heads, dropout)  # Ensure these parameters match the original model's\n",
                "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/H04Cs7O75aOfmJ4YP2HdPw.pt'\n",
                "model.load_state_dict(torch.load('H04Cs7O75aOfmJ4YP2HdPw.pt',map_location=torch.device('cpu')))\n",
                "model.to(device)"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "O3yvB2Hcey5n",
                "outputId": "ede27314-9cfb-45c9-adfe-63460740b18c"
            },
            "id": "O3yvB2Hcey5n",
            "execution_count": 35,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "--2025-04-24 15:48:10--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/H04Cs7O75aOfmJ4YP2HdPw.pt\n",
                        "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n",
                        "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n",
                        "HTTP request sent, awaiting response... 200 OK\n",
                        "Length: 13099721 (12M) [binary/octet-stream]\n",
                        "Saving to: \u2018H04Cs7O75aOfmJ4YP2HdPw.pt\u2019\n",
                        "\n",
                        "H04Cs7O75aOfmJ4YP2H 100%[===================>]  12.49M  63.2MB/s    in 0.2s    \n",
                        "\n",
                        "2025-04-24 15:48:11 (63.2 MB/s) - \u2018H04Cs7O75aOfmJ4YP2HdPw.pt\u2019 saved [13099721/13099721]\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "BERT(\n",
                            "  (bert_embedding): BERTEmbedding(\n",
                            "    (token_embedding): TokenEmbedding(\n",
                            "      (embedding): Embedding(147161, 10)\n",
                            "    )\n",
                            "    (positional_encoding): PositionalEncoding(\n",
                            "      (dropout): Dropout(p=0.1, inplace=False)\n",
                            "    )\n",
                            "    (segment_embedding): Embedding(3, 10)\n",
                            "    (dropout): Dropout(p=0.1, inplace=False)\n",
                            "  )\n",
                            "  (encoder_layer): TransformerEncoderLayer(\n",
                            "    (self_attn): MultiheadAttention(\n",
                            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=10, out_features=10, bias=True)\n",
                            "    )\n",
                            "    (linear1): Linear(in_features=10, out_features=2048, bias=True)\n",
                            "    (dropout): Dropout(p=0.1, inplace=False)\n",
                            "    (linear2): Linear(in_features=2048, out_features=10, bias=True)\n",
                            "    (norm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
                            "    (norm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
                            "    (dropout1): Dropout(p=0.1, inplace=False)\n",
                            "    (dropout2): Dropout(p=0.1, inplace=False)\n",
                            "  )\n",
                            "  (transformer_encoder): TransformerEncoder(\n",
                            "    (layers): ModuleList(\n",
                            "      (0-1): 2 x TransformerEncoderLayer(\n",
                            "        (self_attn): MultiheadAttention(\n",
                            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=10, out_features=10, bias=True)\n",
                            "        )\n",
                            "        (linear1): Linear(in_features=10, out_features=2048, bias=True)\n",
                            "        (dropout): Dropout(p=0.1, inplace=False)\n",
                            "        (linear2): Linear(in_features=2048, out_features=10, bias=True)\n",
                            "        (norm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
                            "        (norm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
                            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
                            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
                            "      )\n",
                            "    )\n",
                            "  )\n",
                            "  (nextsentenceprediction): Linear(in_features=10, out_features=2, bias=True)\n",
                            "  (masked_language): Linear(in_features=10, out_features=147161, bias=True)\n",
                            ")"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 35
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Initialize the tokenizer with the BERT model's vocabulary\n",
                "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
                "model.eval()\n",
                "\n",
                "def predict_nsp(sentence1, sentence2, model, tokenizer):\n",
                "    # Tokenize sentences with special tokens\n",
                "    tokens = tokenizer.encode_plus(sentence1, sentence2, return_tensors=\"pt\")\n",
                "    tokens_tensor = tokens[\"input_ids\"].to(device)\n",
                "    segment_tensor = tokens[\"token_type_ids\"].to(device)\n",
                "\n",
                "    # Predict\n",
                "    with torch.no_grad():\n",
                "        # Assuming the model returns NSP predictions first\n",
                "        nsp_prediction, _ = model(tokens_tensor, segment_tensor)\n",
                "        # Select the first element (first sequence) of the logits tensor\n",
                "        first_logits = nsp_prediction[0].unsqueeze(0)  # Adds an extra dimension, making it [1, 2]\n",
                "        logits = torch.softmax(first_logits, dim=1)\n",
                "        prediction = torch.argmax(logits, dim=1).item()\n",
                "\n",
                "    # Interpret the prediction\n",
                "    return \"Second sentence follows the first\" if prediction == 1 else \"Second sentence does not follow the first\"\n",
                "\n",
                "# Example usage\n",
                "sentence1 = \"The S&P dropped 10% after the Iraqi war.\"\n",
                "sentence2 = \"I hate chocolate\"\n",
                "\n",
                "print(predict_nsp(sentence1, sentence2, model, tokenizer))"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "SwjBcE8IfCuR",
                "outputId": "25cba537-604e-4912-d274-1a3bb59e0801"
            },
            "id": "SwjBcE8IfCuR",
            "execution_count": 42,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Second sentence follows the first\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "def predict_mlm(sentence, model, tokenizer):\n",
                "    # Tokenize the input sentence and convert to token IDs, including special tokens\n",
                "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
                "    tokens_tensor = inputs.input_ids\n",
                "\n",
                "    # Create dummy segment labels filled with zeros, assuming it's needed by your model\n",
                "    segment_labels = torch.zeros_like(tokens_tensor)\n",
                "\n",
                "    with torch.no_grad():\n",
                "        # Forward pass through the model, now correctly handling the output tuple\n",
                "        output_tuple = model(tokens_tensor, segment_labels)\n",
                "\n",
                "        # Assuming the second element of the tuple contains the MLM logits\n",
                "        predictions = output_tuple[1]  # Adjusted based on your model's output\n",
                "\n",
                "        # Identify the position of the [MASK] token\n",
                "        mask_token_index = (tokens_tensor == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
                "\n",
                "        # Get the predicted index for the [MASK] token from the MLM logits\n",
                "        predicted_index = torch.argmax(predictions[0, mask_token_index.item(), :], dim=-1)\n",
                "        predicted_token = tokenizer.convert_ids_to_tokens([predicted_index.item()])[0]\n",
                "\n",
                "        # Replace [MASK] in the original sentence with the predicted token\n",
                "        predicted_sentence = sentence.replace(tokenizer.mask_token, predicted_token, 1)\n",
                "\n",
                "    return predicted_sentence\n",
                "\n",
                "\n",
                "# Example usage\n",
                "sentence = \"The cat sat on the [MASK].\"\n",
                "print(predict_mlm(sentence, model, tokenizer))"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "epq1R2evfHEC",
                "outputId": "7ae96f15-1d08-4ddc-ff6f-3e2f32852e4f"
            },
            "id": "epq1R2evfHEC",
            "execution_count": 43,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "The cat sat on the [unused8].\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Exercise 1: Next Sentence Prediction (NSP) with BERT"
            ],
            "metadata": {
                "id": "8QTXrY1Zf0IN"
            },
            "id": "8QTXrY1Zf0IN"
        },
        {
            "cell_type": "code",
            "source": [
                "from transformers import BertForPreTraining\n",
                "\n",
                "# Load pretrained model tokenizer (vocabulary)\n",
                "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
                "\n",
                "# Load pretrained model (weights)\n",
                "model = BertForPreTraining.from_pretrained('bert-base-uncased')\n",
                "# Prepare text pair for NSP\n",
                "text_1 = \"The cat sat on the mat\"\n",
                "text_2 = \"It was a sunny day\"\n",
                "# Encode text\n",
                "inputs = tokenizer(text_1, text_2, return_tensors=\"pt\")\n",
                "\n",
                "# Predict\n",
                "with torch.no_grad():\n",
                "    outputs = model(**inputs, next_sentence_label=torch.LongTensor([1]))\n",
                "    nsp_logits = outputs.seq_relationship_logits\n",
                "\n",
                "# Interpret the result for NSP\n",
                "if torch.argmax(nsp_logits, dim=-1).item() == 0:\n",
                "    print(\"The model thinks these sentences are NOT consecutive.\")\n",
                "else:\n",
                "    print(\"The model thinks these sentences are consecutive.\")"
            ],
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 121,
                    "referenced_widgets": [
                        "e55f0a83a1b44470a0a3d8c5bc6758c5",
                        "e8999ef1203f44a69c909f4709b5485c",
                        "b781948aba784be086822753e8f2b11e",
                        "c8067336961b46929fa65a86eda84919",
                        "f8aeeb1ce3b24793856f3485f7fbd64a",
                        "3435f6ae3d2448b19a3d1ceed68d716a",
                        "a13faf1adf4e447abed913b149d3ff58",
                        "818faa0371554c61a57a5dde768622d1",
                        "66af7af431ba45a9938c5cd109d7c9c6",
                        "0038f302dd2045399c3a93736bb26e68",
                        "2df5c0834a194605a8204c90ddc67a11"
                    ]
                },
                "id": "vX7AaMvvfYGk",
                "outputId": "3aea4657-d766-49a9-af16-bf4a1185b56c"
            },
            "id": "vX7AaMvvfYGk",
            "execution_count": 44,
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
                        "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
                        ],
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "e55f0a83a1b44470a0a3d8c5bc6758c5"
                        }
                    },
                    "metadata": {}
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "The model thinks these sentences are NOT consecutive.\n"
                    ]
                }
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Exercise 2: Masked Language Modeling (MLM) with BERT"
            ],
            "metadata": {
                "id": "DQ0F5aTZgX6J"
            },
            "id": "DQ0F5aTZgX6J"
        },
        {
            "cell_type": "code",
            "source": [],
            "metadata": {
                "id": "B4FlvdA3gPjr"
            },
            "id": "B4FlvdA3gPjr",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        },
        "colab": {
            "provenance": [],
            "include_colab_link": true
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "e55f0a83a1b44470a0a3d8c5bc6758c5": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "HBoxModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_dom_classes": [],
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "HBoxModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/controls",
                        "_view_module_version": "1.5.0",
                        "_view_name": "HBoxView",
                        "box_style": "",
                        "children": [
                            "IPY_MODEL_e8999ef1203f44a69c909f4709b5485c",
                            "IPY_MODEL_b781948aba784be086822753e8f2b11e",
                            "IPY_MODEL_c8067336961b46929fa65a86eda84919"
                        ],
                        "layout": "IPY_MODEL_f8aeeb1ce3b24793856f3485f7fbd64a"
                    }
                },
                "e8999ef1203f44a69c909f4709b5485c": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "HTMLModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_dom_classes": [],
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "HTMLModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/controls",
                        "_view_module_version": "1.5.0",
                        "_view_name": "HTMLView",
                        "description": "",
                        "description_tooltip": null,
                        "layout": "IPY_MODEL_3435f6ae3d2448b19a3d1ceed68d716a",
                        "placeholder": "\u200b",
                        "style": "IPY_MODEL_a13faf1adf4e447abed913b149d3ff58",
                        "value": "model.safetensors:\u2007100%"
                    }
                },
                "b781948aba784be086822753e8f2b11e": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "FloatProgressModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_dom_classes": [],
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "FloatProgressModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/controls",
                        "_view_module_version": "1.5.0",
                        "_view_name": "ProgressView",
                        "bar_style": "success",
                        "description": "",
                        "description_tooltip": null,
                        "layout": "IPY_MODEL_818faa0371554c61a57a5dde768622d1",
                        "max": 440449768,
                        "min": 0,
                        "orientation": "horizontal",
                        "style": "IPY_MODEL_66af7af431ba45a9938c5cd109d7c9c6",
                        "value": 440449768
                    }
                },
                "c8067336961b46929fa65a86eda84919": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "HTMLModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_dom_classes": [],
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "HTMLModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/controls",
                        "_view_module_version": "1.5.0",
                        "_view_name": "HTMLView",
                        "description": "",
                        "description_tooltip": null,
                        "layout": "IPY_MODEL_0038f302dd2045399c3a93736bb26e68",
                        "placeholder": "\u200b",
                        "style": "IPY_MODEL_2df5c0834a194605a8204c90ddc67a11",
                        "value": "\u2007440M/440M\u2007[00:06&lt;00:00,\u200783.8MB/s]"
                    }
                },
                "f8aeeb1ce3b24793856f3485f7fbd64a": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_model_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.2.0",
                        "_model_name": "LayoutModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "LayoutView",
                        "align_content": null,
                        "align_items": null,
                        "align_self": null,
                        "border": null,
                        "bottom": null,
                        "display": null,
                        "flex": null,
                        "flex_flow": null,
                        "grid_area": null,
                        "grid_auto_columns": null,
                        "grid_auto_flow": null,
                        "grid_auto_rows": null,
                        "grid_column": null,
                        "grid_gap": null,
                        "grid_row": null,
                        "grid_template_areas": null,
                        "grid_template_columns": null,
                        "grid_template_rows": null,
                        "height": null,
                        "justify_content": null,
                        "justify_items": null,
                        "left": null,
                        "margin": null,
                        "max_height": null,
                        "max_width": null,
                        "min_height": null,
                        "min_width": null,
                        "object_fit": null,
                        "object_position": null,
                        "order": null,
                        "overflow": null,
                        "overflow_x": null,
                        "overflow_y": null,
                        "padding": null,
                        "right": null,
                        "top": null,
                        "visibility": null,
                        "width": null
                    }
                },
                "3435f6ae3d2448b19a3d1ceed68d716a": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_model_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.2.0",
                        "_model_name": "LayoutModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "LayoutView",
                        "align_content": null,
                        "align_items": null,
                        "align_self": null,
                        "border": null,
                        "bottom": null,
                        "display": null,
                        "flex": null,
                        "flex_flow": null,
                        "grid_area": null,
                        "grid_auto_columns": null,
                        "grid_auto_flow": null,
                        "grid_auto_rows": null,
                        "grid_column": null,
                        "grid_gap": null,
                        "grid_row": null,
                        "grid_template_areas": null,
                        "grid_template_columns": null,
                        "grid_template_rows": null,
                        "height": null,
                        "justify_content": null,
                        "justify_items": null,
                        "left": null,
                        "margin": null,
                        "max_height": null,
                        "max_width": null,
                        "min_height": null,
                        "min_width": null,
                        "object_fit": null,
                        "object_position": null,
                        "order": null,
                        "overflow": null,
                        "overflow_x": null,
                        "overflow_y": null,
                        "padding": null,
                        "right": null,
                        "top": null,
                        "visibility": null,
                        "width": null
                    }
                },
                "a13faf1adf4e447abed913b149d3ff58": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "DescriptionStyleModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "DescriptionStyleModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "StyleView",
                        "description_width": ""
                    }
                },
                "818faa0371554c61a57a5dde768622d1": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_model_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.2.0",
                        "_model_name": "LayoutModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "LayoutView",
                        "align_content": null,
                        "align_items": null,
                        "align_self": null,
                        "border": null,
                        "bottom": null,
                        "display": null,
                        "flex": null,
                        "flex_flow": null,
                        "grid_area": null,
                        "grid_auto_columns": null,
                        "grid_auto_flow": null,
                        "grid_auto_rows": null,
                        "grid_column": null,
                        "grid_gap": null,
                        "grid_row": null,
                        "grid_template_areas": null,
                        "grid_template_columns": null,
                        "grid_template_rows": null,
                        "height": null,
                        "justify_content": null,
                        "justify_items": null,
                        "left": null,
                        "margin": null,
                        "max_height": null,
                        "max_width": null,
                        "min_height": null,
                        "min_width": null,
                        "object_fit": null,
                        "object_position": null,
                        "order": null,
                        "overflow": null,
                        "overflow_x": null,
                        "overflow_y": null,
                        "padding": null,
                        "right": null,
                        "top": null,
                        "visibility": null,
                        "width": null
                    }
                },
                "66af7af431ba45a9938c5cd109d7c9c6": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "ProgressStyleModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "ProgressStyleModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "StyleView",
                        "bar_color": null,
                        "description_width": ""
                    }
                },
                "0038f302dd2045399c3a93736bb26e68": {
                    "model_module": "@jupyter-widgets/base",
                    "model_name": "LayoutModel",
                    "model_module_version": "1.2.0",
                    "state": {
                        "_model_module": "@jupyter-widgets/base",
                        "_model_module_version": "1.2.0",
                        "_model_name": "LayoutModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "LayoutView",
                        "align_content": null,
                        "align_items": null,
                        "align_self": null,
                        "border": null,
                        "bottom": null,
                        "display": null,
                        "flex": null,
                        "flex_flow": null,
                        "grid_area": null,
                        "grid_auto_columns": null,
                        "grid_auto_flow": null,
                        "grid_auto_rows": null,
                        "grid_column": null,
                        "grid_gap": null,
                        "grid_row": null,
                        "grid_template_areas": null,
                        "grid_template_columns": null,
                        "grid_template_rows": null,
                        "height": null,
                        "justify_content": null,
                        "justify_items": null,
                        "left": null,
                        "margin": null,
                        "max_height": null,
                        "max_width": null,
                        "min_height": null,
                        "min_width": null,
                        "object_fit": null,
                        "object_position": null,
                        "order": null,
                        "overflow": null,
                        "overflow_x": null,
                        "overflow_y": null,
                        "padding": null,
                        "right": null,
                        "top": null,
                        "visibility": null,
                        "width": null
                    }
                },
                "2df5c0834a194605a8204c90ddc67a11": {
                    "model_module": "@jupyter-widgets/controls",
                    "model_name": "DescriptionStyleModel",
                    "model_module_version": "1.5.0",
                    "state": {
                        "_model_module": "@jupyter-widgets/controls",
                        "_model_module_version": "1.5.0",
                        "_model_name": "DescriptionStyleModel",
                        "_view_count": null,
                        "_view_module": "@jupyter-widgets/base",
                        "_view_module_version": "1.2.0",
                        "_view_name": "StyleView",
                        "description_width": ""
                    }
                }
            },
            "state": {}
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}