{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vektor8891/llm/blob/main/projects/19_lora_pytorch/19_lora_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchtext==0.17.2\n",
        "# !pip install portalocker==2.8.2\n",
        "# !pip install torchdata==0.7.1"
      ],
      "metadata": {
        "id": "c1MfMelhSHDC"
      },
      "id": "c1MfMelhSHDC",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LoRA with PyTorch\n",
        "\n",
        "- Low-Rank Adaptation (LoRA): fine-tune model by introducing small fraction of additional parameters compared to the total number of parameters in a large model\n",
        "\n",
        "### Defining helper functions"
      ],
      "metadata": {
        "id": "XWAWkTaZQ8RZ"
      },
      "id": "XWAWkTaZQ8RZ"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "91da9c1b",
      "metadata": {
        "id": "91da9c1b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot(COST,ACC):\n",
        "    fig, ax1 = plt.subplots()\n",
        "    color = 'tab:red'\n",
        "    ax1.plot(COST, color=color)\n",
        "    ax1.set_xlabel('epoch', color=color)\n",
        "    ax1.set_ylabel('total loss', color=color)\n",
        "    ax1.tick_params(axis='y', color=color)\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    color = 'tab:blue'\n",
        "    ax2.set_ylabel('accuracy', color=color)  # You already handled the x-label with ax1\n",
        "    ax2.plot(ACC, color=color)\n",
        "    ax2.tick_params(axis='y', color=color)\n",
        "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data pipeline"
      ],
      "metadata": {
        "id": "ihKs9T6KSALd"
      },
      "id": "ihKs9T6KSALd"
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for  _,text in data_iter:\n",
        "        yield tokenizer(text)"
      ],
      "metadata": {
        "id": "1hMw9h-yR6ce",
        "outputId": "a66ef5bb-384f-4354-9b5c-af6d55480137",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1hMw9h-yR6ce",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-3-53aaa3e7484d>\", line 1, in <cell line: 0>\n",
            "    from torchtext.data.utils import get_tokenizer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtext/__init__.py\", line 3, in <module>\n",
            "    from torch.hub import _get_torch_home\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import GloVe, Vectors\n",
        "\n",
        "# Note that GloVe embeddings are typically downloaded using:\n",
        "#glove_embedding = GloVe(name=\"6B\", dim=100)\n",
        "# However, the GloVe server is frequently down. The code below offers a workaround\n",
        "\n",
        "class GloVe_override(Vectors):\n",
        "    url = {\n",
        "        \"6B\": \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/tQdezXocAJMBMPfUJx_iUg/glove-6B.zip\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, name=\"6B\", dim=100, **kwargs) -> None:\n",
        "        url = self.url[name]\n",
        "        name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
        "        #name = \"glove.{}/glove.{}.{}d.txt\".format(name, name, str(dim))\n",
        "        super(GloVe_override, self).__init__(name, url=url, **kwargs)\n",
        "\n",
        "class GloVe_override2(Vectors):\n",
        "    url = {\n",
        "        \"6B\": \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/tQdezXocAJMBMPfUJx_iUg/glove-6B.zip\",\n",
        "    }\n",
        "\n",
        "    def __init__(self, name=\"6B\", dim=100, **kwargs) -> None:\n",
        "        url = self.url[name]\n",
        "        #name = \"glove.{}.{}d.txt\".format(name, str(dim))\n",
        "        name = \"glove.{}/glove.{}.{}d.txt\".format(name, name, str(dim))\n",
        "        super(GloVe_override2, self).__init__(name, url=url, **kwargs)\n",
        "\n",
        "try:\n",
        "    glove_embedding = GloVe_override(name=\"6B\", dim=100)\n",
        "except:\n",
        "    try:\n",
        "        glove_embedding = GloVe_override2(name=\"6B\", dim=100)\n",
        "    except:\n",
        "        glove_embedding = GloVe(name=\"6B\", dim=100)"
      ],
      "metadata": {
        "id": "38tsuxcEVU0w"
      },
      "id": "38tsuxcEVU0w",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import vocab\n",
        "\n",
        "vocab = vocab(glove_embedding .stoi, 0,specials=('<unk>', '<pad>'))\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "def text_pipeline(x):\n",
        "  return vocab(tokenizer(x))\n",
        "\n",
        "def label_pipeline(x):\n",
        "   return int(x)"
      ],
      "metadata": {
        "id": "GIuoeNQyVmAc"
      },
      "id": "GIuoeNQyVmAc",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMDB dataset"
      ],
      "metadata": {
        "id": "pHCnhvLoV4qL"
      },
      "id": "pHCnhvLoV4qL"
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "import tarfile\n",
        "import tempfile\n",
        "import io\n",
        "\n",
        "urlopened = urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/35t-FeC-2uN1ozOwPs7wFg.gz')\n",
        "tar = tarfile.open(fileobj=io.BytesIO(urlopened.read()))\n",
        "tempdir = tempfile.TemporaryDirectory()\n",
        "tar.extractall(tempdir.name)\n",
        "tar.close()"
      ],
      "metadata": {
        "id": "L-g1XGkvV4Rq"
      },
      "id": "L-g1XGkvV4Rq",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, root_dir, train=True):\n",
        "        \"\"\"\n",
        "        root_dir: The base directory of the IMDB dataset.\n",
        "        train: A boolean flag indicating whether to use training or test data.\n",
        "        \"\"\"\n",
        "        self.root_dir = os.path.join(root_dir, \"train\" if train else \"test\")\n",
        "        self.neg_files = [os.path.join(self.root_dir, \"neg\", f) for f in os.listdir(os.path.join(self.root_dir, \"neg\")) if f.endswith('.txt')]\n",
        "        self.pos_files = [os.path.join(self.root_dir, \"pos\", f) for f in os.listdir(os.path.join(self.root_dir, \"pos\")) if f.endswith('.txt')]\n",
        "        self.files = self.neg_files + self.pos_files\n",
        "        self.labels = [0] * len(self.neg_files) + [1] * len(self.pos_files)\n",
        "        self.pos_inx=len(self.pos_files)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.files[idx]\n",
        "        label = self.labels[idx]\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        return label, content"
      ],
      "metadata": {
        "id": "-Rb_dofXV3xx"
      },
      "id": "-Rb_dofXV3xx",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "root_dir = tempdir.name + '/' + 'imdb_dataset'\n",
        "train_iter = IMDBDataset(root_dir=root_dir, train=True)  # For training data\n",
        "test_iter = IMDBDataset(root_dir=root_dir, train=False)  # For test dataart=train_iter.pos_inx"
      ],
      "metadata": {
        "id": "8QZlcRfTWLuJ"
      },
      "id": "8QZlcRfTWLuJ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start=train_iter.pos_inx\n",
        "start=0\n",
        "for i in range(-10,10):\n",
        "    print(train_iter[start+i])"
      ],
      "metadata": {
        "id": "duUonSSjWN1n",
        "outputId": "aab92025-13ad-4baf-bdca-55794f06383f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "duUonSSjWN1n",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, \"A bunch of American students and their tutor decide to visit the ugliest part of Ireland in order to study ancient religious practices. Despite being repeatedly warned about the dangers of straying off the beaten path (by the local creepy Irish guy, natch), they do just that, and wind up with their insides on the outside courtesy of a family of inbred cannibals (the descendants of the infamous Sawney Bean clan, who according to the film's silly plot, upped sticks from Scotland and settled on the Emerald Isle).<br /><br />If you think that porn stars plus low budget horror automatically equals tons of nudity and terrible acting, then think again: Evil Breed is bristling with adult stars, but in fact, there's not nearly as much nudity as one might expect given the 'talent' involved, and the acting, although far from Oscar worthy, ain't all that bad (with the exception of Ginger Lynn Allen, who we know can do marvellous 'French', but whose Irish is lousy).<br /><br />Evil Breed opens in superb style with the brutal slaughter of a couple of amorous campers: after some brief under-canvas sex, the silicone enhanced hottie is dragged from the tent and torn in half; the guy has his arms and legs cut off and is roasted on a spit. It's a very gory start, and bodes well for the rest of the film.<br /><br />Unfortunately, after this promising beginning, things start to go seriously downhill: we are introduced to the main characters, an annoying bunch of twenty-somethings just begging to become cannibal chow, and are subjected to a fair amount of time wasting in the form of some terrible false scares, a lot of blarney about murderous druids from local Irish weirdo Gary (Simon Peacock), and worst of all, some sub-Scream, post-modernistic conversation about the conventions of horror films (how clever!).<br /><br />Then, just as it looks as though the film is never going to get any better, director Christian Viel decides to get serious: a guy gets a knife rammed through his head and there's a gratuitous sex-in-the-shower scene featuring lovely blonde Gillian Leigh (NOT a porn star, but I'm sure there's a career there waiting if she wants it). After that, things improve rapidly as the cannibals kick into top flesh-eating gear, and the film is transformed into a veritable bloodbath: Gary has a machete rammed up his ass (about time!), and is strangled with his intestines; Ginger Lynn kick-boxes a mutant; Jenna Jameson is torn open, eviscerated and has her silicone breast implant gnawed on by confused cannibal; a guy gets decapitated by cheese wire; and Taylor Hayes is seen bloody, bruised and naked with a dead foetus between her legs (apparantly, she's been captured and used as breeding stock).<br /><br />All of this is so outrageously gory that it makes sitting through the less interesting stuff worthwhile, and earns Evil Breed a final rating of 7/10.<br /><br />NB. A very troubled production and studio meddling resulted in Christian Viel eventually abandoning the project. Re-shoots were done and the gore was heavily trimmed for a US release. The good news is that although the film doesn't flow as well as it might have, and is cursed with a terrible ending, the UK DVD (the version I watched) seems to have been left relatively intact as far as the splatter is concerned (only 13s were cut from the film in total).\")\n",
            "(1, 'Well, I am delighted to hear a rumor that this may finally be issued on DVD. When that will happen, I don\\'t know, but I will grab it when it\\'s released.<br /><br />In my humble opinion, this is Errol Flynn\\'s most entertaining film, especially when \"Gentleman Jim\" Corbett\\'s ring career begins in the film. Then it goes from a good film to a great one.<br /><br />Few people could play arrogant men and still come off as a likable good guy as well as Flynn could and this film is a perfect example of that. Reportedly, this was Flynn\\'s favorite role and I believe that. You can just sense how much fun he was having here. Ward Bond also looks like he was really enjoying his role playing the famous John L. Sullivan. Bond, too, was never better.<br /><br />There is just the right amount of action boxing scenes in here and they are pretty well done, too. Corbett\\'s family is fun to watch, too, as they carry on in the stands during Jim\\'s matches. Out of the arena, Corbett\\'s family\\'s constant arguments and yelling can get a little too loud and annoying but they set the stage for a fitting conclusion.<br /><br />And speaking of the conclusion, Sullivan\\'s speech to Corbett after the big fight is very touching and the highlight of the film. Some mean-spirited critics (Variety, for example) didn\\'t like that ending nor the fact that much of the film is fictionalized but - duh - most films are fictionalized, like it or not. And, in this case, it made for a nice story and nice ending. (In real life, Corbett was a very soft-spoken true gentleman, not anything like Flynn\\'s portrayal, but Flynn still make him a good guy.)<br /><br />This is one of the more entertaining classic films I have ever watched and I eagerly wait for the DVD.')\n",
            "(1, 'Tarzan and Jane are living happily in the jungle. Some men come looking for ivory and to take Jane back to civilization. But Jane loves Tarzan and refuses to leave. One of the men falls in love with Jane and is determined to take her back...even if that means killing Tarzan.<br /><br />This is a rarity--a sequel that\\'s better than the original. \"Tarzan, the Ape Man\" of 1932 was good but had some dreadful special effects and sort of dragged. This one has MUCH better effects and is a lot more adult. There is tons of blatant racism (a black man is shot to death point blank--and no one really cares) but this was 1934. There\\'s also plenty of blood, gore and violence (for a 1934 movie) and uncut prints have Jane doing a lengthy underwater swim totally nude! There\\'s also obvious sexual content and Tarzan and Jane are wearing next to nothing and (it\\'s implied) they sleep together and have sex--without being married. This wouldn\\'t bother anyone today but in 1934 this was pretty extreme.<br /><br />That aside, the movie is well-directed, very fast-moving and full of adventure and excitement. Seeing Weissmuller in that skimpy lion cloth is certainly a treat for the eyes and Jane\\'s outfit is pretty revealing too. I still think Maureen O\\'Sullivan is bad as Jane but Weismuller is perfect as Tarzan. Everybody else is OK.<br /><br />This is easily the best Weismuller--O\\'Hara Tarzan out there. WELL worth seeing but not for kids!')\n",
            "(1, 'Hilarious, evocative, confusing, brilliant film. Reminds me of Bunuel\\'s L\\'Age D\\'Or or Jodorowsky\\'s Holy Mountain-- lots of strange characters mucking about and looking for..... what is it? I laughed almost the whole way through, all the while keeping a peripheral eye on the bewildered and occasionally horrified reactions of the audience that surrounded me in the theatre. Entertaining through and through, from the beginning to the guts and poisoned entrails all the way to the end, if it was an end. I only wish i could remember every detail. It haunts me sometimes.<br /><br />Honestly, though, i have only the most positive recollections of this film. As it doesn\\'t seem to be available to take home and watch, i suppose i\\'ll have to wait a few more years until Crispin Glover comes my way again with his Big Slide Show (and subsequent \"What is it?\" screening)... I saw this film in Atlanta almost directly after being involved in a rather devastating car crash, so i was slightly dazed at the time, which was perhaps a very good state of mind to watch the prophetic talking arthropods and the retards in the superhero costumes and godlike Glover in his appropriate burly-Q setting, scantily clad girlies rising out of the floor like a magnificent DADAist wet dream.<br /><br />Is it a statement on Life As We Know It? Of course everyone EXPECTS art to be just that. I rather think that the truth is more evident in the absences and in the negative space. What you don\\'t tell us is what we must deduce, but is far more valid than the lies that other people feed us day in and day out. Rather one \"WHAT IS IT?\" than 5000 movies like \"Titanic\" or \"Sleepless in Seattle\" (shudder, gag, groan).<br /><br />Thank you, Mr. Glover (additionally a fun man to watch on screen or at his Big Slide Show-- smart, funny, quirky, and outrageously hot). Make more films, write more books, keep the nightmare alive.')\n",
            "(1, \"This is an amazing movie and all of the actors and actresses and very good! Even though some of the actors and actresses weren't very popular in show business it seemed like they have been acting since they were 1 one year old! It was funny, gross and just all out a very good movie. In most parts I just didn't know what was going to happen next! I was like I think this is going to happen, wait I think this is going to happen. All age groups will love this movie! In some parts I couldn't stop laughing, it was so funny, but in some parts I was totally grossed out and I couldn't believe what I was seeing! I am definitely going to see this movie again! It is one of those movies where it can't get boring. Every time you see it is so suspenseful. I definitely recommend seeing this movie!!\")\n",
            "(1, 'This tale based on two Edgar Allen Poe pieces (\"The Fall of the House of Usher\", \"Dance of Death\" (poem) ) is actually quite creepy from beginning to end. It is similar to some of the old black-and-white movies about people that meet in an old decrepit house (for example, \"The Cat and the Canary\", \"The Old Dark House\", \"Night of Terror\" and so on). Boris Karloff plays a demented inventor of life-size dolls that terrorize the guests. He dies early in the film (or does he ? ) and the residents of the house are subjected to a number of terrifying experiences. I won\\'t go into too much detail here, but it is definitely a must-see for fans of old dark house mysteries.<br /><br />Watch it with plenty of popcorn and soda in a darkened room.<br /><br />Dan Basinger 8/10')\n",
            "(1, 'There is nothing not to like about Moonstruck. I\\'m from a New York Italian family and I actually get a little homesick when I watch it. The actors & actresses, the plot, the subplots, the humor.. they were all fantastic. It starts a little slow, but a lot happens in that two days! I fell in love with LaBoheme because of this movie. On my list of favorite movies, Moonstruck is number 3. It\\'s a \"feel good\" movie where you leave the theatre humming \"that\\'s amore\" or repeating some of your favorite lines: \"old man, if you give those dogs another piece of my food, I\\'ll kick you till you\\'re dead\"; \"Chrissy, bring me the big knife\", \"who\\'s dead\", \"do you love him Loretta....., good because when you do, they drive you crazy because they know they can\". I always put Moonstruck on when there\\'s nothing good to watch because it makes me happy.')\n",
            "(1, 'Always enjoy the great acting of Drew Barrymore and her great performance in this film, where she plays a very very complicated young gal,(Holly Gooding),\"Skipped Parts\",2000, who leaves New York and travels to California and shares an apartment with a up and coming writer, George Newbern,(Patrick Highsmith),\"Far Harbor\",\\'96. Many strange things start to happen to Holly and she seeks to find her brother in a mental institution after he killed her father. If you look close enough you will actually see the mother of Drew Barrymore in real life appear as her mother in this picture. If it was not for the good acting of Drew Barrymore and George Newbern, this film should be seen only on Halloween Night! However, it sure has it\\'s surprises in the END!!!!')\n",
            "(1, \"After a love triangle story in Har Dil Jo Pyaar Karega these 3 stars were again chosen in this controversial flick. The film would have been considered as hit if there was not a controversy with the production values from Bharat Shah. Here director duo Abbas-Mustan did a very different and unique job as compared with their previous and after directorial ventures. They are considered as thriller makers of Bollywood. But in this CCCC they proved that they can equally handle to make a romantic family drama. Hardly there is a single action scene when Preity was being raped by Salman's colleague in her apartment, Salman slapped him.<br /><br />The movie has almost all the standards and ingredients like song, story, casting, performances etc. which are required to make a movie hit. But of course for Salman's fan this was something a surprise gift from him. Why? Because for so long he has been doing roles where he has a scene to show his open body and dance la-la-la all around. His role as a rich young businessman who has no-nonsense nature and of normal attitude is really impressive. After all Madhubala, a prostitute role performed by Preity is amazing. Later when she too turns out thoughtful about her life she deserve proper attention. Her facial expressions and body language become more attractive, and focus mainly goes to her. Her previous role as a pregnant woman in Kya Kehna was not that heart-touching as it is here. Of course, this can be termed as improvement. Then Priya, a very innocent and helpless wife of Raj who only depends on him for a better result. She has nothing powerful influence in the story as the main ingredients are in the hands of Preity.<br /><br />Finally, the main point of the story which is something rare and unique in itself. In real world of this age it is not totally impossible to happen such step of searching for a surrogate mother. Perhaps, many are happening in this large world where these are kept secret. And in this way the scriptwriter of CCCC has uncovered a hidden truth which is taking place in others daily lives. But still then it is a doubt.\")\n",
            "(1, \"This stirring western spins the tale of the famous rifle of the early west that was coveted by one and all. James Stewart is the cowboy who wins the prized Winchester in a shootout, only to lose it in a robbery. The story details Stewart's pursuit of the rifle and a certain man through the film. The rifle changes hands time after time, as though the owner is fated to lose it through violence. The picture has plenty of action and suspense as Stewart closes in on his quarry. A great cast supports Stewart here, namely Stephen McNally, Dan Duryea, Millard Mitchell, John McIntire and Jay C. Flippen. Shelley Winters seems miscast here and the purpose of her role is rather obscure. Tony Curtis and Rock Hudson, teen heartthrobs in later years, have brief but good roles.\")\n",
            "(0, 'There are bad movies, terrible movies even boring movies...I can watch most and put up until the end, not this time. Avoid this like the plague, annoying music throughout, terrible editing, no comedy, its tackier than a novelty mug...My missus wanted to watch this thinking it would be Legally Blonde material or something kind of watchable, but never better than average, chick flick. Its the first time she was begging me to push the stop button.<br /><br />The Girls, well, they were not great to start with (Denise done OK in Starship Troopers and Wild things) but you have sank to the gravel. I feel like a mug having spent 30 minutes on this...Pamela Anderson is almost unrecognisable after much construction work to her face.<br /><br />Please take my advice if you want to avoid wasting valuable oxygen and brain cells ranting at the utter mince that is on your screen.')\n",
            "(0, 'Film critics of the world, I apologize. It is your job to give advice to the moviegoing public so that they can wisely choose what to spend money on. But I ignored your advice and I have been deeply hurt. However, my decision to see \"The Cat in the Hat\" wasn\\'t made haphazardly. You see, three years ago all of you critics said that we should all avoid the \"calamity\" known as \"How the Grinch Stole Christmas\". Then some friends of mine took me to see it and it turned out to be a colorful, funny and almost hypnotic yuletide treat. So when the critics unleashed their fury against \"The Cat in the Hat\", another big budget Seuss update with a big name star in the title role, I thought that it must be the same old song. How wrong I was.<br /><br />For five whole minutes I thought I was in the clear. The opening credits are clever, the kids are charming and the production values are top notch. Then the cat showed up. There are many problems from this point on, but the biggest one was the woeful miscasting of Mike Myers. Where \"The Grinch\" was saved by the inspired casting of Jim Carrey, \"The Cat\" was destroyed by Myers. He can be very funny when his energies are applied where they belong, comic sketches. Every movie he\\'s made that was truly funny was really just a feature length comedy sketch, from \"Wayne\\'s World\" to \"Austin Powers\". So he tries to do the same thing here, it\\'s just that these comedy sketches are more like the stuff that they stick at the end of SNL, not funny, just painful. Not that the writers helped him out any. After the charming prologue the movie turns into an hour of repulsive bodily humor gags, poorly timed pratfalls and insultingly stunted attempts at hip humor. This movie was the most disheartening cinematic experience I have ever had. Period. So much talent and work went into something so vile. I know that the adult stars of this movie will be relatively unscathed by this mess, I just hope that the wonderful Spencer Breslin and Dakota Fanning will get more chances to show their charms in far better movies. If you are a parent, please avoid this like the plague. With movies like \"Elf\" and \"Brother Bear\" currently in theaters, you have far better choices.')\n",
            "(0, \"Ah WINTER KILLS , based on the novel by Richard Condon which deals with a conspiracy that killed the president of the United States 20 years ago . I knew Condon also wrote THE MANCHURIAN CANDIDATE which dealt with a similar theme and was looking forward to seeing an intelligent thriller<br /><br />WINTER KILLS left me cold . It's not a thriller - It's a piece of worthless crap , possibly the worst movie I've seen this month and boy have I seen a lot of bad movies in June . The problem lies in both the direction and the script and seeing as William Richert was responsible for both then he should be blamed entirely for this unfunny farce <br /><br />There's two things wrong with this movie . First off is the way everything is presented in a totally over the top manner . It's not as OTT as say something like that James Bond movie with David Niven and Peter Sellers but everything has a farcial edge to it with actors completely mugging their performances . This might have been justified if there was entertainment value to the movie but there's none . As a satire it's very silly , so silly that it becomes almost unwatchable . Secondly the scenes seem to have been cut so much that they're rendered senseless . Take for example a scene where the hero is confronting a loopy militia leader called Dawson . Dawson tells the hero he has 30 seconds start then it cuts to the hero being on board a plane . The scenes begin and end with no rhyme nor reason<br /><br />A dire movie that's an ordeal to sit through\")\n",
            "(0, \"The book that this movie is based on seriously changed my life. But saying this movie was a disappointment is an understatement. The acting, directing, cinematography, and storyline were all horrible. I would never recommend this movie to anyone. I've told countless people about the book but will now be telling them all that they should definitely not see the movie! I did not expect the plot to follow the book exactly, but they have left out too many key components of the book. The movie tried, but failed, to deliver a powerful and inspiring message and only demeaned the central theme of the prophecy. While putting myself in the position who had not read the book, I saw the Celestine Prophecy as a bunch of hoaxy B.S. I am thoroughly disappointed with Redfield for the way this movie turned out.\")\n",
            "(0, 'This barely watchable film was a bit of an ordeal to sit through. None of the segments are good, but at least the first one was mildly amusing, and the middle one was somewhat imaginative. The final one was just plain brutal, and after sitting through two weak comedic shorts, the third one was truly painful to watch. Even by the low standards of a National Lampoon movie, this one seemed especially boring and joyless.')\n",
            "(0, 'Amazing. That\\'s what you\\'d say if you sat through this film. Simply, incredibly, amazing. It\\'s actually so amazing that anyone was stupid enough to dump money into making this monstrosity that you simply can\\'t believe what you\\'re seeing. That, my friends, is what is truly scary about this film. Somebody thought it was a good idea to make it. <br /><br />Well, here\\'s another amazingly original story: High School student (occasionally seemed like college\\x97go figure) has whore for a mom, lives in a trailer park, and is an \"artist\" who is ridiculed for his \"being all different.\" Well, of course, this poor ridiculed boy is eventually killed and, here\\'s the original part, his soul inhabits a scarecrow (beneath which, he is killed by his slutty mama\\'s latest john). Then he goes around with the standard killing off of all the people that done hurt him. Awww.<br /><br />Here\\'s the breakdown:<br /><br />The Good:<br /><br />--Amazingly funny movie\\x97even if that\\'s not what the clearly drunk filmmakers wanted.<br /><br />--This and the sequel on one disk in the Wal-Mart $5.00 bin\\x97so it\\'s only a little overpriced.<br /><br />Didn\\'t Hurt It, Didn\\'t Help:<br /><br />--The violence and gore are kind of sub-standard. One person is stabbed with a corncob.<br /><br />--Sounds like they put some effort into the music\\x97but it doesn\\'t really fit the movie\\x97and isn\\'t all that good.<br /><br />The Bad:<br /><br />--Terrible, terrible acting.<br /><br />--Another slasher let-down with sexy women\\x97none of them removing clothing. When did that cease being a staple of low-brow slashers??<br /><br />--Ridiculous story.<br /><br />--The scarecrow vomits up one-liners that would make Freddy Krueger and Arnold Swartzenegger blush.<br /><br />--Standard underlying love story goes nowhere, and is poorly done.<br /><br />--Some of the people killed seem like they were chosen at random\\x97you never really know who anybody is and then they\\'re killed. And you only assume that they must\\'ve had it coming.<br /><br />The Ugly:<br /><br />--Extremely average slasher fare, just with a murdering scarecrow instead of\\x85 well, all that other crap.<br /><br />--Nowhere near as interesting as Freddy Krueger, Jason Voorhees, Pinhead, Chucky, or even Angela from the \"Sleepaway Camp\" series\\x97all of which are better than this atrocity.<br /><br />--The absolute worst dialogue I have ever heard in my LIFE. The script is laden with a level of retardedness that I never imagined could exist. I\\'m serious here\\x97it\\'s a full step beyond terrible. Don\\'t get me wrong, though, it\\'s funny as hell\\x97but I\\'ve never heard more asinine banter\\x97even in \"Slumber Party Massacre III.\" This film makes \"Jason X\" look like Shakespeare.<br /><br />--The man who kills the boy that becomes the scarecrow: Worst wig ever. Dialogue to match.<br /><br />Memorable Scene:<br /><br />--The one where elementary-school youths spew out their own witty dialogue: \"Hey, let\\'s go find small animals to torture. Huh huh.\"<br /><br />Acting: 3/10 Story: 3/10 Atmosphere: 2/10 Cinematography: 1/10 Character Development: 2/10 Special Effects/Make-up: 5/10 Nudity/Sexuality: 1/10 (No nudity, Mom\\'s a whore, girls wear no bras) Violence/Gore: 5/10 (Low quality, mediocre amount) Dialogue: 0/10 (Extremely ridiculous, blatant, over-the-top and painfully funny\\x97so bad it\\'s good. My first rating for dialogue in any film!) Music: 5/10 Direction: 2/10<br /><br />Cheesiness: 10/10 Crappiness: 9/10<br /><br />Overall: 3/10<br /><br />Another one for just people like me who enjoy watching pure crap. Or Slasher-film completists. This is not a good movie, at all. Laughable dialogue and characters keep it from being truly boring.<br /><br />www.ResidentHazard.com')\n",
            "(0, 'Wow, I love and respect pretty much anything that David Lynch has done. However, this movie is akin to a first filmmaker\\'s attempt at making a pseudo art video. <br /><br />To give you a couple of examples: <br /><br />1. David Lynch is typically a visual filmmaker, however, this had little visual artistic content (blank walls, \"up shots\" with ceiling in the background) <br /><br />2. David Lynch typically takes great pride in audio, however, in this you could even hear the video camera\\'s hum. <br /><br />In fact, it is very hard to swallow the idea that he had anything to do with this movie. unless...<br /><br />...this is a joke, on David\\'s part, to force fans search his website (for hours) only to find this drivel. I hope so, because at least that idea is funny.')\n",
            "(0, 'This film differentiates itself from the run-of-the-mill \"wonder of the human body\" documentaries by bravely, if bizarrely, opting to elicit disgust in the viewer. In one scene, the camera closes in on a gigantic 50-foot zit as a teenager squeezes pus and fluid out of it. In another, the camera is semisubmerged in a swamp of half digested food and stomach acid as parts of a pasta salad drop in from the esophagus and plop into the goo. In a final tour de force, the camera takes the viewer on a harrowing ride through a forest of...teenage armpit hair. Unfortunately, I\\'m not making any of this up. See this film if you must, but: bring your vomit bag, and don\\'t have pasta salad beforehand.')\n",
            "(0, \"Contains spoilers The movie plot can be summarized in a few sentences: Three guys go hunting in the forest. Two of them along other people get shot in the head without explanation. The last guy can stand in the clear, shout and do anything without getting shot. He gets to walk through an old factory and has the evil people walk right into his scope without a struggle. The villains are conveniently dressed in black and look like villains.<br /><br />That is the whole story, not summarized but in detail. Everything is drawn out with a guy standing ringing a door bell. We wait with him. Long shot of guys being bored in the woods and sleeping. We can take a nap with them. The one drawn out shot of following a female jogger could have been redeeming, if we could see her butt or boobs bouncing.<br /><br />There dialog is less then Terminator and it is not because there is so much action. The characters just don't talk. And, then they don't even have something corny to say like 'I'll be back.' If my buddy shot this on the weekend, I'd cheer for him, because it is quite a feat to figure out the camera controls. To pay money to rent this as a DVD is totally inappropriate.<br /><br />The one thing that is a little funny is the extra with the director telling, how they local police didn't realize that they were shooting and treated them like a random guy walking around with a gun. If they'd have filmed that, I'd be sure it would be more fun to watch then the movie.\")\n",
            "(0, \"As a fan of the Sookie Stackhouse books, I find this series to be a totally crass representation of them. Vampire Bill is not very good looking and looks much older than described in the book. I found that they have made already wonderfully colourful characters seem very course and vulgar. One of the things I loved about the books is that despite all the crap that she is going through Sookie is always a lady, and yet in the TV series she doesn't seem like that at all. Not only that but the prejudices displayed in the TV series are not nearly as wide spread in the books. I didn't expect an exact replica of the books but I at least expected the feel of them to be used for the series.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_label = {0: \" negative review\", 1: \"positive review\"}\n",
        "imdb_label[1]"
      ],
      "metadata": {
        "id": "4ADZ_9d6DFm6",
        "outputId": "b7ca2b5b-729c-46bb-a074-b437e0c74f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "4ADZ_9d6DFm6",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive review'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = len(set([label for (label, text) in train_iter ]))\n",
        "num_class"
      ],
      "metadata": {
        "id": "qJI4Fqj3DF5g",
        "outputId": "fc3dae45-8963-487b-e654-99f250a28928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qJI4Fqj3DF5g",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab([\"age\",\"hello\"])"
      ],
      "metadata": {
        "id": "6kQ2OvGaDHna",
        "outputId": "13be0446-ef24-46ef-dc30-50e6168e3912",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6kQ2OvGaDHna",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[466, 13077]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and validate"
      ],
      "metadata": {
        "id": "6ArUA_BZDLDc"
      },
      "id": "6ArUA_BZDLDc"
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch.utils.data.dataset import random_split,Dataset\n",
        "\n",
        "# Convert the training and testing iterators to map-style datasets.\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "\n",
        "# Determine the number of samples to be used for training and validation (5% for validation).\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "\n",
        "# Randomly split the training dataset into training and validation datasets using `random_split`.\n",
        "# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.\n",
        "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])"
      ],
      "metadata": {
        "id": "pFnyFDyfDIoQ"
      },
      "id": "pFnyFDyfDIoQ",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "93fBXkV-DSgo",
        "outputId": "67ec67b3-9c80-409c-dc15-a727699025d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "id": "93fBXkV-DSgo",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-738194a35e70>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data loader"
      ],
      "metadata": {
        "id": "OQT_MA1RDZMX"
      },
      "id": "OQT_MA1RDZMX"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list = [], []\n",
        "    for _label, _text in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        text_list.append(torch.tensor(text_pipeline(_text), dtype=torch.int64))\n",
        "\n",
        "\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    text_list = pad_sequence(text_list, batch_first=True)\n",
        "\n",
        "\n",
        "    return label_list.to(device), text_list.to(device)"
      ],
      "metadata": {
        "id": "yGuQcdu4DXdH"
      },
      "id": "yGuQcdu4DXdH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")"
      ],
      "metadata": {
        "id": "RWV-Mp3iDbYA"
      },
      "id": "RWV-Mp3iDbYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label,seqence=next(iter(valid_dataloader ))\n",
        "label,seqence"
      ],
      "metadata": {
        "id": "CqsYxXX1Dchw"
      },
      "id": "CqsYxXX1Dchw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural network"
      ],
      "metadata": {
        "id": "beH6LdJSDfU8"
      },
      "id": "beH6LdJSDfU8"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, num_classes,freeze=False):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(glove_embedding.vectors.to(device),freeze=freeze)\n",
        "        # An example of adding additional layers: A linear layer and a ReLU activation\n",
        "        self.fc1 = nn.Linear(in_features=100, out_features=128)\n",
        "        self.relu = nn.ReLU()\n",
        "        # The output layer that gives the final probabilities for the classes\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the embedding layer\n",
        "        x = self.embedding(x)\n",
        "        # Here you can use a simple mean pooling\n",
        "\n",
        "        x = torch.mean(x, dim=1)\n",
        "        # Pass the pooled embeddings through the additional layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "tYXKls_5Dd-N"
      },
      "id": "tYXKls_5Dd-N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model on the full dataset"
      ],
      "metadata": {
        "id": "7DZmuhAqDjC1"
      },
      "id": "7DZmuhAqDjC1"
    },
    {
      "cell_type": "code",
      "source": [
        "model=TextClassifier(num_classes=2,freeze=True)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ACKAETrDDhHF"
      },
      "id": "ACKAETrDDhHF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "predicted_label=model(seqence)"
      ],
      "metadata": {
        "id": "NK58nPwBDkZh"
      },
      "id": "NK58nPwBDkZh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_label.shape)"
      ],
      "metadata": {
        "id": "T2slLswvDlYP"
      },
      "id": "T2slLswvDlYP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label"
      ],
      "metadata": {
        "id": "UfsvUEN7Dm71"
      },
      "id": "UfsvUEN7Dm71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text, model, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.unsqueeze(torch.tensor(text_pipeline(text)),0).to(device)\n",
        "\n",
        "        output = model(text)\n",
        "        return imdb_label[output.argmax(1).item()]"
      ],
      "metadata": {
        "id": "VtR4OYgxDoaD"
      },
      "id": "VtR4OYgxDoaD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(\"the is a good movie\",model,text_pipeline )"
      ],
      "metadata": {
        "id": "10Mg3Wa5DqWM"
      },
      "id": "10Mg3Wa5DqWM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader, model, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for label, text in dataloader:\n",
        "            label, text = label.to(device), text.to(device)\n",
        "            outputs = model(text)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += label.size(0)\n",
        "            correct += (predicted == label).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "f-36TM4rDrVH"
      },
      "id": "f-36TM4rDrVH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_dataloader , model, device)"
      ],
      "metadata": {
        "id": "lBNNw91qDszh"
      },
      "id": "lBNNw91qDszh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "gGWXWO2TDvMp"
      },
      "id": "gGWXWO2TDvMp"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, criterion, train_dataloader, valid_dataloader, epochs=100, model_name=\"my_modeldrop\"):\n",
        "    cum_loss_list = []\n",
        "    acc_epoch = []\n",
        "    best_acc = 0\n",
        "    file_name = model_name\n",
        "\n",
        "    for epoch in tqdm(range(1, epochs + 1)):\n",
        "        model.train()\n",
        "        cum_loss = 0\n",
        "        for _, (label, text) in enumerate(train_dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            predicted_label = model(text)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "            optimizer.step()\n",
        "            cum_loss += loss.item()\n",
        "        #print(\"Loss:\", cum_loss)\n",
        "        cum_loss_list.append(cum_loss)\n",
        "        acc_val = evaluate(valid_dataloader, model, device)\n",
        "        acc_epoch.append(acc_val)\n",
        "\n",
        "        if acc_val > best_acc:\n",
        "            best_acc = acc_val\n",
        "            print(f\"New best accuracy: {acc_val:.4f}\")\n",
        "            #torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
        "\n",
        "    #save_list_to_file(cum_loss_list, f\"{model_name}_loss.pkl\")\n",
        "    #save_list_to_file(acc_epoch, f\"{model_name}_acc.pkl\")"
      ],
      "metadata": {
        "id": "_IpnE-w4Dt0c"
      },
      "id": "_IpnE-w4Dt0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR=1\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
      ],
      "metadata": {
        "id": "sex_xjVYDxXn"
      },
      "id": "sex_xjVYDxXn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2PzKFKhkEFfd"
      },
      "id": "2PzKFKhkEFfd"
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"model_imdb_freeze_true2\"\n",
        "train_model(model, optimizer, criterion, train_dataloader, valid_dataloader, epochs=2, model_name=model_name)"
      ],
      "metadata": {
        "id": "MHuq2KGxDzTY"
      },
      "id": "MHuq2KGxDzTY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load pretrained model\n",
        "\n",
        "%%capture\n",
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ZvhVWJU0flC7BmU1jjYxjg/model-imdb-freeze-true2.pth\n",
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/2RdN-JG4Rm5Gx3UNtOP4NA/model-imdb-freeze-true2-acc.pkl\n",
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/8qoGvWk0BdXRGoFAOT-dAw/model-imdb-freeze-true2-loss.pkl"
      ],
      "metadata": {
        "id": "m97RvsnqD3Jd"
      },
      "id": "m97RvsnqD3Jd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cum_loss_list=load_list_from_file(model_name.replace('_','-') + \"-loss.pkl\")\n",
        "acc_epoch=load_list_from_file(model_name.replace('_','-') + \"-acc.pkl\")\n",
        "plot(cum_loss_list,acc_epoch)"
      ],
      "metadata": {
        "id": "1Hc3GJ8WEBtv"
      },
      "id": "1Hc3GJ8WEBtv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(model_name.replace('_','-') + \".pth\", map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "ybPk6IgnEB-p"
      },
      "id": "ybPk6IgnEB-p",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}